{"0": {
    "doc": "이분 탐색 (Binary Search)",
    "title": "이분 탐색 (Binary Search)",
    "content": "# 이분 탐색 (Binary Search) ![](/Algorithm/img/ag_binary_search.gif) - **정렬되어 있는 리스트** 에서 **탐색 범위를 절반씩 나누어가며 데이터를 탐색** 하는 알고리즘. - 탐색 할 때마다 탐색 범위가 절반씩 좁혀가기 때문에, O(log n) 까지 속도를 줄 일 수 있다. # 구현 _오름차순으로 정렬된 정수 배열 nums와 정수 target이 주어졌을 때, nums에서 target을 검색하는 함수를 작성하시오. target이 존재하면 그 인덱스를 반환하고, 존재하지 않으면 -1을 반환하시오._ - 범위의 **경계(최소, 최대)** 를 나타내는 변수 `lo`, `hi` - 범위의 **중간 요소** 를 나타내며, 범위를 **절반으로 나는 기준**이 되는 변수 `mid`. 타겟 과 비교하며, 타겟 이 속하는 범위를 판단한다. 1. 타겟이 크다면, 최소 경계인 `lo` 를 변경 2. 타겟이 작다면, 최대 경계인 `hi` 를 변경 3. 타겟이 같다면, 탐색 성공 - **타겟과 `mid` 의 값을 비교** 하며, **범위의 경계(`lo`, `hi`) 를 변경**하여 타겟이 속하는 범위를 점차 좁혀나가, 타겟이 위치한 인덱스를 찾아낸다. ## 구현 방법 1 - 재귀 ```javascript const search = (nums, target) => { const lo = 0; const hi = nums.length - 1; return binary_search(nums, target, lo, hi); }; const binary_search = (nums, target, lo, hi) => { if (lo > hi) return -1; // 범위 중간요소 mid 계산 const mid = lo + Math.floor((hi - lo + 1) / 2); // 타겟이 같다면, 탐색 성공 if (nums[mid] === target) { return mid; } // 타겟이 작다면, 최대 경계인 hi 를 변경 if (nums[mid] > target) { return binary_search(nums, target, lo, mid - 1); } // 타겟이 크다면, 최소 경계인 lo 를 변경 if (nums[mid] { let lo = 0; let hi = nums.length - 1; // 타겟이 같다면 (lo === hi), 탐색 성공 while (lo = nums[mid]) { // 타겟이 크다면, 최소 경계인 lo 를 변경 lo = mid; } } return nums[lo] === target ? lo : -1; }; ``` # 출처 - [이분 탐색(Binary Search) 헷갈리지 않게 구현하기](https://www.acmicpc.net/blog/view/109) - [Binary Search 101](https://leetcode.com/problems/binary-search/solutions/423162/binary-search-101-by-aminick-kkch/) ",
    "url": "/Algorithm/ag_binary_search.html",
    
    "relUrl": "/Algorithm/ag_binary_search.html"
  },"1": {
    "doc": "비트마스크",
    "title": "비트마스크",
    "content": "## 비트마스크 - 정수를 이진수(비트) 형태로 표현하여, 비트 연산을 활용해 데이터를 효율적으로 관리하는 기법 - 주로 집합을 표현하거나 상태를 압축하여 저장하는 데 사용됨 ### 비트 연산 | 연산 | 설명 | 예시 | --- | --- | --- | **AND (`&`)** | 공통된 비트가 1이면 1 | `1010 & 1100 = 1000` | **OR** (`\\|`) | 하나라도 1이면 1 | `1010 \\| 1100 = 1110` | **XOR (`^`)** | 다르면 1, 같으면 0 | `1010 ^ 1100 = 0110` | **NOT (`~`)** | 0은 1로, 1은 0으로 | `~1010 = 0101` | **SHIFT (`>`)** | 비트를 좌/우로 이동 | `1010 > 1 = 01010` | `\\|=` | **OR** 대입 연산자 (둘 중 하나라도 1이면 1) | `a \\|= b` → `a = a \\| b` | **`&=`** | **AND** 대입 연산자 (둘 다 1이어야 1) | `a &= b` → `a = a & b` | **`^=`** | **XOR** 대입 연산자 (서로 다를 때 1) | `a ^= b` → `a = a ^ b` | **`+=`** | 덧셈 대입 연산자 | `a += b` → `a = a + b` | **`-=`** | 뺄셈 대입 연산자 | `a -= b` → `a = a - b` | **`*=`** | 곱셈 대입 연산자 | `a *= b` → `a = a * b` | **`/=`** | 나눗셈 대입 연산자 | `a /= b` → `a = a / b` | **`%=`** | 나머지 대입 연산자 | `a %= b` → `a = a % b` | ### 1. 집합 표현 - N개의 요소가 있는 집합을 N비트 정수로 표현 - `{0, 2, 3}`을 비트마스크로 나타내면 `1101 (2^3 + 2^2 + 2^0)` - O(1)의 시간 복잡도로 집합 연산 가능 ``` set = {0, 2, 3} = 1101 (2^3 + 2^2 + 2^0) int set = 0; // 공집합 set |= (1 0001 set |= (1 0101 set |= (1 1101 ``` ### 2. 특정 원소 포함 여부 확인 - 특정 원소가 집합에 포함되었는지 `AND` 연산으로 확인 ``` set = 1101 if ((set & (1 << 2)) != 0) { System.out.println(\"2가 포함됨\"); } // (1 << 2) = 0100 ``` ### 3. 원소 삭제 - 특정 원소를 제거할 때 `AND` 연산과 `NOT`을 활용 ``` set = 1101 set &= ~(1 << 2); // ~(1 << 2) = 1011 // set = 1001 ``` ### 4. 원소 토글(있으면 제거, 없으면 추가) - `XOR` 연산을 사용하면 특정 원소를 추가 또는 제거 가능 ``` set = 1101 set ^= (1 << 2); // (1 << 2) = 0100 // set = 1010 ``` ### 5. 모든 원소가 포함된 상태(전체 집합) - N개의 비트가 모두 1인 값 ``` int N = 3; int fullSet = (1 << N) - 1; // 0111 // (1 << 3) = 1000 ``` --- ## 활용 예제 ### 1. 부분 집합 탐색 ```java int n = 3; for (int subset = 0; subset < (1 << n); subset++) { System.out.print(\"Subset: \"); for (int i = 0; i < n; i++) { if ((subset & (1 << i)) != 0) { // subset의 i번째 비트가 1인지 0인지 확인 System.out.print(i + \" \"); } } System.out.println(); } ``` | **subset (이진수)** | **subset 값** | **출력** | --- | --- | --- | 000 | 0 | Subset: | 001 | 1 | Subset: 0 | 010 | 2 | Subset: 1 | 011 | 3 | Subset: 0 1 | 100 | 4 | Subset: 2 | 101 | 5 | Subset: 0 2 | 110 | 6 | Subset: 1 2 | 111 | 7 | Subset: 0 1 2 | ### 2. DP 예제 ```java int[][] dist = new int[N][N]; // 도시 i에서 도시 j까지의 거리 int[][] dp = new int[1 << N][N]; // (방문 상태, 현재 노드) int tsp(int visited, int cur) { if (visited == (1 << N) - 1) return dist[cur][0]; // 모든 도시 방문 완료 if (dp[visited][cur] != -1) return dp[visited][cur]; // 현재 상태에서 최단 경로를 저장 int result = Integer.MAX_VALUE; for (int next = 0; next < N; next++) { if ((visited & (1 << next)) == 0) { // 아직 방문 안한 도시 // result에는 최단 경로가 갱신 result = Math.min(result, dist[cur][next] + tsp(visited | (1 << next), next)); } } return dp[visited][cur] = result; } ``` --- ### 비트마스크의 장점 - **메모리 절약 :** 배열보다 작은 공간을 사용해 상태를 저장 - **빠른 연산 O(1) :** 일반적인 연산보다 빠르고 메모리 공간을 절약할 수 있다. - **알고리즘 최적화** : 간단하고 빠르게 DP, 그래프 탐색 등 다양한 문제 해결 가능 ### 언제 사용하면 좋을까? - 집합 연산이 빈번한 경우 - DP에서 상태를 효율적으로 관리할 때 - 그래프에서 방문 여부를 체크할 때 --- https://rebro.kr/63 https://mygumi.tistory.com/361 https://david0506.tistory.com/76 ",
    "url": "/Algorithm/ag_bitMask.html",
    
    "relUrl": "/Algorithm/ag_bitMask.html"
  },"2": {
    "doc": "DFS와 BFS",
    "title": "DFS와 BFS",
    "content": "## DFS와 BFS 그래프 탐색에서 가장 기본이 되는 방법 두 가지가 바로 **DFS(Depth First Search)**와 **BFS(Breadth First Search)**입니다. DFS는 그래프에서 한 방향으로 갈 수 있는 곳까지 깊이 들어가며 탐색하고, BFS는 시작 정점으로부터 가까운 순으로(너비 우선으로) 탐색을 진행합니다. ![](/Algorithm/img/ag_dfs_bfs_1.png) --- ## DFS (Depth First Search) ### DFS란? - **깊이 우선 탐색**: 시작 정점에서 한 방향으로 갈 수 있는 정점 끝까지 탐색을 마친 뒤, 다시 돌아와 다른 방향을 탐색하는 방식입니다. - **재귀**나 **스택**을 이용해 구현 가능합니다. ### DFS의 특징 - 트리나 그래프의 한 갈래를 먼저 끝까지 탐색 - 백트래킹(Backtracking)과 함께 사용되어 그래프, 트리 문제를 효율적으로 해결 가능 - BFS에 비해 경로를 찾거나 (예: 미로 찾기) 모든 경로를 조사해야 할 때 유용 ### DFS 동작 과정 예시 1. **시작 정점 방문**: 시작 정점을 방문하고, 방문했다고 표시 2. **인접한 정점 순회**: 해당 정점에 연결된(인접한) 정점을 하나씩 방문 (재귀 혹은 스택 사용) 3. **갈 수 있는 곳까지 깊이 탐색**: 더 이상 진행할 수 없으면 이전 경로로 돌아와(백트래킹) 탐색 안 한 경로를 다시 진행 ### DFS 기본 구조 (Java) ```java public class DFSMatrix { static int[][] graph; // 인접 행렬 static boolean[] visited; static int n = 5; // 노드 개수(0~4) public static void main(String[] args) { graph = new int[n][n]; visited = new boolean[n]; // 그래프 연결 정보 (무방향) // 0 ↔ 1 graph[0][1] = 1; graph[1][0] = 1; // 0 ↔ 2 graph[0][2] = 1; graph[2][0] = 1; // 1 ↔ 3 graph[1][3] = 1; graph[3][1] = 1; // 2 ↔ 4 graph[2][4] = 1; graph[4][2] = 1; // 3 ↔ 4 graph[3][4] = 1; graph[4][3] = 1; // DFS 수행 (시작 노드: 0) System.out.print(\"DFS 방문 순서: \"); dfs(0); System.out.println(); } // 재귀 함수를 사용한 DFS public static void dfs(int node) { visited[node] = true; System.out.print(node + \" \"); // 인접 노드 탐색 for (int next = 0; next 1 -> 3 -> 4 -> 2` --- ## BFS (Breadth First Search) ### BFS란? - **너비 우선 탐색**: 시작 정점으로부터 가까운 정점을 먼저 방문하고, 점차 멀리 있는 정점을 방문해 나가는 방식입니다. - **큐(Queue)**를 이용해 구현할 수 있습니다. ### BFS의 특징 - 최단 경로 문제에서 유용 (가중치가 동일한 그래프에서 **시작 정점으로부터 최단 거리**를 구할 때) - 방문 순서를 인접한 정점들부터 차례대로(너비 우선) 처리 ### BFS 동작 과정 예시 1. **시작 정점을 큐에 삽입**하고, 방문했다고 표시 2. **큐에서 정점을 꺼냄** → 해당 정점과 인접한(연결된) 정점들을 큐에 삽입 (아직 방문 안 했을 경우) 3. 큐가 빌 때까지 2번 과정을 반복 ### BFS 기본 구조 (Java) ```java import java.util.LinkedList; import java.util.Queue; public class BFSMatrix { static int[][] graph; static boolean[] visited; static int n = 5; // 노드 개수(0~4) public static void main(String[] args) { graph = new int[n][n]; visited = new boolean[n]; // 그래프 연결 정보 (무방향) // 0 ↔ 1 graph[0][1] = 1; graph[1][0] = 1; // 0 ↔ 2 graph[0][2] = 1; graph[2][0] = 1; // 1 ↔ 3 graph[1][3] = 1; graph[3][1] = 1; // 2 ↔ 4 graph[2][4] = 1; graph[4][2] = 1; // 3 ↔ 4 graph[3][4] = 1; graph[4][3] = 1; // BFS 수행 (시작 노드: 0) System.out.print(\"BFS 방문 순서: \"); bfs(0); System.out.println(); } public static void bfs(int start) { Queue queue = new LinkedList(); visited[start] = true; queue.offer(start); while (!queue.isEmpty()) { int node = queue.poll(); System.out.print(node + \" \"); // 인접 노드 탐색 for(int next = 0; next 1 -> 2 -> 3 -> 4` --- ## DFS와 BFS의 비교 | 특징 | DFS | BFS |--------------------|---------------------------------------------------------|---------------------------------------------------------| **탐색 방향** | 시작 정점에서 갈 수 있는 곳까지 깊게 들어감 | 시작 정점에서 가까운 정점부터 순차적으로 방문 | **자료구조** | 재귀(스택) | 큐(Queue) | **최단 경로** | 경로를 모두 탐색하며 찾을 수 있으나, 일반적으로 BFS보다빠른 최단 경로 확인은 어려움 | 동일 가중치 그래프에서최단 경로 찾기에 적합 | **적용 예시** | 백트래킹, 사이클 여부 확인, 위상 정렬(변형) 등 | 최단 거리 계산, 층(level)별 탐색, 너비 우선 검색 등 | **구현 난이도** | 재귀나 반복(스택)로 비교적 단순 | 큐를 사용하기 때문에 구조는 간단하지만코드가 약간 더 길어질 수 있음 | --- ## 참고 자료 1. [백준 온라인 저지 - 그래프 탐색](https://www.acmicpc.net/problemset?sort=ac_desc&algo=7) 2. [GeeksforGeeks - DFS](https://www.geeksforgeeks.org/depth-first-search-or-dfs-for-a-graph/) 3. [GeeksforGeeks - BFS](https://www.geeksforgeeks.org/breadth-first-search-or-bfs-for-a-graph/) --- 위 예시 코드를 참고하여 **그래프를 어떻게 표현(인접 리스트/인접 행렬)하느냐**에 따라 구현이 조금씩 달라질 수 있습니다. 실제 프로젝트나 문제 풀이에서, 그래프의 특성(노드 개수, 간선 개수, 가중치 유무 등)에 맞춰 적절한 방식으로 DFS와 BFS를 활용하면 됩니다. ",
    "url": "/Algorithm/ag_dfs_bfs.html",
    
    "relUrl": "/Algorithm/ag_dfs_bfs.html"
  },"3": {
    "doc": "다익스트라(dijkstra) 알고리즘",
    "title": "다익스트라(dijkstra) 알고리즘",
    "content": "# 다익스트라(dijkstra) 알고리즘 다익스트라 알고리즘은 가중치가 있는 그래프에서 한 노드에서 다른 모든 노드의 최단 거리를 구하는 알고리즘이다. 우선순위 큐를 사용하여 효율적인 동작이 가능하다. ## 동작 원리 1. 초기화 - 시작 정점에서 각 정점까지의 거리를 무한(INF)으로 설정합니다. - 시작 정점의 거리는 0으로 설정합니다. - 우선순위 큐(priority queue, 최소 힙)를 사용하여 현재 방문할 정점을 관리합니다. 2. 가장 가까운 정점 선택 - 우선순위 큐에서 현재까지의 최단 거리가 가장 짧은 정점을 꺼냅니다. 3. 인접한 정점 업데이트 - 해당 정점의 인접한 정점들을 확인하며 더 짧은 경로가 있다면 갱신합니다. - (현재 정점까지의 최단 거리) + (현재 정점 → 인접 정점 거리)를 계산하여 기존보다 짧으면 갱신 후 큐에 삽입합니다. 4. 모든 정점을 처리할 때까지 반복 ## 시간복잡도 우선순위 큐를 사용한 다익스트라는 다음과 같은 연산을 수행한다. 1. 각 노드에 대한 초기화 작업 → O(V) - dist 배열을 INF로 초기화. - 입력을 받아 인접 리스트(graph)를 구성. 2. 우선순위 큐에 시작 정점을 삽입 → O(log V) - 시작 정점에서 출발하는 간선만 고려. 3. 우선순위 큐에서 노드를 꺼내는 연산 → O(V log V) - V개의 노드를 각각 한 번씩 꺼내므로 O(V log V). - (최소 힙에서 요소를 꺼내는 연산: O(log V)) 4. 각 노드에서 인접 노드를 확인하고 거리 갱신 → O(E log V) - 모든 간선을 확인해야 하므로 O(E). - 각 갱신마다 새로운 거리를 우선순위 큐에 삽입(O(log V)) 하므로 O(E log V). ## 예시 1. 출발 노드인 1번을 선택하고 자신과의 최단 거리를 0, 나머지 모든 노드의 최단거리를 무한대로 초기화 ![img](/Algorithm/img/ag_dijkstra_2.png) 2. 우선순위 큐에서 현재 노드인 1번 선택 후, 인접한 노드와 거리 갱신 ![img](/Algorithm/img/ag_dijkstra_3.png) 3. 우선순위 큐에서 다음 노드인 4번 선택 후, 인접한 노드와 거리 갱신 ![img](/Algorithm/img/ag_dijkstra_4.png) 4. 우선순위 큐에서 다음 노드인 2번 선택 후, 인접한 노드와 거리 갱신 ![img](/Algorithm/img/ag_dijkstra_5.png) 5. 우선순위 큐에서 다음 노드인 5번 선택 후, 인접한 노드와 거리 갱신 ![img](/Algorithm/img/ag_dijkstra_6.png) 6. 우선순위 큐에서 다음 노드인 6번 선택. 도착 노드이며 알고리즘을 종료한다. 3번은 방문하지 않는다. ![img](/Algorithm/img/ag_dijkstra_7.png) ## 예제 코드 ```C++ #include #include #include using namespace std; #define INF 1e9 // 무한대 값 설정 // 그래프를 저장하는 인접 리스트 (비용, 연결 노드) vector> graph[100001]; vector dist(100001, INF); // 최단 거리 테이블 초기화 // 다익스트라 알고리즘 함수 void dijkstra(int start) { // 최소 힙(우선순위 큐) 선언 - (최단 거리, 노드 번호) 형태 priority_queue, vector>, greater> pq; pq.push({0, start}); // 시작 노드의 거리는 0 dist[start] = 0; while (!pq.empty()) { auto [cost, now] = pq.top(); // 현재 노드와 비용 pq.pop(); // 이미 처리된 노드라면 무시 if (dist[now] > V >> E >> start; // 정점, 간선 개수, 시작 노드 입력 // 그래프 입력 받기 for (int i = 0; i > u >> v >> w; // 시작점, 도착점, 가중치 graph[u].push_back({w, v}); } // 다익스트라 실행 dijkstra(start); // 결과 출력 for (int i = 1; i <= V; i++) { if (dist[i] == INF) cout << \"INF\\n\"; // 도달할 수 없는 경우 else cout << dist[i] << '\\n'; } } ``` # 참고 링크 - [다익스트라 알고리즘 velog](https://velog.io/@717lumos/알고리즘-다익스트라Dijkstra-알고리즘) - [동적계획법(Dynamic Programming) velog](https://velog.io/@boyeon_jeong/동적계획법Dynamic-Programming) - [다익스트라 알고리즘 나무위키](https://namu.wiki/w/다익스트라%20알고리즘) ",
    "url": "/Algorithm/ag_dijkstra.html",
    
    "relUrl": "/Algorithm/ag_dijkstra.html"
  },"4": {
    "doc": "분할 정복 알고리즘",
    "title": "분할 정복 알고리즘",
    "content": "# 분할 정복 알고리즘 ![img](/Algorithm/img/ag_divide_and_conquer_1.png) 분할 정복 알고리즘(Divide and conquer)은 문제를 반씩 나누어 해결하고, 하위 문제에 대한 결과를 원래 문제에 대한 결과로 조합해 해결하는 알고리즘이다. ## 특징 1. 문제를 두 개 이상의 작은 문제로 나눈다. 2. 각각의 작은 문제를 재귀적으로 해결한다 3. 해결한 결과를 병합하여 최종 답을 얻는다. ## 예시 ### 병합 정렬 ```C++ #include #include using namespace std; // 두 개의 정렬된 부분 배열을 병합하는 함수 void merge(vector& arr, int left, int mid, int right) { vector temp; // 병합 결과를 저장할 임시 배열 int leftIndex = left, rightIndex = mid + 1; // 두 부분 배열을 비교하며 병합 while (leftIndex & arr, int left, int right) { if (left >= right) return; // 기저 조건: 배열 크기가 1이면 종료 int mid = left + (right - left) / 2; // 중간 지점 계산 mergeSort(arr, left, mid); // 왼쪽 부분 정렬 mergeSort(arr, mid + 1, right); // 오른쪽 부분 정렬 merge(arr, left, mid, right); // 정렬된 두 부분 병합 } int main() { vector arr = {5, 2, 9, 1, 5, 6}; mergeSort(arr, 0, arr.size() - 1); // 병합 정렬 실행 // 정렬된 배열 출력 for (int num : arr) { cout << num << \" \"; } } ``` ### 거듭제곱 계산 ```C++ long long power(long long base, long long exp) { if (exp == 0) return 1; long long half = power(base, exp / 2); return (exp % 2 == 0) ? half * half : half * half * base; } ``` 예를 들어 2^10을 계산할 때는 일반적으로 시작복잡도가 O(n)인 반복문을 사용한다. 하지만 분할 정복을 활용한 거듭제곱은 시간복잡도가 O(log n)으로 더 빠르게 계산할 수 있다. 공식 : x^n = (n%2==0)? (x^(n/2))^2 : x*(x^((n-1)/2))^2 n을 절반으로 줄여서 재귀적으로 해결할 수 있다. # Meet in the middle? Meet in the middle 기법은 분할 정복 알고리즘처럼 문제를 반으로 나누지만 하위 문제를 계속 나누는 것이 아닌 두 개의 문제로 나누는 차이가 있다. 완전 탐색으로 풀기 어려운 문제를 해결할 때 사용되며, 시간 복잡도를 O(2^(N/2)) 수준으로 줄이는 것이 목표다. - [관련 알고리즘 문제](https://www.acmicpc.net/problem/1182) - [해답](https://duplicated.tistory.com/114) ",
    "url": "/Algorithm/ag_divide_and_conquer.html",
    
    "relUrl": "/Algorithm/ag_divide_and_conquer.html"
  },"5": {
    "doc": "DP (Dynamic Programming)",
    "title": "DP (Dynamic Programming)",
    "content": "## DP (Dynamic Programming) - 여러 개의 하위 문제를 풀고 **그 결과를 기록하고 이용해 문제를 해결**하는 알고리즘 - 핵심 - **중복 계산 방지** (Memoization, Tabulation) - **최적 부분 구조** (Optimal Substructure) ![](/Algorithm/img/ag_dp_1.png) ```java Fibo(1) = 1 Fibo(2) = 1 Fibo(3) = Fibo(1) + Fibo(1) = 1 + 1 = 2 Fibo(4) = Fibo(3) + Fibo(2) = 2 + 1 = 3 Fibo(5) = Fibo(4) + Fibo(3) = 3 + 2 = 5 Fibo(6) = Fibo(5) + Fibo(4) = 5 + 3 = 8 ... Fibo(n) = Fibo(n - 1) + Fibo(n-2) 중복된 작업을 반복적으로 실행되므로 이미 했던 일을 기록할 필요가 생김 👉 **Memoization** memo = { 1: 1, 2: 1, 3: 2 ... } ``` --- ## LIS (Longest Increasing Subsequence, 최장 증가 부분 수열) - 증가 부분 수열: 선택한 원소들이 오름차순을 이루는 부분 수열 - LIS 문제는 이러한 증가 부분 수열 중 **가장 긴 길이를 찾는 것**이 목표 ### 1. DP 방식 (O(n²)) - `dp[i]`: i번째 요소를 끝으로 하는 LIS의 최대 길이 ``` dp[i] = max(dp[j] + 1) (j list = new ArrayList(); for (int num : arr) { int pos = Collections.binarySearch(list, num); // num의 위치 탐색 if (pos ancestors = new HashSet(); // u의 조상 집합 생성 while (u != -1) { ancestors.add(u); u = parent[u]; } // v의 조상 확인 while (v != -1) { if (ancestors.contains(v)) return v; v = parent[v]; } return -1; } ``` - 노드의 개수에 비례하여 조상을 찾기 때문에 최악의 경우 모든 노드를 탐색해야 할 수 있음 ### 2. 희소 테이블을 이용한 방식 (O(log N)) - **`sparseTable[i][j]`를 사용하여 2^j 번째 부모를 저장** 1. LOG(한 번에 이동할 수 있는 최대 점프 크기) 값 계산 2. DFS로 깊이 설정 후 희소 테이블 초기화 3. 희소 테이블(`parent[i][j]`) 저장 ```java static int[][] parent; //노드 i의 2^j번째 부모를 저장하는 배열 (희소 테이블) static int[] depth; // 노드 i의 깊이 (루트로부터의 거리) static int LOG; // 최대 2^j 범위를 구하기 위한 log2(N) // 전처리 함수 static void init(int n, List[] tree) { LOG = (int) (Math.log(n) / Math.log(2)) + 1; parent = new int[n + 1][LOG]; depth = new int[n + 1]; dfs(1, -1, 0, tree); // (루트에서 시작) for (int j = 1; j [] tree) { parent[node][0] = par; depth[node] = dep; for (int next : tree[node]) { if (next != par) dfs(next, node, dep + 1, tree); } } // LCA 찾기 static int lca(int u, int v) { if (depth[u] = 0; j--) { // u의 깊이가 v의 깊이보다 크거나 같으면 u의 2^j 번째 부모로 이동 if (depth[u] - (1 = depth[v]) u = parent[u][j]; } if (u == v) return u; // u와 v가 다를 때, 두 노드의 조상을 찾음 for (int j = LOG - 1; j >= 0; j--) { // u와 v의 2^j 번째 부모가 다를 때, 두 노드를 각각의 부모로 이동 if (parent[u][j] != parent[v][j]) { u = parent[u][j]; v = parent[v][j]; } } return parent[u][0]; } ``` ```java parent[i][j] 노드 번호(i) → 1 2 3 4 5 6 7 ------------------------------------------------ j = 0 (1칸 위) -1 1 1 2 2 3 3 j = 1 (2칸 위) -1 -1 -1 1 1 1 1 j = 2 (4칸 위) -1 -1 -1 -1 -1 -1 -1 ``` **활용** - **네트워크 라우팅**: 네트워크 트리 구조에서 최단 경로 탐색 - **파일 시스템**: 디렉터리 구조에서 공통 최상위 폴더 찾기 --- ### LIS vs. LCA | 개념 | LIS (최장 증가 부분 수열) | LCA (최소 공통 조상) | --- | --- | --- | 구조 | 배열 기반 문제 | 트리 기반 문제 | 알고리즘 | DP + 이분 탐색 | DFS + DP (희소 테이블) | 시간 복잡도 | O(n log n) | O(log N) | 활용 예시 | 수열 최적화 문제 | 트리 탐색 문제 | https://galid1.tistory.com/507 https://chanhuiseok.github.io/posts/algo-49/ https://loosie.tistory.com/364 [https://velog.io/@ddongh1122/알고리즘-LCA-알고리즘](https://velog.io/@ddongh1122/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98-LCA-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98) ",
    "url": "/Algorithm/ag_dp.html",
    
    "relUrl": "/Algorithm/ag_dp.html"
  },"6": {
    "doc": "GCD(Greatest Common Divisor) 알고리즘",
    "title": "GCD(Greatest Common Divisor) 알고리즘",
    "content": "## GCD(Greatest Common Divisor) 알고리즘 > GCD란 영어 단어 그대로 최대공약수라는 뜻입니다. 최대공약수는 공약수 중에서 가장 큰 값을 의미합니다. ### 공약수 > 사전에서는 둘 이상의 정수에 공통된 약수라고 정의되어 있습니다. 정수 두 개를 놓고 보았을 때, 둘 다 나누어 떨어지게 만들 수 있는 수를 공약수라고 합니다. 예시 - 16의 약수: 1, 2, 4, 8, 16 - 24의 약수: 1, 2, 3, 4, 6, 8, 12, 24 16과 24의 공약수는 1, 2, 4, 8이고, 최대공약수는 8입니다. ### 유클리드 호제법(Euclidean algorithm) - 최대공약수를 구하는 알고리즘입니다. - 2개의 자연수 a, b(a > b)에 대해서 a를 b로 나눈 나머지를 r이라고 했을 때, a와 b의 최대 공약수는 b와 r의 최대공약수와 같습니다. - `(a, b) = (b, a % b)` - 이 방법을 나머지가 0이 될 때까지 반복하면 a와 b의 최대공약수가 됩니다. 예시 - 16과 24의 최대공약수를 구하면 (24, 16) = (16, 8) = (8, 0)로 이전 계산과 같습니다. ### GCD Algorithm(Euclidean algorithm)의 자바 코드 - b와 a를 b로 나눈 나머지의 값을 b의 인자로 계속 보내주면서 b 인자 자리에 위치한 값이 0이 될 때까지 재귀적으로 호출하는 코드입니다. ```java // 재귀 함수 public static int gcd(int a, int b) { if (b == 0) return a; return gcd(b, a % b); } // 반복문 public static int gcd(int a, int b) { int c; while(b != 0) { c = a % b; a = b; b = c; } return a; } ``` ## LCM(Least common multiple) 알고리즘 > 최소공배수라는 뜻으로 최소공배수는 공배수 중에서 가장 작은 값을 의미합니다. ### 공배수 > 공배수는 두 개 이상인 자연수의 공통인 배수라는 뜻입니다. 쉽게 말해 여러 개의 수가 있을 때, 공통적으로 배수가 되는 수를 말하는 것입니다. 두 개 이상의 모든 공배수는 최소공배수의 배수입니다. 예시 - 3의 배수: 3, 6, 9, 12, 15, 18, 21, 24, ... - 4의 배수: 4, 8, 12, 16, 20, 24, ... 3과 4의 공배수는 12와 24이고, 최소공배수는 12입니다. ### GCD와 LCM 사이의 관계 두 자연수 A와 B의 최대공약수를 G, 최소공배수를 L이라고 하면, `A = G x a, B = G x b(a, b는 서로소)`로 나타낼 수 있습니다. - `L = G x a x b` - `A x B = (a x G) x (b x G) = (a x b x G) x G = L x G` - 식은 `A x B = L x G`로 간단하게 나타낼 수 있고, `L = A x B / G`라고 표현할 수도 있습니다. ![](/Algorithm/img/ag_gcd_lcm_1.png) 예시 - 16과 24 최대공약수 G는 8이 되고, 이를 바탕으로 최소공배수 L은 48이 됩니다. - G = 8 - A = 8 x 3 = 24 - B = 8 x 2 = 16 위 값을 기준으로 LCM을 구하면 아래 두 방법으로 구할 수 있고, 2번은 GCD를 활용한 방식입니다. 1. L = 8 x 3 x 2 = 48 2. L = 24 x 16 / 8 = 48 ### LCM 식 앞서 GCD를 구하는 알고리즘을 알고 있다는 가정 하에 아래의 식을 통해 구할 수 있습니다. - `LCM(a, b) = a x b / GCD(a, b)` ### LCM 알고리즘 - GCD 알고리즘을 기반으로 구할 수 있습니다. ```java public static int lcm(int a, int b) { return a * b / gcd(a, b); } ``` ## 참고 자료 [GeeksforGeeks - GCD](https://www.geeksforgeeks.org/program-to-find-gcd-or-hcf-of-two-numbers/) ",
    "url": "/Algorithm/ag_gcd_lcm.html",
    
    "relUrl": "/Algorithm/ag_gcd_lcm.html"
  },"7": {
    "doc": "그리디 (Greedy)",
    "title": "그리디 (Greedy)",
    "content": "# 그리디 (Greedy) - 각 단계마다 최적이라고 생각되는 것을 선택 해 나가, 최종적으로 해답에 도달하는 알고리즘. - 항상 최적의 값을 보장하는것이 아니라 최적의 값의 ‘근사한 값’을 찾는 것을 목표로 한다. - 예를 들어, 노드에서 가장 합이 높은 값을 선택하는 방법 ![](/Algorithm/img/ag_greedy_ex_1.png) ✅ 그리디 ![](/Algorithm/img/ag_greedy_ex_2.png) # 조건 - **탐욕 선택 속성** (Greedy Choice Property) : **각 단계에서 가장 최적인 선택**을 하는 것으로, **전체적으로 최적의 결과**를 가져올 수 있어야 한다. - **최적 부분 구조** (Optimal Substructure) : 전체 문제를 작은 부분 문제로 나누어 **각각의 부분 문제에서 최적의 해**를 구한 후 이를 조합하여 **전체 문제의 최적해**를 구할수 있어야 한다. # 단계 1. 선택 절차 (Selection Procedure) : 현재 상태 에서 **최적인 선택**을 한다. 이 선택은 이후에는 바뀌지 않는다. 2. 적절성 검사(Feasibility Check) : **현재 선택이 문제의 조건을 만족시키는지 확인**한다. 조건을 만족시키지 않으면 해당 항목은 제외된다. # 예제 _한 상점에서 사탕을 할인 판매하고 있습니다. 두 개의 사탕을 판매할 때마다 상점은 세 번째 사탕을 무료로 제공합니다. 고객은 구매한 두 개의 사탕 중 최소 비용 이하의 가격을 가진 사탕이라면 어떤 사탕이든 무료로 선택할 수 있습니다._ _예를 들어, 비용이 1, 2, 3, 4인 4개의 사탕이 있고 고객이 비용 2와 3인 사탕을 구매한다면, 비용 1인 사탕을 무료로 가져갈 수 있지만 비용 4인 사탕은 가져갈 수 없습니다._ _0부터 시작하는 정수 배열 cost가 주어지며, cost[i]는 i번째 사탕의 비용을 나타냅니다. 모든 사탕을 구매하는 데 필요한 최소 비용을 반환하세요._ --- **각 단계 에서 최적의 선택(3(혹은 1, 2) 개의 사탕마다, 최소의 비용으로 구매) 을 하여, 전체 문제의 최적의 결과 (모든 사탕을 최소 비용으로 구매) 이 가능하기 에, 그리디 알고리즘 으로 문제 해결 가능.** ```javascript /** * @param {number[]} cost * @return {number} */ const minimumCost = (cost) => { const len = cost.length; if (len === 1) return cost[0]; // 1. 선택 절차 cost.sort((a, b) => b - a); let ans = cost[0] + cost[1]; // 루프 를 통해, 각 단계 에서 최적의 선택을 구한다. for (let i = 3; i b - a); let ans = cost[0] + cost[1]; ``` 2. 적절성 검사 - 세 번째 사탕은 무료로 제공하기 때문에, 구매해선 안된다. 구매하는 경우는 제외한다. ```javascript if ((i + 1) % 3 === 0) { continue; } ``` # 출처 - [[Java/알고리즘] 그리디 알고리즘(탐욕법, Greedy Algorithm) 이해하기]() - [그리디 알고리즘(Greedy Algorithm, 탐욕법)](https://velog.io/@kyunghwan1207/%EA%B7%B8%EB%A6%AC%EB%94%94-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98Greedy-Algorithm-%ED%83%90%EC%9A%95%EB%B2%95#%EB%AC%B8%EC%A0%9C1-1%EC%9D%B4-%EB%90%A0-%EB%95%8C%EA%B9%8C%EC%A7%80) - [Minimum Cost of Buying Candies With Discount](https://leetcode.com/problems/minimum-cost-of-buying-candies-with-discount/description/) ",
    "url": "/Algorithm/ag_greedy.html",
    
    "relUrl": "/Algorithm/ag_greedy.html"
  },"8": {
    "doc": "해싱(Hashing)이란?",
    "title": "해싱(Hashing)이란?",
    "content": "# 해싱(**Hashing**)이란? 해싱(Hashing)은 **입력값에 수학적 알고리즘(해시 함수)을 적용하여 고정된 크기의 문자열을 출력**하는 과정 출력된 문자열은 무작위적으로 보이고 보통 16진수의 형식 입력값의 크기와 상관없이 해시라고 부르는 출력값은 항상 알고리즘에 정의된 고정 길이로 출력된다. 해싱은 주로 컴퓨터 과학에서 데이터 무결성, 효율적인 데이터 관리를 위해 사용된다. # 해싱의 구조 만약 어떤 회사의 직원이 100명이라면 직원들은 0에서 99까지의 아이디를 부여받는다. 탐색을 하려면 단순히 크기가 100인 배열을 만들면 된다. 자료를 저장하거나 탐색하려면 직원의 아이디를 키(배열의 인덱스)로 생각하고 단지 배열의 특정 요소를 일거나 쓰면 된다. 이런 연산의 시간 복잡도는 O(1)이다. 그러나 현실적으로는 탐색 키들이 문자열이거나 매우 큰 숫자이기 때문에 탐색 키를 직접 배열의 인덱스로 사용하기에는 무리가 있으므로 각 탐색 키를 작은 정수로 사상(mapping)시키는 어떤 함수가 필요하다. 해싱에서는 자료를 저장하는데 배열을 사용한다. ![Alt text](/Algorithm/image.png) # 해시함수 ![Alt text](/Algorithm/image-1.png) - 입력값 - 메시지라고 부름. 입력값으로는 다양한 길이와 형태의 데이터가 사용돼요. 단일 문자, 음악 파일, 메시지뿐만 아니라 복잡한 데이터 구조도 입력할 수 있다 - 해시함수 - 해시 함수는 입력값을 고정된 크기의 블록으로 나눈 다음에 수학적 연산을 적용해서 최종 해시를 출력해요. 해시 함수는 주어진 입력에 대해 항상 동일한 해시를 생성하고, 입력 데이터가 조금이라도 바뀌어도 출력값은 크게 달라집니다. - 좋은 해시 함수는 효율적이고 다른 입력이 동일한 해시를 생성하는 것을 거의 불가능하게 합니다. 이런 특성 때문에 해시를 데이터 비교 및 무결성에 안전하게 사용할 수 있어요. [해시 함수 예시] - **SHA (Secure Hash Algorithm)**: SHA-1 (구버전), SHA-256, SHA-3 등 다양한 길이의 해시를 제공하며, 보안용이나 블록체인에 주로 사용됩니다. - **MD5 (Message Digest Algorithm 5)**: 데이터 무결성 검사에 사용되지만, 보안이 중요한 용도로는 권장되지 않아요. - 출력값 - 해시 or 다이제스트라고 함 - 각 입력값에 고유한 출력값이 생성되기 때문에 지문과 비슷하다고 생각할 수 있음 - 출력값의 길이는 해시 함수에 따라 달라집니다. 예를 들어 SHA-256 해시 함수는 항상 265비트의 출력값을 생성한다. - 해싱은 암호화와 달리 출력값을 원본 입력값으로 복호화할 수 없어요. 출력값은 항상 고정된 길이의 문자열을 출력하기 때문에 입력 데이터가 손실돼요. 출력값과 해싱 함수를 안다고 해도 대응하는 입력값을 찾는 것은 어려워요. # 해시테이블 해시 테이블은 **연관 배열구조**를 이용하여 데이터를 Key와 Value로 저장하는 자료구조이다. 해시 테이블은 해시 함수를 사용하여 색인(index)을 버킷(bucket)이나 슬롯(slot)의 배열로 계산한다. # 장점 - 중복을 제거할 수 있다 - 데이터 캐싱, 보안에 주로 사용 - 배열의 인덱스로 접근하기 때문에 삽입,삭제등의 연산이 빠르다 # 단점 - 공간복잡도가 커진다 - 충돌이 발생할 수 있다. - 충돌이 발생할 경우 시간 복잡도는 O(n)에 가까워진다. - 순서가 있는 배열에는 어울리지 않음 ### 출처 --- https://docs.tosspayments.com/resources/glossary/hashing https://devlog-wjdrbs96.tistory.com/50 [https://velog.io/@hanif/자료구조-해시](https://velog.io/@hanif/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0-%ED%95%B4%EC%8B%9C) ",
    "url": "/Algorithm/ag_hashing.html",
    
    "relUrl": "/Algorithm/ag_hashing.html"
  },"9": {
    "doc": "힙(Heap)",
    "title": "힙(Heap)",
    "content": "# 힙(Heap) 힙은 완전 이진 트리의 일종으로, 부모 노드와 자식노드가 특정한 조건을 만족하는 자료구조를 말합니다. > 📢 완전 이진 트리 > > 부모 노드 밑에 자식 노드가 최대 2개까지 있을 수 있고, 마지막 레벨을 제외한 모든 레벨의 노드가 완전히 채워져 있는 트리 구조 ## 1. 힙의 특징 - 힙에서 부모는 최대 2개의 자식 노드를 갖습니다. - 힙은 가능한 가장 적은 공간을 차지합니다. 다음 레벨로 내려가기 전에 모든 노드(왼쪽/오른쪽 노드)가 다 채워집니다. - 같은 레벨에서는 왼쪽 자식이 언제나 먼저 채워집니다. - 형제 노드 사이에는 어느 관계도 존재하지 않는다. ## 2. 힙의 종류 ### 1) 최대 힙(Max-Heap) 각 부모 노드의 값이 자식 노드의 값보다 크거나 같은 완전 이진 트리입니다. 루트 노드에는 항상 최대값이 위치합니다. ### 2) 최소 힙 (Min-Heap) 각 부모 노드의 값이 자식 노드의 값보다 작거나 같은 완전 이진 트리입니다. 루트 노드는 항상 최소값이 위치합니다. ![Image](https://github.com/user-attachments/assets/4671475c-f531-4a03-a073-48e750fb9f7b) ## 3. 힙 구현 방법 - 힙은 보통 배열(Array)을 이용하여 구현합니다. - 아래 그림과 같이 `루트 노드(9)`는 배열의 첫번째 인덱스에 위치하게 됩니다. - 인덱스가 1부터 시작하는 배열의 경우, i 인텍스에 있는 노드의 왼쪽 자식 노드는 `2 * i` 인덱스에 위치하며, - 오른쪽 자식 노드는 `2 * i + 1` 인덱스에 위치하게됩니다. ![Image](https://github.com/user-attachments/assets/a679052f-89fd-40cd-86ca-16f5ffd365f4) > - 첫 번째 인덱스가 0인 배열을 사용하는 경우에 노드가 인덱스 i에 있을 때, > - 왼쪽 자식 노드는 인덱스 `2 * i + 1`에, 오른쪽 자식 노드는 인덱스 `2 * i + 2`에 위치합니다. > - 또한, 자식 노드의 부모 인덱스는 `(i - 1) / 2` (정수 나눗셈)로 계산할 수 있습니다. ### 4. 주요 연산 및 알고리즘 ### 1) 힙 삽입 (Insertion) ![Image](https://github.com/user-attachments/assets/1aec11d1-9601-4de8-af13-8d757693bf34) - **절차:** > 1. 새 요소를 `힙의 끝(배열의 마지막 위치)에 추가`합니다. > 2. 새 요소를 부모 노드와 비교하여, 힙 속성이 깨진 경우 서로 교환합니다. (예: 최대 힙에서 새 요소가 부모보다 큰 경우) > 3. 이 과정을 힙 속성이 만족될 때까지 반복합니다. - **시간 복잡도:** O(log n) ### 2) 힙 삭제 (Deletion) - 일반적으로 루트 노드 삭제 → 힙 자료구조는 최대값과 최소값을 이용하는 것이 목적이기 때문 ![Image](https://github.com/user-attachments/assets/a8646d8a-053d-40cc-9088-6164d4d5801d) ![Image](https://github.com/user-attachments/assets/91033c91-7a6c-4c91-8ee9-414036eea959) - **절차:** > 1. `루트 노드를 제거`합니다(최대 힙에서는 최대값, 최소 힙에서는 최소값) > 2. `힙의 마지막 요소`를 `루트로 이동`합니다. > 3. 이동한 요소를 자식 노드와 비교하여 힙 속성을 만족하지 않으면, 더 적절한 자식과 교환합니다. > 4. 이 과정을 힙 속성이 만족될 때까지 반복합니다. - **시간 복잡도:** O(log n) ## 5. 힙의 사용사례 힙은 데이터를 관리하는데 있어서 다양한 상황에서 유용하게 사용됩니다. 그 중 많이 사용하는 사례는 `우선 순위 큐(Priority Queue)`입니다. ### 우선순위 큐: 힙은 우선순위 큐(Priority Queue)를 구현하는 데 널리 사용됩니다. 삽입, 삭제, 최댓값/최솟값 검색 연산이 모두 효율적입니다. ## 참고 [힙 (최소 힙, 최대 힙)](https://velog.io/@jsbryan/%ED%9E%99-%EC%B5%9C%EC%86%8C-%ED%9E%99-%EC%B5%9C%EB%8C%80-%ED%9E%99) [자료구조 개념 이해하기 ‘힙과 힙 정렬 알고리즘’ | 요즘IT](https://yozm.wishket.com/magazine/detail/2312/) [[알고리즘] 힙(Heap) 자료구조](https://velog.io/@yeonjin1357/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98-%ED%9E%99Heap-%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0) [[알고리즘] 힙(Heap)](https://velog.io/@phobos90/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98-%ED%9E%99Heap) ",
    "url": "/Algorithm/ag_heap.html",
    
    "relUrl": "/Algorithm/ag_heap.html"
  },"10": {
    "doc": "힙(Heap)이란, 어떤 자료구조일까?",
    "title": "힙(Heap)이란, 어떤 자료구조일까?",
    "content": "## 힙(Heap)이란, 어떤 자료구조일까? 힙 정렬을 알아보기 전에, 힙이라는 자료구조에 알아보고자 한다. 만약 힙 자료구조에 대해 잘 알고 있다면, 이후의 [힙 정렬](#힙-정렬)부터 글을 읽어도 좋을 것 같다. 혹시라도 힙 자료구조에 대해 애매하게 알고 있다면 같이 확실하게 알아보자. ### 완전 이진 트리(Complete Binary Tree) 힙은 완전 이진 트리(Complete Binary Tree)의 일종인 자료구조다. 그래서 힙을 알기 위해서는 완전 이진 트리에 대해서도 알아야한다. 그럼 이진 탐색 트리란 뭘까? ![완전 이진 트리](/Algorithm/img/complete-binary-tree.png) _완전 이진 트리의 구조_ 완전 이진 트리(Complete Binary Tree) : 부모노드 밑에 자식 노드가 최대 2개까지 있을 수 있고, 마지막 레벨을 제외한 모든 레벨에 노드가 완전히 채워져 있는 트리구조 > 만약 트리를 모르거나, 이 완전 이진 트리의 설명으로 이해하기 어렵다면 트리를 먼저 공부하는 것을 권한다. ### 힙 속성 힙은 이러한 완전 이진 트리에 힙 속성을 가지는 구조인데, 그렇다면 힙 속성은 무엇일까? 힙 속성은 부모 노드와 자식 노드 간의 관계를 정의하는 규칙으로 2가지(최대힙, 최소힙) 종류가 있다. 이 2가지의 속성 중 하나만 만족하면 된다. #### 최대 힙(Max Heap) ![최대 힙](/Algorithm/img/max-heap.png) _최대 힙의 구조_ 최대 힙 : 부모 노드의 값은 항상 자식 노드 보다 **크거나 같아야**한다.(부모 노드 >= 자식 노드) : 그렇기 때문에 루트 노드에는 항상 가장 큰 값이 위치한다.(루트 노드 = 최대 값) #### 최소 힙(Min Heap) ![최소 힙](/Algorithm/img/min-heap.png) _최소 힙의 구조_ 최소 힙 : 부모 노드의 값이 자식 노드보다 **작거나 같아야**한다.(부모 노드 Heapity 연산 2. 힙 정렬 : 힙에서 최대 값이나 최소 값을 꺼내며 정렬 수행 각 과정에 대해 상세히 알아보자. ### build heap #### 완전 이진 트리로 구성 먼저 배열 데이터가 있을 때, 이를 힙 정렬로 정렬한다고 가정하자. 그러면 이 배열 데이터를 완전 이진 트리의 구조로 형태를 변경해야한다. **완전 이진 트리 규칙** 배열의 인덱스를 기준으로 부모-자식 관계를 정하는 규칙으로, 이를 통해 변경하면 된다. - 부모 노드의 인덱스: i-1 / 2 - 왼쪽 자식의 인덱스: 2*i + 1 - 오른쪽 자식의 인덱스: 2*i + 2 예시 데이터로 [4, 10, 3, 5, 1]의 데이터가 있다고 가정하자. ```text 배열 데이터 : [4, 10, 3, 5, 1] 배열 인덱스 : [0, 1, 2, 3, 4] // 이진트리 변환시 4 (인덱스 0) / \\ 10 3 (인덱스 1, 2) / \\ 5 1 (인덱스 3, 4) ``` 예를 들어, 10을 기준으로 - 부모 노드 접근시 1. 10의 인덱스 = 1 2. 부모 노드를 구하는 식: `i-1 / 2` -> 1-1/2 = 0 - 왼쪽 자식 노드 접근시 1. 10의 인덱스 = 1 2. 왼쪽 자식의 인덱스를 구하는 식 : `2*i + 1` -> 2*1 +1 = 3 - 오른쪽 자식 노드 접근시 1. 10의 인덱스 = 1 2. 오른쪽 자식의 인덱스를 구하는 식 : `2*i + 2` -> 2*1 +1 = 4 이런식으로 접근하면 된다. #### Heapify 위에서는 완전 이진 트리의 형식으로 변환만 한 것이라, 힙의 속성을 만족시키지 못하고 있다. 이럴 때 이제 Heapify 연산을 해보자. ```text 4 4 10 / \\ / \\ / \\ 10 3 -> 10 3 -> 4 3 / \\ / \\ / \\ 5 1 5 1 5 1 ``` 예시에서 최대 힙으로 만드는 과정을 같이 해보자. 1. **마지막 부모 노드**(=10)와 두 자식 노드를 비교한다. 3 은 자식이 없어 패스 -> 10은 이미 완벽한 상태라 패스 -> 4는 10보다 작으므로, 10이랑 교환 2. 부모모다 큰 자식이 있다면 교환한다. 만약, 최소 힙이라면, 부모모다 작은 자식이 있다면 교환한다. 3. 루트 노드까지 이 과정을 반복한다. > 이렇게 하면, **단 한번만 이 과정을 수행해도** 최대값 10이 루트 노드로 올라온다. > 주의할 점은 1번의 수행으로 최소값이나 최대값이 루트노드로 올라오는 것이지, **모든 값이 정렬 되는 것이 아니라는 점**이다. ### 힙 정렬 이렇게 구성된 힙에서 최대값이나 최소값인 루트노드의 값을 꺼내게 되고, 꺼내면서 또 Heapify 과정을 반복하게 됨으로써 정렬을 합니다. ",
    "url": "/Algorithm/ag_heap_sort.html",
    
    "relUrl": "/Algorithm/ag_heap_sort.html"
  },"11": {
    "doc": "구현(Implementation)",
    "title": "구현(Implementation)",
    "content": "## 구현(Implementation) ### 구현(Implementation)이란? 알고리즘을 작성할 때, 특정 알고리즘 개념이나 자료구조보다 **구현의 정확성**이 더 큰 비중을 차지하는 문제들이 있습니다. 이처럼 문제에서 요구하는 과정을 단계별로 **직접 코드로 옮기는 작업**을 중시하는 것을 구현 문제라 합니다. 예컨대, 시뮬레이션을 하듯 문제에서 제시한 규칙을 하나씩 적용해가며, 최종적으로 원하는 결과를 출력해야 하는 유형 등이 대표적입니다. ## 구현 문제의 특징 1. **알고리즘의 난이도보다는 꼼꼼함이 요구**됨 - 복잡한 알고리즘을 요구하지 않고, 주어진 로직을 그대로 따라가거나 시뮬레이션하는 형식이 많습니다. 2. **에지 케이스(Edge Case) 처리**가 중요 - 예상치 못한 입력이나 극단적인 범위에서의 동작을 제대로 처리하지 않으면 오답이 됩니다. 3. **다양한 자료구조나 언어 기능 사용** - 문자열 파싱, 배열 인덱스 처리, 조건문 등 다양하게 사용합니다. 4. **실수가 발생하기 쉬움** - 일반적으로 구현 문제는 조건이 복잡하게 구성되어 있기 때문에 실수가 많이 발생합니다. 또한 인덱스 범위, 조건 분기, 변수 초기화 실수 등 사소한 부분에서 오류가 날 가능성이 높으므로 디버깅 시간이 많이 소요됩니다. ## 구현 시 주의사항 1. **문제에서 요구하는 입출력 형식을 정확히 지키기** - \"공백 하나\" 또는 \"줄바꿈\" 하나 차이로 오답이 될 수 있습니다. 2. **에지 케이스를 고려한 충분한 테스트** - 최소/최대 범위의 입력, 빈 문자열 처리, 음수나 0이 포함될 때 등 평소에 놓치기 쉬운 케이스에 대한 검증이 필요합니다. 3. **코너 케이스에 대한 조건 처리** - 예를 들어, 반복문에서 인덱스가 -1이 되거나 배열 크기를 초과하는지, 문자열의 끝까지 도달했는지 등을 항상 점검합니다. 4. **변수 사용에서의 오탈자와 자료형 범위** - int/long과 같은 자료형 범위 부족, 혹은 중복된 변수명 등 기본적인 실수에 유의합니다. ## 구현 문제 예시 유형 ### 1. 시뮬레이션(Simulation) 유형 - 주어진 규칙에 따라 객체나 지점이 **어떻게 이동**하거나 **상태가 변화**하는지를 단계별로 직접 따라가며 구현합니다. - 예: 보드 게임 시뮬레이션, 로봇 명령 실행, 2D 격자에서의 이동 등 #### 간단 예시 (자바) ```java import java.util.Scanner; public class SimulationExample { public static void main(String[] args) { Scanner sc = new Scanner(System.in); // 1. 보드의 크기 입력 (예: n=5 -> 5x5 좌표) int n = sc.nextInt(); sc.nextLine(); // nextInt() 후의 줄바꿈 제거 // 2. 시작 위치 (문제 가정상 0,0에서 시작한다고 가정) int x = 0, y = 0; // 3. 이동 명령어 입력 (예: \"R R U D L\") String moves = sc.nextLine(); // 4. 이동 처리 // moves를 공백 기준으로 분리 -> R, L, U, D 각각에 맞춰 위치 변경 // 단, 보드를 벗어나는 경우 이동 무시 for (String move : moves.split(\" \")) { System.out.println(\"현재 move: \" + move + \", 이전 위치: (\" + x + \", \" + y + \")\"); switch(move) { case \"R\": // 오른쪽 이동 시 y를 +1, 단 y+1 = 0 이어야 유효 if (y - 1 >= 0) { y -= 1; } break; case \"U\": // 위로 이동 시 x를 -1, 단 x-1 >= 0 이어야 유효 if (x - 1 >= 0) { x -= 1; } break; case \"D\": // 아래로 이동 시 x를 +1, 단 x+1 [\"Hello\", \"World\", \"Program\"] String[] words = sentence.split(\" \"); // 중간 과정 출력: split으로 나눈 단어 배열 상태 System.out.println(\"split으로 나눈 단어 배열 상태: \"); for (int i = 0; i = 0; i--) { reversed[j++] = words[i]; } // 중간 과정 출력: 뒤집힌 단어 배열 상태 System.out.println(\"뒤집힌 단어 배열 상태: \"); for (int i = 0; i 구현(Implementation) 문제는 알고리즘적으로는 간단해 보이지만, **사소한 실수가 치명적**인 유형입니다. 입력을 파싱하고, 조건에 맞춰 로직을 단계별로 처리하고, 예외 상황까지 꼼꼼하게 챙기는 과정이 필수입니다. ## 참고 자료 1. [Baekjoon Online Judge](https://www.acmicpc.net/) (구현 문제 태그 참고) 2. [LeetCode](https://leetcode.com/) (String, Simulation 카테고리) ",
    "url": "/Algorithm/ag_implementation.html",
    
    "relUrl": "/Algorithm/ag_implementation.html"
  },"12": {
    "doc": "합병 정렬(Merge Sort)",
    "title": "합병 정렬(Merge Sort)",
    "content": "# 합병 정렬(Merge Sort) ## 합병정렬 `존 폰 노이만(John von Neumann)`이라는 사람이 제안한 방법으로 분할 정복 알고리즘 중 하나입니다. 기본 원리는 하나의 리스트를 두개의 균등한 크기로 분할하고, 분할된 부분 리스트를 정렬한 다음 두개의 정렬된 부분 리스트를 합하여 전체가 정렬된 리스트가 되게하는 방법입니다. ``` 분할 정복 - 문제를 작은 2개의 문제로 분리하고 각각을 해결한 다음, 결과를 모아서 문제를 해결하는 방법 - 대개 순환 호출을 이용하여 구현 ``` - 과정 설명 - 리스트의 길이가 0 또는 1이면 이미 정렬된 것으로 본다. - 그렇지 않은 경우 정렬되지 않은 리스트로 본다. - 정렬되지않은 리스트를 절반으로 잘라 비슷한 크기의 두 부분 리스트로 나눈다 - 각 부분 리스트를 재귀적으로 합병 정렬을 이용해 정렬한다. - 두 부분 리스트를 다시 하나의 정렬된 리스트로 합병한다. - 예시 ![image.png](https://github.com/user-attachments/assets/b6b0560d-2d88-4450-b896-88ef50caee9c) ![image.png](https://github.com/user-attachments/assets/9d52a065-0149-4286-8f85-387c10396e49) ## 합병정렬 알고리즘 - 합병 정렬은 크게 3단계로 이뤄집니다. - `분할(Divide)` - 정렬할 배열을 비슷한 크기의 두 부분 배열로 분할합니다. - 리스트를 더 이상 나눌 수 없는 단위(크기가 1인)리스트 까지 쪼개는 단계입니다. - `정복(Concuer)` - 분할된 각 부분(크기가 1인 리스트)이 정렬된 상태임을 전제로, 재귀적으로 정렬하는 과정을 포함하는 단계입니다. - 크기가 1인 리스트는 본질적으로 정렬된 상태이기 때문에, 이 단계에서는 별도의 정렬 작업 없이 바로 결합 단계로 넘어갑니다. - `결합(Combine)` - 분할과 정복을 통해 얻은 정렬된 부분 리스트들을 서로 병합하여 하나의 정렬된 리스트로 만드는 단계입니다. - 실제 정렬이 일어나는 부분이라고 볼 수 있습니다. ## 합병정렬 시간복잡도 합병 정렬의 시간복잡도는 최선, 평균, 최악 모두 `O(NlogN)`입니다. - 분할 단계 : 리스트를 반씩 나누므로 재귀 호출의 깊이는 약 log₂n이 됩니다. - 병합 단계 : 각 재귀 단계 마다 두 부분 리스트를 합치는 데 전체 원소 n에 대한 선형시간이 소요됩니다. - 두개의 정렬된 부분 배열에서 각 원소를 한번씩 비교하여 정렬된 순서로 합침 - 따라서 전체 시간복잡도는 O(n) × O(log n) = O(n log n)입니다. ![image.png](https://github.com/user-attachments/assets/8cebc734-a2d4-422d-948d-9dd2a30aef9e) ## 합병정렬 특징 - 장점 - 합병 정렬은 병합 과정에서 동일한 값의 순서를 보존함으로써 안정적인 정렬입니다. - 데이터의 분포에 영향을 덜 받습니다. 입력데이터가 어떻게 구성되어있든지 간에 log₂n이 보장됩니다. - 연결리스트(Linked List)로 구성하면, 링크 인덱스만 변경되므로 데이터 이동은 무시될 만큼 작아집니다. - 단점 - 데이터가 배열로 구성된 경우 추가적인 메모리 임시 배열이 필요합니다. - 배열 기반 합병 정렬에서는 데이터가 클 경우 반복적인 복사(이동)로 인한 오버헤드가 발생할 수 있습니다. ## 합병정렬 구현 ```java import java.util.Arrays; public class MergeSort { // 두 정렬된 배열(left와 right)을 병합하여 하나의 정렬된 배열을 반환하는 메서드 public static int[] merge(int[] left, int[] right) { int[] merged = new int[left.length + right.length]; // 병합 결과를 저장할 배열 int leftPointer = 0; // left 배열의 현재 인덱스 int rightPointer = 0; // right 배열의 현재 인덱스 int mergeIndex = 0; // merged 배열의 현재 인덱스 // 두 배열의 요소를 비교하여 작은 값부터 merged 배열에 추가 while (leftPointer right[rightPointer]) { merged[mergeIndex++] = right[rightPointer++]; } else { merged[mergeIndex++] = left[leftPointer++]; } } // left 배열에 남은 요소들을 merged 배열에 추가 while (leftPointer < left.length) { merged[mergeIndex++] = left[leftPointer++]; } // right 배열에 남은 요소들을 merged 배열에 추가 while (rightPointer < right.length) { merged[mergeIndex++] = right[rightPointer++]; } return merged; // 정렬된 병합 배열 반환 } // 합병 정렬(Merge Sort) 재귀 메서드 // 주어진 배열을 재귀적으로 반으로 나누고, 각 부분을 정렬 후 병합하여 전체 배열을 정렬 public static int[] mergeSort(int[] arr) { // 배열의 길이가 1 이하이면 이미 정렬된 상태이므로 그대로 반환 if (arr.length <= 1) { return arr; } // 배열을 두 부분으로 분할 int mid = arr.length / 2; int[] left = Arrays.copyOfRange(arr, 0, mid); // 왼쪽 부분 배열 int[] right = Arrays.copyOfRange(arr, mid, arr.length); // 오른쪽 부분 배열 // 재귀적으로 각각의 부분 배열을 정렬 left = mergeSort(left); right = mergeSort(right); // 정렬된 두 부분 배열을 병합하여 하나의 정렬된 배열로 반환 return merge(left, right); } // 메인 메서드: 합병 정렬을 테스트하는 용도 public static void main(String[] args) { int[] arr = {5, 4, 1, 9, 3, 7, 2, 6}; // 정렬할 배열 int[] sorted = mergeSort(arr); // 배열 정렬 수행 System.out.println(Arrays.toString(sorted)); // 정렬된 배열 출력 } } ``` ## 참고 자료 [알고리즘 합병정렬(Merge sort) 그림으로 쉽게 이해하기](https://rosweet-ai.tistory.com/52) [[알고리즘] 합병 정렬(merge sort)이란 - Heee's Development Blog](https://gmlwjd9405.github.io/2018/05/08/algorithm-merge-sort.html) [자료구조알고리즘-합병병합정렬](https://velog.io/@roro/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98-%ED%95%A9%EB%B3%91%EB%B3%91%ED%95%A9%EC%A0%95%EB%A0%AC) ",
    "url": "/Algorithm/ag_merge_sort.html",
    
    "relUrl": "/Algorithm/ag_merge_sort.html"
  },"13": {
    "doc": "순열 &amp; 조합",
    "title": "순열 &amp; 조합",
    "content": "# 순열 & 조합 ## 순열(Permutation) > 서로 다른 n개 중에서 r개를 뽑아 순서를 고려하여 정렬하는 경우의 수 > - 순서를 중요하게 생각함 → `[1, 2]`와 `[2, 1]`은 다른 경우로 취급 - 공식: ![permutation.png](https://github.com/user-attachments/assets/2af8c3f2-3545-4bf8-a486-fa54fefce0a4) - 예시 - `{1, 2, 3}`에서 2개를 뽑는 순열 → `(1,2), (1,3), (2,1), (2,3), (3,1), (3,2)` → 총 `6`가지 경우 - 구현 ```java public class Permutation { static int[] answer; // 선택된 숫자들을 저장할 배열 (순열 결과) static int r; // 순열으로 뽑을 숫자의 개수 (r) static int[] arr; // 순열의 대상이 되는 배열 (총 n개 중 선택) static int[] visited; // 각 숫자의 선택 여부를 표시합니다 (1: 선택됨, 0: 미선택) // index는 현재 순열에서 채울 위치(0부터 시작) private static void permutation(int index) { // 선택된 숫자의 개수가 r과 같으면 순열 완성 → 출력 후 종료 if (index == r) { for (int i = 0; i 서로 다른 n개 중에서 r개를 뽑아, 중복을 허용하고 순서를 고려하는 경우의 수 > - 같은 원소를 여러 번 선택할 수 있음 - 공식: ![repeatedPermutation.png](https://github.com/user-attachments/assets/d478d16c-e303-466e-af56-aaa9af2413e0) - 예시 - `{1, 2, 3}`에서 2개를 뽑는 중복 순열 → `(1,1), (1,2), (1,3), (2,1), (2,2), (2,3), (3,1), (3,2), (3,3)` → 총 `9`가지 경우 - 구현 - 순열에서 중복을 체크하는 부분을 삭제해주면 됨 ```java public class RepeatedPermutation { static int[] answer; // 선택된 숫자들을 저장할 배열 (순열 결과) static int r; // 순열으로 뽑을 숫자의 개수 (r) static int[] arr; // 순열의 대상이 되는 배열 (총 n개 중 선택) // 재귀적으로 순열(중복 허용)을 생성합니다. // index는 현재 선택할 위치를 나타냅니다. private static void permutation(int index) { // 현재까지 선택한 숫자의 개수가 n과 같으면, 출력 if (index == r) { for (int i = 0; i 서로 다른 n개 중에서 r개를 뽑아 순서를 고려하지 않는 경우의 수 > - 순서는 고려하지 않음 → `[1, 2]`와 `[2, 1]`은 같은 경우로 취급 - **공식**: ![combination.png](https://github.com/user-attachments/assets/87f5331b-5764-4c0d-8838-5501f308633a) - **예시** - `{1, 2, 3}`에서 2개를 뽑는 조합 → `{1,2}, {1,3}, {2,3}` → 총 `3`가지 경우 - 구현 ```java public class Combination { static int[] answer; // 선택된 숫자들을 저장할 배열 (조합 결과) static int r; // 조합으로 뽑을 숫자의 개수 (r) static int[] arr; // 조합의 대상이 되는 배열 (총 n개 중 선택) // combination 메서드: // start: 탐색 시작 인덱스 // size: 현재까지 선택된 숫자의 개수 private static void combination(int start, int size) { if (size == r) { // 완성된 조합을 출력 for (int i = 0; i 서로 다른 n개 중에서 r개를 뽑아, 중복을 허용하지만 순서를 고려하지 않는 경우의 수 > - 같은 원소를 여러 번 선택할 수 있음. - 공식: ![repeatedCombination.png](https://github.com/user-attachments/assets/e681b6ba-998c-4eb2-8e4b-361603c7985a) - 예시 - `{1, 2, 3}`에서 2개를 뽑는 중복 조합 → `(1,1), (1,2), (1,3), (2,2), (2,3), (3,3)` → 총 6가지 경우 - 구현 ```java public class RepeatedCombination { static int[] answer; // 선택된 숫자들을 저장할 배열 (조합 결과) static int r; // 조합으로 뽑을 숫자의 개수 (r) static int[] arr; // 조합의 대상이 되는 배열 (총 n개 중 선택) // start: 탐색 시작 인덱스 // size: 현재까지 선택된 숫자의 개수 private static void repeatedCombination(int start, int size) { if (size == r) { // 완성된 조합을 출력 for (int i = 0; i < r; i++) { System.out.print(answer[i] + \" \"); } System.out.println(); return; } // start 인덱스부터 배열의 끝까지 반복 // 중복 조합이므로, 동일한 원소를 다시 선택할 수 있도록 i를 start부터 시작 (즉, 인덱스의 중복 허용) for (int i = start; i < arr.length; i++) { answer[size] = arr[i]; repeatedCombination(i, size + 1); } } public static void main(String[] args) { arr = new int[]{1, 2, 3}; r = 2; answer = new int[r]; repeatedCombination(0,0); } } ``` ### 참고 [Permutation Algorithm(순열 알고리즘) & Combination Algorithm(조합 알고리즘)](https://rutgo-letsgo.tistory.com/entry/Permutation-Algorithm%EC%88%9C%EC%97%B4-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98-Combination-Algorithm%EC%A1%B0%ED%95%A9-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98) [[알고리즘] 순열과 조합](https://velog.io/@chancehee/%EC%88%9C%EC%97%B4%EA%B3%BC-%EC%A1%B0%ED%95%A9) ",
    "url": "/Algorithm/ag_permutation_combination.html",
    
    "relUrl": "/Algorithm/ag_permutation_combination.html"
  },"14": {
    "doc": "Quick Sort",
    "title": "Quick Sort",
    "content": "# Quick Sort - **분할 정복(divide-and-conquer)** 방식의 정렬 알고리즘의 일종. - 주어진 배열에서 **피벗(pivot)** 이라는 분할의 기준이 되는 요소를 선택하고, 이를 기준으로 배열을 두 개의 부분 배열(파티션) 로 나누어 정렬하는 방식으로 작동한다. ## 특징 - **시간 복잡도** : 평균적으로 O(n log n) 의 시간 복잡도를 가지지만(n 번 파티션을 나누고, 나눌때마다 탐색 범위가 절반이 되므로), 최악의 경우 O(n^2) (선택하는 모든 피벗이 가장 작은 값일 때) 이 될 수 있다. - **메모리 사용** : 퀵 정렬은 정렬을 할 때, 추가적인 메모리가 필요없는 **제자리(in-place)** 정렬로, 추가적인 메모리 사용이 최소화된다. ## 단계 ### 1. 피벗 선택 과 배열 분할 (분할) 배열에서 **임의의 요소**를 피벗으로 선택한다. 따라서, 피벗은 첫 번째 요소, 마지막 요소, 중간 요소, 또는 배열 내의 여러 요소 중 하나일 수 있다. ### 2. 정렬 (정복) 피벗을 기준으로 배열의 요소를 정렬한다. 피벗보다 작은 요소는 피벗의 왼쪽에, 큰 요소는 오른쪽에 위치하게 한다. 정렬하는 방식은 다음과 같다. - `left`(혹은 `start`), `right`(혹은 `end`) 포인트를 피벗과 비교한다. - `left` 가 가리키는 값이 피벗보다 작다면, 무시하고 포인터를 다음으로 이동한다. - `left` 가 가리키는 값이 크다면, `right` 포인터가 가리기키는 값과 피벗을 비교한다. - `right` 가 가리키는 값이 피벗보다 크다면, 무시하고 포인터를 다음으로 이동한다. - `right` 가 가리키는 값이 피벗보다 작다면, `left` 가 가리키는 값과 교체(swap) 한다. - `left` 와 `right` 가 엇갈린다면, 정렬을 멈춘다. ![](/Algorithm/img/ag_quick_sort_parti_1.png) ### 결합(Combine) 정렬된 부분 배열들을 하나의 배열에 합병한다. ```C # include # define MAX_SIZE 9 # define SWAP(x, y, temp) ( (temp)=(x), (x)=(y), (y)=(temp) ) // 1. 피벗을 기준으로 2개의 부분 리스트로 나눈다. // 2. 피벗보다 작은 값은 모두 왼쪽 부분 리스트로, 큰 값은 오른쪽 부분 리스트로 옮긴다. /* 2개의 비균등 배열 list[left...pivot-1]와 list[pivot+1...right]의 합병 과정 */ /* (실제로 숫자들이 정렬되는 과정) */ int partition(int list[], int left, int right){ int pivot, temp; int low, high; low = left; high = right + 1; pivot = list[left]; // 임의의 값을 피벗으로 선택(이 경우, 배열의 첫번째 요소를 피벗으로 선택.) /* low와 high가 교차할 때까지 반복(low = left && list[high] > pivot); // pivot 과 비교하여 값이 크거나 작은 시점. // 만약 low와 high가 교차하지 않았으면 list[low]를 list[high] 교환 if(low < high){ SWAP(list[low], list[high], temp); } } while (low < high); // low와 high가 교차했으면(엇갈렸다면)ㅣ 반복문을 빠져나와 list[left]와 list[high]를 교환 SWAP(list[left], list[high], temp); // 피벗의 위치인 high를 반환 return high; } // 퀵 정렬 void quick_sort(int list[], int left, int right){ if(left < right){ int pivot = partition(list, left, right); // 피벗의 위치 // 피벗은 제외한 2개의 부분 리스트를 대상으로 순환 호출 quick_sort(list, left, pivot - 1); // left 부터 피벗 바로 앞 정렬 quick_sort(list, pivot + 1, right); // 피벗 바로 뒤 부터 right 뒤 정렬 } } void main(){ int i; int n = MAX_SIZE; int list[n] = {5, 3, 8, 4, 9, 1, 6, 2, 7}; quick_sort(list, 0, n-1); } ``` # 출처 - [[알고리즘] 퀵 정렬(quick sort)이란](https://gmlwjd9405.github.io/2018/05/10/algorithm-quick-sort.html) - [[자료구조 알고리즘] 퀵정렬(Quicksort)에 대해 알아보고 자바로 구현하기](https://www.youtube.com/watch?v=7BDzle2n47c) ",
    "url": "/Algorithm/ag_quick_sort.html",
    
    "relUrl": "/Algorithm/ag_quick_sort.html"
  },"15": {
    "doc": "스택 &amp; 큐",
    "title": "스택 &amp; 큐",
    "content": "## **스택 & 큐** | **스택 (Stack)** | **큐 (Queue)** | --- | --- | --- | **구조** | LIFO (Last In, First Out) | FIFO (First In, First Out) | **시간복잡도** | `push()` → `O(1)`, `pop()` → `O(1)` | `enqueue()` → `O(1)`, `dequeue()` → `O(1)` | **사용** | 되돌리기(Undo), 백트래킹, 재귀 호출 대체 | 처리 순서가 중요한 경우, 탐색, 스케줄링 | **주요 알고리즘** | Monotonic Stack, 백트래킹, DFS | 슬라이딩 윈도우, BFS , 위상 정렬 | ## 스택 예제 ### **Monotonic Stack**: `O(N)` - 다음 큰 수 찾기 → 주식 가격 상승 분석, 온도 변화 예측 - 히스토그램에서 가장 큰 직사각형 **예제 - 다음 큰 수 찾기** **🚫 기존 방식 (브루트포스 O(N²))** - 모든 요소에 대해 오른쪽 숫자들과 비교해서 큰 수를 찾으면 O(N²) 걸림. ```java public int[] nextGreaterElement(int[] nums) { int[] result = new int[nums.length]; Arrays.fill(result, -1); for (int i = 0; i nums[i]) { result[i] = nums[j]; break; } } } return result; } ``` **문제점** 1. 모든 숫자 쌍을 비교해야 하므로 느림 **O(N²)** 2. 데이터가 커질수록 연산량이 많음 ```java public int[] nextGreaterElement(int[] nums) { Stack stack = new Stack(); int[] result = new int[nums.length]; Arrays.fill(result, -1); for (int i = 0; i deque = new LinkedList(); int[] result = new int[nums.length - k + 1]; int idx = 0; for (int i = 0; i = k - 1) result[idx++] = nums[deque.peekFirst()]; } return result; } ``` 👉 큐를 활용하면 1. 한 번만 스캔 (O(N)) 2. 불필요한 비교 제거 3. 윈도우가 이동할 때마다 새로 정렬 x → 시간 절약 https://upcurvewave.tistory.com/724 https://velog.io/@corone_hi/75.-Sliding-Window-Maximum ",
    "url": "/Algorithm/ag_stack_queue.html",
    
    "relUrl": "/Algorithm/ag_stack_queue.html"
  },"16": {
    "doc": "알고리즘",
    "title": "알고리즘",
    "content": "# 알고리즘 - 순열 & 조합 - 최대공약수 & 최소공배수 - 스택 & 큐 - 힙 - 해싱 - 분할 정복 - 정렬 - Quick Sort, Merge Sort, Heap Sort - DFS & BFS - 이분 탐색 - 그리디 - 구현 - DP - LIS, LCA - 다익스트라(Dijkstra) - 비트마스크 ",
    "url": "/Algorithm/readme_AG.html",
    
    "relUrl": "/Algorithm/readme_AG.html"
  },"17": {
    "doc": "알고리즘의 성능 분석: Big-O 표기법과 복잡도 이해하기",
    "title": "알고리즘의 성능 분석: Big-O 표기법과 복잡도 이해하기",
    "content": "# 알고리즘의 성능 분석: Big-O 표기법과 복잡도 이해하기 ## 목차 1. [개요](#개요) 2. [Big-O 표기법이란?](#big-o-표기법이란) 3. [시간 복잡도와 공간 복잡도](#시간-복잡도와-공간-복잡도) 4. [주요 Big-O 표기법 살펴보기](#주요-big-o-표기법-살펴보기) 5. [시간 복잡도 최적화 방법](#시간-복잡도-최적화-방법) ## 개요 알고리즘을 설계하고 구현할 때, 우리는 항상 그 알고리즘이 얼마나 효율적인지 고민합니다. 단순히 \"작동한다\"는 것을 넘어서, 얼마나 빠르게 실행되는지(시간 복잡도), 얼마나 많은 메모리를 사용하는지(공간 복잡도)를 이해하는 것이 중요합니다. 이러한 성능 분석을 위해 우리는 Big-O 표기법을 사용합니다. ## Big-O 표기법이란? Big-O 표기법은 알고리즘의 성능을 수학적으로 표현하는 방법입니다. 이는 입력 크기에 따른 알고리즘의 실행 시간이나 공간 요구사항의 상한선을 나타냅니다. ### Big-O 표기법의 특징 - **최악의 경우를 표현**: 알고리즘이 실행될 때 발생할 수 있는 최악의 시나리오를 기준으로 합니다. - **상수는 무시**: O(2n)과 O(n)은 같은 것으로 간주됩니다. - **지배적인 항만 고려**: O(n² + n)은 O(n²)으로 표현됩니다. ### 왜 Big-O를 사용하나? 1. **알고리즘 비교가 용이**: 서로 다른 알고리즘의 성능을 객관적으로 비교할 수 있습니다. 2. **확장성 예측**: 입력 크기가 증가할 때 성능이 어떻게 변화할지 예측할 수 있습니다. 3. **최적화 방향 제시**: 알고리즘의 병목 지점을 파악하고 개선할 수 있습니다. ## 시간 복잡도와 공간 복잡도 ### 시간 복잡도 (Time Complexity) 시간 복잡도는 알고리즘이 실행을 완료하는 데 필요한 연산 횟수를 나타냅니다. **특징:** - 입력 크기에 따른 실행 시간의 증가율을 측정 - 하드웨어의 성능과 무관한 객관적 지표 - 실제 러닝 타임이 아닌 연산 횟수를 기준으로 함 ### 공간 복잡도 (Space Complexity) 공간 복잡도는 알고리즘이 실행되는 동안 필요한 메모리 공간의 양을 나타냅니다. **특징:** - 입력 크기에 따른 메모리 사용량의 증가율을 측정 - 기본 공간(입력 데이터 저장 공간)과 부가 공간(연산을 위한 추가 공간)으로 구분 - 메모리 효율성을 평가하는 중요한 지표 ## 💡 주요 시간 복잡도 분석 ### 1. O(1) - 상수 시간 입력 크기와 관계없이 일정한 시간이 소요되는 알고리즘입니다. ```java public class ConstantTime { public int getFirst(int[] array) { return array[0]; // 배열의 크기와 관계없이 항상 같은 시간 소요 } public void swap(int[] array, int i, int j) { int temp = array[i]; array[i] = array[j]; array[j] = temp; } } ``` ### 2. O(log n) - 로그 시간 입력 크기가 2배로 증가할 때마다 한 단계씩 증가하는 알고리즘입니다. ```java public class LogarithmicTime { public int binarySearch(int[] array, int target) { int left = 0; int right = array.length - 1; while (left max) { max = array[i]; } } return max; } } ``` ### 4. O(n log n) - 선형 로그 시간 효율적인 정렬 알고리즘의 시간 복잡도입니다. ```java public class NLogNTime { public void mergeSort(int[] array, int left, int right) { if (left array[j + 1]) { // swap int temp = array[j]; array[j] = array[j + 1]; array[j + 1] = temp; } } } } } ``` ### 6. O(2ⁿ) - 지수 시간 재귀적으로 모든 경우의 수를 확인하는 알고리즘의 시간 복잡도입니다. ```java public class ExponentialTime { public int fibonacci(int n) { if (n arrayList = new ArrayList(); // 인덱스 접근 O(1) LinkedList linkedList = new LinkedList(); // 순차 접근 O(n) // ArrayList: 끝에 추가 O(1), 중간에 추가 O(n) arrayList.add(1); // O(1) arrayList.add(0, 2); // O(n) // LinkedList: 끝에 추가 O(1), 중간에 추가 O(1) (위치를 알고 있는 경우) linkedList.add(1); // O(1) linkedList.addFirst(2); // O(1) } } ``` ## 🎯 최적화 전략 ### 1. 분할 정복 (Divide and Conquer) 큰 문제를 작은 부분 문제로 나누어 해결하는 전략입니다. ```java public class DivideAndConquer { public int power(int x, int n) { if (n == 0) return 1; int half = power(x, n/2); if (n % 2 == 0) return half * half; else return half * half * x; } } ``` ### 2. 동적 프로그래밍 (Dynamic Programming) 중복 계산을 피하기 위해 결과를 저장하고 재사용하는 전략입니다. ```java public class DynamicProgramming { public int fibonacciDP(int n) { if (n <= 1) return n; int[] dp = new int[n + 1]; dp[0] = 0; dp[1] = 1; for (int i = 2; i <= n; i++) { dp[i] = dp[i-1] + dp[i-2]; } return dp[n]; } } ``` ## 📊 성능 최적화 팁 1. **적절한 자료구조 선택** - 검색이 빈번한 경우: HashSet/HashMap (O(1)) - 정렬이 필요한 경우: TreeSet/TreeMap (O(log n)) - 순차적 접근이 많은 경우: ArrayList (O(1)) 2. **알고리즘 선택 시 고려사항** - 입력 데이터의 크기 - 데이터의 특성 (정렬 여부, 중복 여부 등) - 메모리 제약 사항 - 실행 시간 요구사항 ## 시간 복잡도 최적화 방법 ### 1. 적절한 자료구조 선택 자료구조별 시간 복잡도를 고려하여 상황에 맞는 최적의 자료구조를 선택합니다: | 자료구조 | 접근 | 검색 | 삽입 | 삭제 |---------|------|------|------|------| 배열 | O(1) | O(n) | O(n) | O(n) | 연결 리스트 | O(n) | O(n) | O(1) | O(1) | 이진 검색 트리 | O(log n) | O(log n) | O(log n) | O(log n) | 해시 테이블 | O(1) | O(1) | O(1) | O(1) | ### 2. 알고리즘 최적화 기법 1. **분할 정복 (Divide and Conquer)** - 문제를 더 작은 하위 문제로 분할 - 각 하위 문제를 해결 - 결과를 합쳐 전체 문제 해결 2. **동적 프로그래밍 (Dynamic Programming)** - 중복 계산을 피하기 위한 메모이제이션 활용 - 하위 문제의 결과를 저장하고 재사용 3. **탐욕 알고리즘 (Greedy Algorithm)** - 각 단계에서 최적의 선택 - 지역적 최적해를 통해 전역적 최적해 도출 ### 결론 알고리즘의 성능을 이해하고 최적화하는 것은 소프트웨어 개발에서 매우 중요합니다. Big-O 표기법을 통해 알고리즘의 효율성을 객관적으로 평가하고, 이를 바탕으로 더 나은 해결책을 찾을 수 있습니다. 시간 복잡도와 공간 복잡도를 모두 고려하여 상황에 맞는 최적의 알고리즘을 선택하는 것이 중요합니다. ",
    "url": "/Data_Structure/ds_Time_Space%20Complexity.html",
    
    "relUrl": "/Data_Structure/ds_Time_Space%20Complexity.html"
  },"18": {
    "doc": "배열(Array)",
    "title": "배열(Array)",
    "content": "## 배열(Array) ### 배열이란? 배열은 같은 타입의 변수들로 이루어져 있고, 크기가 정해져 있으며, 인접한 메모리 위치에 있는 데이터를 모아놓은 집합입니다. *여기서 설명하는 배열은 '정적 배열'을 기준으로 합니다. ## 배열의 특징 - 고정된 크기: 정적 배열은 선언 시점에 크기가 확정되며, 실행 도중에 크기를 변경할 수 없습니다. - 인덱스를 이용한 빠른 접근: 메모리 주소가 연속적이기 때문에 `arr[k]`로 k번째 원소에 O(1) 시간에 접근 가능합니다. 이 때, 직접 접근이 가능하다는 것은 랜덤 접근으로 표현하기도 합니다. - 삽입/삭제의 비효율: 중간에 원소를 삽입하거나 삭제하려면, 뒤쪽에 위치한 원소를 전부 옮겨야 하기 때문에 O(n) 시간이 소요됩니다. ### 랜덤 접근과 순차적 접근 - 직접 접근 == 랜덤 접근 - 동일한 시간에 배열과 같은 순차적인 데이터가 있을 때, 임의의 인덱스에 해당하는 데이터에 접근할 수 있는 기능입니다. - 이와 반대인 순차적 접근은 데이터를 저장된 순서대로 검색해야 합니다. ### 배열과 연결 리스트의 비교 ![](/Data%20Structure/img/ds_array_vector_1.png) - 탐색 속도는 배열이 연결 리스트보다 빠르다. - 배열의 경우, 각 요소를 탐색하면 되지만 연결 리스트의 경우, 연결된 다음 요소에 따라 찾는 데에 시간이 더 오래 소요됩니다. - 추가 및 삭제는 연결 리스트가 배열보다 빠르다. - 배열은 모든 요소를 옮겨야 추가 또는 삭제가 가능하지만 연결 리스트의 경우 다음에 올 요소에 대해 가리키는 주소를 바꿔주면 되기 때문에 더 빠릅니다. ## 동적 배열(Dynamic Array - vector, ArrayList) ### 동적 배열이란? 동적으로 요소를 할당할 수 있는 자료구조입니다. 정적 자료구조인 배열의 단점을 보완하여 동적으로 배열의 사이즈를 조정할 수 있도록 한 자료구조입니다. ## 동적 배열의 특징 - 배열의 크기 변경: 요소를 배열처럼 연속적으로 저장하면서, 배열의 크기를 필요에 따라 확장 또는 축소할 수 있는 구조입니다. - 동작의 원리: 초기 용량을 정하고, 원소를 삽입하면서 현재 사용 크기가 한계에 도달하면 용량을 2배 등으로 늘려 새 배열을 할당한 후 기존 데이터를 복사한 뒤 새 배열로 교체합니다. ## 동적 배열의 예시 ### C++의 Vector ```C++ #include #include using namespace std; int main() { vector v; // 기본 생성 (용량 0 또는 최소 시작) v.push_back(10); // 동적 확장되어 10 삽입 v.push_back(20); cout list = new ArrayList(); list.add(10); list.add(20); System.out.println(list.get(0)); // 10 System.out.println(list.size()); // 2 } } ``` - 특징 - 내부적으로 Object[] 배열로 관리 - 원소가 추가될 때, 동적 활당(새 배열 할당 후 복사) - 인덱스 접근 가능, 일부 메서드(get(index) 등)가 O(1) - 임의 접근 O(1), 중간 삽입/삭제 O(n) ### 자바스크립트의 Array ``` javascript let arr = []; arr.push(10); // 동적으로 확장 arr.push(20); arr[2] = 30; // 인덱스로 추가 가능 console.log(arr); // [10, 20, 30] arr.pop(); // 맨 끝 원소 제거 console.log(arr); // [10, 20] ``` - 특징 - 일반 배열처럼 보이나 내부적으로는 동적 할당 구조를 가집니다. - 크기를 명시적으로 고정할 필요가 없고, `push()`, `pop()` 등을 사용하면 알아서 크기가 확장/축소됩니다. - 인덱스를 순차적으로 사용하는 경우에는 배열처럼 작동하며, 희소 배열(중간에 인덱스가 비는) 형태로도 동작 가능 ## 배열과 동적 배열 비교 | 항목 | 정적 배열 (Array) | 동적 배열 (Dynamic Array) |---------------------|---------------------------------------------|-----------------------------------------------------------| **크기 지정** | 고정적 (선언 시 크기 확정) | 자동 또는 프로그래머가 원하는 시점에 변경 | **메모리 구조** | 연속적 | 연속적 (단, 확장 시 재할당 후 복사) | **삽입/삭제 (맨 뒤)** | O(1) (여유 공간이 있어야 함) | 평균(Amortized) O(1) | **삽입/삭제 (중간)** | O(n) (원소들을 한 칸씩 밀거나 당겨야 함) | O(n) (배열 내부 이동 필요) | **랜덤 접근** | O(1) (인덱스로 직접 접근) | O(1) (인덱스로 직접 접근) | **예시 언어/클래스** | C/C++ 배열, Java 배열 등 | C++ `std::vector`, Java `ArrayList`, JavaScript `Array` | ## 참고 자료 1. 면접을 위한 CS 전공지식 노트, 주홍철 2. https://www.geeksforgeeks.org/array-data-structure-guide/ ",
    "url": "/Data_Structure/ds_array_vector.html",
    
    "relUrl": "/Data_Structure/ds_array_vector.html"
  },"19": {
    "doc": "이진 트리, 이진 탐색 트리",
    "title": "이진 트리, 이진 탐색 트리",
    "content": "# 이진 트리, 이진 탐색 트리 ## **이진 트리(Binary Tree)** 각 노드가 최대 **두 개의 자식 노드**를 가질 수 있는 계층적 자료구조로 두 개의 자식 노드는 왼쪽 자식과 오른쪽 자식으로 구분된다. - 같은 루트에 같은 자식노드 하나를 가지고 있어도 위치가 다르면 다른 트리가 된다. 1. **노드(Node)**: 데이터를 저장하는 기본 단위. 2. **루트(Root)**: 트리의 최상단 노드. 3. **자식 노드(Child)**: 특정 노드가 가리키는 다음 단계의 노드. 4. **부모 노드(Parent)**: 특정 노드를 가리키는 상위 노드. 5. **리프 노드(Leaf)**: 자식이 없는 끝 노드. 6. **서브트리(Subtree)**: 특정 노드를 루트로 하는 트리 구조. ```java class Node { int value; Node left, right; } ``` ### 트리의 종류 ![](/Data%20Structure/img/ds_binary_tree_1.png) - **정 이진 트리(Full Binary Tree)**: - 모든 노드가 0개 또는 2개의 자식 노드를 가지는 트리 - **완전 이진 트리(Complete Binary Tree)** - 마지막 레벨을 제외하고 모든 레벨이 완전히 채워져 있으며, 마지막 레벨의 노드는 왼쪽부터 순서대로 채워져 있다. - 어느 노드에 오른쪽 자식이 존재한다면 왼쪽 자식도 가지고 있어야 완전 이진 트리가 된다. - **포화 이진 트리(perfect binary tree)** - 모든 내부 노드가 두 개의 자식 노드를 가지며 모든 노드가 동일한 레벨의 트리 - **균형 이진 트리(Balanced Binary Tree)** - 높이 균형이 맞춰진 트리 ![](/Data%20Structure/img/ds_binary_tree_2.png) 이진 트리는 레벨 순(왼 → 오)으로 각 노드에 index를 붙여 1차원 배열로 표현할 수 있다. 중간에 자식 노드가 빈 트리는 배열 사이에 null 값이 들어간다. | 노드 위치 | index | --- | --- | 루트 노드 | **1** | 노드 i의 부모 | i/2 | 노드 i의 왼쪽 자식 | i * 2 | 노드 i의 오른쪽 자식 | i * 2 + 1 | ### 탐색 ![](/Data%20Structure/img/ds_binary_tree_3.png) **트리 탐색 방법** 1. **전위 탐색** (preorder) - 노드 - 왼쪽 서브트리 - 오른쪽 서브트리 - **A** → B → D → E → H → C → F → G → I 2. **중위 탐색** (inorder) - 왼쪽 서브트리 - 노드 - 오른쪽 서브트리 - D → B → E → H → **A** → F → C → G → I - 왼쪽 서브트리부터 탐색하기 때문에 루트인 A 노햣드는 중간에 방문하게 된다. 3. **후위 탐색** (postorder) - 왼쪽 서브트리 - 오른쪽 서브트리 - 노드 - D → H → E → B → F → I → G → C → **A** - 왼쪽과 오른쪽 서브 트리 모두 탐색 후 노드를 방문한다. 루트인 A 노드는 가장 마지막에 방문하게 된다. --- ## **이진 탐색 트리(Binary Search Tree, BST)** - 이진 트리의 일종으로, 빠른 탐색을 위한 규칙을 가지고 있다. - 왼쪽 서브트리의 모든 노드 값은 부모 노드의 값보다 작고, 오른쪽 서브트리의 모든 노드 값은 부모 노드의 값보다 크다. ![](/Data%20Structure/img/ds_binary_tree_4.png) - **활용** - 데이터베이스: 인덱스를 빠르게 탐색하기 위해 균형 트리를 활용. - 검색 엔진: 대규모 데이터 탐색에 이진 탐색 트리의 변형 사용. - 파일 시스템: 디렉토리 탐색에 계층적 구조 적용. ### 장점 - **탐색(Search)**: 특정 값을 빠르게 찾을 수 있다. - **범위 쿼리(Range Query)**: 특정 범위의 데이터를 효율적으로 조회 할 수 있다. - **정렬(Sorting)**: 중위 탐색를 통해 오름차순으로 정렬된 데이터를 가져올 수 있다. ### 트리의 균형이 맞지 않으면? 이진 탐색 트리에서 탐색, 삽입, 삭제 작업의 시간 복잡도는 트리의 깊이에 비례한다. - 완전 균형 트리에서는 모든 노드가 균등하게 분포하여 탐색 성능이 최적화된다. - 불균형 트리에서 한쪽으로만 노드가 치우치는 최악의 경우엔 사실상 연결 리스트처럼 변형될 수 있다. 시간 복잡도는 `O(N)`로, 노드 수에 선형적으로 비례한다. 불균형 문제를 해결하기 위해 개발된 **레드-블랙 트리, 2-3트리, b-트리** 등이 있다. ## 이진 탐색 VS 이진 탐색 트리 - 선형 스캔을 한번 진행하는 경우, 데이터가 변하지 않는 경우에는 이진 탐색이 나을 수 있다. - 데이터의 변동성이 큰 경우(예. 입사/퇴사)에 배열을 사용할 경우 정렬된 배열로 처리하려면 매번 배열을 갱신해야 하기 때문에 비용이 커질 수 있다. 이진 탐색 트리는 데이터 자체가 변경돼도 탐색 구조가 유지되기 때문에 효율적이다. | **특징** | **이진 트리** | **이진 탐색 트리** | --- | --- | --- | **구조** | 노드가 최대 2개의 자식을 가질 수 있음 | 이진 트리의 특수한 형태로, 정렬 규칙을 따름 | **데이터 정렬** | 정렬되지 않음 | 정렬된 형태 유지 (왼쪽 < 부모 < 오른쪽) | **탐색 속도** | 비효율적 (O(n)) | 효율적 (평균 O(log n), 최악 O(n)) | **삽입 규칙** | 규칙 없음 | 데이터 값에 따라 특정 위치에 삽입 | [읽고 나면 진짜 쉬워지는 자료 구조](https://www.yes24.com/product/goods/125403649) [https://cdragon.tistory.com/entry/자료구조-Tree-Binary-Tree트리-이진-트리](https://cdragon.tistory.com/entry/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0-Tree-Binary-Tree%ED%8A%B8%EB%A6%AC-%EC%9D%B4%EC%A7%84-%ED%8A%B8%EB%A6%AC) https://jh2021.tistory.com/34 ",
    "url": "/Data_Structure/ds_binary_tree.html",
    
    "relUrl": "/Data_Structure/ds_binary_tree.html"
  },"20": {
    "doc": "해싱, 해시 함수 란?",
    "title": "해싱, 해시 함수 란?",
    "content": "# 해싱, 해시 함수 란? **해시 함수** 은 **임의의 길이를 가진 키를 입력** 으로 받아, **고정된 길이의 값인 해시**(또는 다이제스트)로 변환하는 단방향 함수(혹은 알고리즘) 를 의미한다. **해싱** 은 **해시 함수를 통해 해시를 생성**하는 과정을 의미한다. ## 해시 함수의 특징 - **단방향성**. 입력 데이터 -> 해시 는 쉽지만, 해시 -> 입력데이터 로 역변환은 거의 불가능하다. - 단방향성으로 인해 **데이터의 무결성을 보장**하고, **보안** 용도로 활용 가능하게 한다. - 블록체인 - 비밀번호 저장 시 - Git - 디지털 서명 (SHA 알고리즘, MD5 등) - SHA-256 의 경우, 32비트 크기의 해시를 생성하는 해시 알고리즘이다. 즉, 항상 32개의 고정된 크기의 해시를 생성한다. ![](/Data%20Structure/img/ds_hash_table_sha.png) 출처 : 나 - **같은 입력 값에 대해 어떤 경우에도 동일한 출력 값이 보장**된다. # Hash Table (해시 테이블) - 해싱 을 통해 생성한 **해시(인덱스)** 와 **값** 으로 구성된 **연관 배열** 로 구성된 데이터 구조 > 연관 배열은 키 하나와 값 하나가 연관되어 있는 형태의 데이터 구조. 키를 통해 연관되는 값을 얻을 수 있다. 맵 혹은 딕셔너리 라고도 부른다. ![](/Data%20Structure/img/ds_hash_table_overview.png) 출처 : [Hash Tables, Hashing and Collision Handling](https://medium.com/codex/hash-tables-hashing-and-collision-handling-8e4629506572) ## 저장, 검색, 삭제 - 해쉬 테이블의 저장, 검색, 삭제의 평균 시간 복잡도는 모두 O(1)이다. 이는 데이터를 검색하기 위해 데이터를 모두 선회해야하는 선형 자료구조인 배열 혹은, 연결 리스트에 비해 **빠르다**. - 다만, 검색 및 삭제의 최악의 경우는 O(n) 이 될 수 있다. 이는 해시가 중복되어 테이블의 공간을 모두 찾는 경우이다. 후술할 해시가 중복되는 해시 충돌로 인해 발생할 수 있다. - 또한, 배열, 트리와 같은 데이터 구조는 삭제 혹은 저장하기위해 해당 데이터와 모든 데이터를 비교해보아야하지만, 해시 테이블은 해시만 알면되기때문에 이러한 **불필요한 과정이 생략된다.** # 해시 테이블의 해시 함수 해시 함수는 굉장히 다양하게 만들 수 있다. 해시 테이블에서 자주 사용하는 해시 함수의 형태는 다음과 같다. ``` h(x) = x mod n ``` `x` : 키 에 해당하며, 보통 정수 이다. `n` : 보통 저장소의 길이를 나타낸다. 예를 들어 10 의 길이를 가지고 있는 해시 테이블이라면, `n` 은 10 이된다. ## 좋은 해시 함수의 조건 - 계산이 간단해야한다. 계산이 복잡하다면, **데이터 접근 속도가 저하** 될 것이다. - 입력 키가 해시 테이블 전체에 **고루 저장** 되어, **해시 충돌을 최소화** 해야한다. # 해시 충돌 해시 함수가 서로 다른 두개의 입력(키) 값에 대해 같은 출력(해시) 값을 변환하는 상황. 다양한 해결방법들이 있지만, 어떤 해결방법이든 연산 비용이 증가하기에 해시 테이블을 설계하는 초기단계에서 해시 충돌을 최대한 일어나지않도록 하는 것이 중요하다. 예를 들어, 앞서 살펴본 해시 알고리즘인 SHA 는 SHA-0, SHA-1 까지 해시 충돌 가능성이 존재했지만, SHA-256 의 경우 사실상 해시 충돌 가능성이 0에 수렴한다. ![](/Data%20Structure/img/ds_hash_table_collision.png) 출처 : [[10분 테코톡] 👩‍🏫코니의 #️⃣Hash Function](https://www.youtube.com/watch?v=Rpbj6jMYKag) ``` h(x) = x mod 13 h(7) = 7 h(20) = 7 ``` ## 해결 방법 1 : 체이닝 (chaining) - 같은 해시로 해싱되는 데이터를 **모두 하나의 연결리스트로 연결하여 관리**. - 따라서, 데이터를 검색할 때는, 해당 연결 리스트의 데이터를 차례로 지나가며 검색하게 된다. - 하지만 이는, 해시 함수의 해시값만 알면 데이터를 바로 검색할 수 있다는 장점이 없어지는 부분. 체인이 길어지면 그만큼 해시 테이블에서는 생략되는 데이터를 대조하는 과정이 길어진다. ## 해결 방법 2 : 개방 주소 (open addressing) - 체이닝 과 달리, 어떻게든 **주어진 공간 내에서 해결**한다. - 따라서, 모든 데이터가 반드시 자신의 해시와 일치하는 공간에 저장된다는 보장이 없다. ### 선형 조사 - 가장 간단한 방법 - **충돌이 일어난 자리에서 일차함수 폭으로(바로 다음 자리 부터)** 찾는다. - 계속 찾다가 테이블의 경계를 넘어가면, 맨 앞으로 돌아간다. - 찾으려고 하는 위치가 멀수록 연산 횟수가 늘어난다. ### 이차원 조사 - **바로 다음 자리 부터가 아닌, 이차함수 폭**으로 찾는다. - 특정 영역에 데이터가 몰려도, 그 영역을 빨리 벗어날 수 있다. - 아래와 같은 경우, 이전에 지나왔던 경로를 모두 똑같이 지나와야 할 수 도 있다. ![](/Data%20Structure/img/ds_hash_table_quadra_problem.png) ![](/Data%20Structure/img/ds_hash_table_linear_probing.png) 출처 : [Linear Probing in Hashing](https://prepinsta.com/data-structures-and-algorithms-in-python/linear-probing-in-hashing/) ## 해결 방법 3 : 더블 해싱 (double hashing) - 두 개의 해시 함수를 사용한다. - **하나는 최초의 해시값을 얻을 때만, 나머지 하나는 해시 충돌이 일어났을 때 이동할 폭을 구하기 위해** 사용된다. - 첫번째 해시는 같더라도 두번째 해시함수로 구한 해시까지 같은 확률은 매우 작으므로 서로 다른 보폭으로 이동할 가능성이 크다. # 프로그래밍 언어 단계의 해시 테이블 과 연관 배열 구조(딕셔너리, 맵) - Python 의 `dict` 클래스 는 매우 최적화된 **해시 테이블** 로 구현되어있다. - JAVA 에서 `Dictionary` 클래스는 추상 클래스이며, `HashTable` 의 상위 클래스이다. - C# 의 `Dictionary` 클래스 또한, **해시 테이블** 기반으로 구현되어있다. - Javascript 의 Map 은 경우에 따라 해시 테이블로 구현될 수 있다. > _Map의 명세는 \"평균적으로 집합 내 요소의 수에 따라 하위 선형인 접근 시간을 제공하는\" 맵을 구현해야 한다고 기술되어 있습니다. 따라서 복잡성이 O(N)보다 더 나은 경우 내부적으로 해시 테이블(O(1) 룩업), 검색 트리(O(log(N)) 룩업) 또는 기타 데이터 구조로 표현될 수 있습니다._ https://developer.mozilla.org/ko/docs/Web/JavaScript/Reference/Global_Objects/Map - Golang 의 map 은 해시 테이블로 구현되어있다. 다양한 프로그래밍 언어에서 딕셔너리, 혹은 맵을 내부적으로는 해시 테이블로 구현하고 있음을 확인할 수 있다. 데이터 구조 단계에서는 딕셔너리의 부분집합 으로서 해시 테이블이 존재하지만, 실제로 사용하는 프로그래밍 언어 단계에서는 거의 같은 위계로 사용되고 있는 듯하다. # 가상 메모리 페이지 테이블 [가상 메모리의 페이지 테이블](https://github.com/Hi-Tech-Study/CS-Study/blob/main/OS/os_memory.md#%EC%9E%91%EB%8F%99-%EC%9B%90%EB%A6%AC) 에서도 해시 테이블을 사용할 수 있다. 이 경우, 키에 해당하는 논리 주소를 해싱 한다. 해시 함수를 어떻게 정의하냐에 따라 전체적인 페이지 테이블의 사이즈를 줄일 수 있다. # 출처 - [해싱과 암호화는 어떻게 다른가요?](https://docs.tosspayments.com/blog/hashing-and-encryption-difference#%ED%95%B4%EC%8B%B1%EA%B3%BC-%EC%95%94%ED%98%B8%ED%99%94%EB%8A%94-%EC%96%B4%EB%96%BB%EA%B2%8C-%EB%8B%A4%EB%A5%B8%EA%B0%80%EC%9A%94) - [[10분 테코톡] 👩‍🏫코니의 #️⃣Hash Function](https://www.youtube.com/watch?v=Rpbj6jMYKag) - [Basics of Hash Tables](https://www.hackerearth.com/practice/data-structures/hash-tables/basics-of-hash-tables/tutorial/) - [블록체인 해시함수 | 정의, 특징, 블록체인 활용 예시](https://www.codestates.com/blog/content/%EB%B8%94%EB%A1%9D%EC%B2%B4%EC%9D%B8-%ED%95%B4%EC%8B%9C%ED%95%A8%EC%88%98) - [Learn Hash Tables in 13 minutes #️⃣](https://www.youtube.com/watch?v=FsfRsGFHuv4) - [Hash Tables, Hashing and Collision Handling](https://medium.com/codex/hash-tables-hashing-and-collision-handling-8e4629506572) ",
    "url": "/Data_Structure/ds_hash_table.html",
    
    "relUrl": "/Data_Structure/ds_hash_table.html"
  },"21": {
    "doc": "힙(Heap)",
    "title": "힙(Heap)",
    "content": "## 힙(Heap) ### 힙이란? 힙은 완전 이진 트리 기반의 자료 구조이며, 최소힙과 최대힙이 있고 종류에 따라 특징을 가집니다. ## 힙의 특징 - Heapify: 힙 데이터 구조의 속성을 유지하기 위해 노드를 재배치하는 프로세스입니다. - 삭제 연산: 루트 노드가 삭제되고, 가장 마지막 노드를 루트로 옮긴 다음 Heapify를 호출하여 힙 속성을 유지합니다. - 삽입 연산: 가장 마지막 노드부터 루트 노드까지 Heapify를 호출하여 힙 속성을 유지합니다. - 완전 이진 트리: 모든 레벨이 완전하게 채워져 있어햐 하며, 마지막 레벨은 왼쪽부터 채워집니다. - 효율적인 연산: - 삽입/삭제: O(logN) - 최댓값/최솟값 조회: O(1) - 최소힙: 부모 노드의 값이 자식 노드보다 작거나 같음 - 최대힙: 부모 노드의 값이 자식 노드보다 크거나 같음 ### 힙의 삽입 1. 새 요소를 배열의 마지막에 추가합니다. 2. 부모와 비교하여 힙 속성을 유지하도록 상향 이동(Up-Heapify) 합니다. ![](/Data%20Structure/img/ds_heap_priority_queue_1.png) ### 힙의 삭제 1. 루트 노드(최댓값 또는 최솟값)를 제거합니다. 2. 배열의 마지막 요소를 루트로 이동합니다. 3. 자식과 비교하여 힙 속성을 유지하도록 하향 이동(Down-Heapify) 합니다. ![](/Data%20Structure/img/ds_heap_priority_queue_2.png) ### 힙의 구조 *인덱스가 1부터 시작하는 것으로 가정 - 자식 노드 구하기(i는 부모 노드의 인덱스) - 왼쪽 자식 노드: `2i` - 오른쪽 자식 노드: `2i + 1` - 부모 노드 구하기(i는 자식 노드의 인덱스) - 부모 노드: `i / 2` ![](/Data%20Structure/img/ds_heap_priority_queue_3.png) ## 힙의 장단점 ### 힙의 장점 | **장점** | **설명** |--------------------|-------------------------------------------------------------------------------------------------------------------| **시간 효율성** | 힙은 요소 삽입 및 삭제에 대해 평균적으로 O(log n)의 시간 복잡도를 가지며, 배열을 힙으로 변환하는 데는 O(n)의 시간이 소요됩니다. 가장 중요한 점은 최소값 또는 최대값을 O(1) 시간에 가져올 수 있다는 점입니다. | **공간 효율성** | 힙은 완전 이진 트리이므로 배열에 공간 낭비 없이 저장할 수 있습니다. | **동적 크기 조정** | 힙은 요소가 삽입되거나 삭제됨에 따라 동적으로 크기를 조정할 수 있어, 실시간 요소 추가/삭제가 필요한 동적 애플리케이션에 적합합니다. | **우선순위 기반** | 힙은 요소를 우선순위에 따라 처리할 수 있어, 실시간 애플리케이션(부하 분산, 의료 애플리케이션, 주식 시장 분석 등)에 적합합니다. | **제자리 정렬** | 힙의 대부분의 응용은 요소를 제자리에서 재배치합니다. 예를 들어, **힙 정렬(HeapSort)**은 추가적인 메모리 사용 없이 요소를 정렬합니다. | ### 힙의 단점 | **단점** | **설명** |--------------------|-------------------------------------------------------------------------------------------------------------| **유연성 부족** | 힙은 특정 요소의 순서를 유지하도록 설계되었기 때문에, 더 유연한 데이터 구조가 필요한 애플리케이션에는 적합하지 않을 수 있습니다. | **검색에 비효율적** | 힙은 최상위 요소에 효율적으로 접근할 수 있지만, 특정 요소를 검색하려면 트리 전체를 순회해야 하며, 이는 O(n)의 시간 복잡도를 가집니다. | **안정성 부족** | 힙은 안정적이지 않은 데이터 구조로, 동일한 값을 가진 요소들의 상대적인 순서가 힙이 구성되거나 수정될 때 보장되지 않습니다. | **복잡성** | 힙은 삽입, 삭제, 우선순위 큐 구현에는 효율적이지만, 최악의 경우 시간 복잡도가 O(n log n)이 될 수 있어, 더 빠른 알고리즘이 요구되는 애플리케이션에는 최적이 아닐 수 있습니다. | ## 우선순위 큐(Priority Queue) ### 우선순위 큐란? 각 요소가 우선순위를 가지며, 우선순위가 높은 요소가 먼저 처리되는 자료구조입니다. 일반적으로 힙을 사용하여 구현합니다. ## 우선순위 큐의 특징 - 우선순위 기반 처리: 각 요소는 우선순위를 가지며, 우선순위가 높은 요소가 먼저 처리됩니다. - 동적 크기 조정: 요소의 삽입과 삭제에 따라 크기가 동적으로 변합니다. - 다양한 구현 방법: 배열, 연결 리스트, 힙(Heap) 등을 사용하여 구현할 수 있습니다. ## 우선순위 큐의 구현 방법 - 배열(Array) 또는 연결 리스트(Linked List): - 정렬되지 않은(Unsorted) 경우: - 삽입(Insertion): O(1) - 삭제(Deletion): O(n) 최대 또는 최소 우선순위 요소를 찾기 위해 전체를 탐색해야 함 - 정렬된(Sorted) 경우: - 삽입(Insertion): O(n) 적절한 위치에 삽입 - 삭제(Deletion): O(1) 가장 앞이나 뒤에서 제거 - 힙(Heap): - 삽입(Insertion): O(log n) - 삭제(Deletion): O(log n) - 힙을 사용하면 우선순위 큐를 효율적으로 구현할 수 있습니다. ## 참고 자료 1. 면접을 위한 CS 전공지식 노트, 주홍철 2. https://www.geeksforgeeks.org/introduction-to-heap/ 3. https://www.geeksforgeeks.org/priority-queue-set-1-introduction/?ref=header_outind ",
    "url": "/Data_Structure/ds_heap_priority_queue.html",
    
    "relUrl": "/Data_Structure/ds_heap_priority_queue.html"
  },"22": {
    "doc": "연결 리스트 (Linked List)",
    "title": "연결 리스트 (Linked List)",
    "content": "# 연결 리스트 (Linked List) # 선형 데이터 구조 - 데이터 와, 그 뒤의 데이터는 1:1 관계이다. 즉 1개의 데이터 뒤에는 1개의 데이터만 존재한다. - 리스트의 끝, 혹은 특정 데이터에 도달하려면 리스트의 모든 항목을 순차적으로 거쳐야 한다. - 반면, 비선형 데이터 구조에서는 항목들이 순서대로 배열될 필요가 없어 비순차적으로 데이터 구조를 순회할 수 있다. # 동적 데이터 구조 동적 데이터 구조는 메모리에서 축소되거나 확장될 수 있다. 존재하기 위해 정해진 양의 메모리가 할당될 필요가 없으며, 크기와 모양이 변할 수 있고 필요한 메모리의 양도 변할 수 있다. # 구성 요소 연결 리스트는 일련의 노드로 구성된다. 단순히 말해, 그저 노드들의 모음이라고 볼 수 있다. 데이터와, 그 다음 데이터를 가리키는 포인터로 이루어져 있다. `헤드` : 연결 리스트의 시작점으로써, 첫 번째 노드에 대한 참조이다. 거의 모든 연결 리스트에는 `헤드` 가 있어야 한다. 이는 실질적으로 리스트와 모든 요소에 대한 유일한 진입점이기 때문. `노드` : `헤드` 와 마지막 노드를 제외한 노드들로써, 데이터와 그 다음 데이터를 가리키는 포인터로 이루어져있다. `마지막 노드` : 노드가 아니라 null 또는 빈 값을 가리키는 노드입니다. ## 노드 의 작동 방식 _**노드는 자신이 포함하는 데이터와, 그 다음 노드가 누구인지만 알고 있다.**_ 연결 리스트가 연속적인 메모리 블록에 할당될 필요가 없는 이유를 설명한다. 노드는 다음 노드에 대한 참조인 포인터를 가지고 있기 때문에, 물리적으로 붙어있을 필요없이 떨어져 있을 수 있는 것이다. ![](/Data%20Structure/img/datastructure_linkedlist_party.png) # 구성 방식 ## 단일 연결 리스트 한 방향으로만 진행되는 기본적인 형태의 연결 리스트를 의미한다. 헤드에서 출발하여 마지막 노드 까지 한 방향으로만 진행한다. ## 이중 연결 리스트 이전 노드에 대한 참조 포인터를 가져, 두 방향으로 진행될 수 있는 연결 리스트를 의미한다. 따라서 노드는 다음 노드, 이전 노드 에 대한 포인터를 가진다. 이는 데이터 구조를 한가지 방향이 아닌 반대로도 순회할 수 있게 하고자 할 때 유용할 수 있다. 예를 들어, 리스트의 현재 노드 에서, 3개 전의 노드로 이동하고 싶을 때, 이중 연결 리스트를 사용하면 맨 처음으로 돌아가지 않고도 이동할 수 있다. ## 원형 연결 리스트 마지막 노드가 null 값을 가리키며 끝나지 않고, 헤드가 가리키는 노드를 가리키는 형태의 연결 리스트를 의미한다. 여기서 마지막 노드를 tail 이라고도 부른기도 한다. 이중 연결리스트와 마찬가지로 하나의 노드에서 다른 모든 노드로의 접근이 가능하다. 노드의 삽입, 삭제가 단순 / 이중 연결 리스트 보다 용이하다. ![](/Data%20Structure/img/datastructure_category.png) # 배열 과의 유사성과 차이점 ## 데이터 순서화 방식 배열 또한 선형 데이터 구조를 사용하기에, 데이터를 순차적으로 거쳐야하는 점에서 배열과 연결 리스트는 **유사** 하다고 볼 수 있다. ## 메모리 관리 배열과 연결 리스트의 가장 **큰 차이점은 기계 수준에서 메모리를 사용하는 방식**이다. ### 배열의 메모리 관리 예를 들어, 7개의 문자를 각각 배열과 연결 리스트에 저장해야 한다고 치자. 그렇다면 7바이트의 메모리를 저장할 공간이 필요할 것이다. 배열은 모든 7바이트의 메모리가 연속된 블록에 있어야 한다. 즉, 컴퓨터는 한 곳에, 서로 옆에 붙어있는 상태의 7바이트의 메모리를 찾아야 한다. 이러한 특성은, index 로 특정 데이터에 접근할 수 있다는 점에서 데이터에 접근하고 조회하는 속도가 빠르다는 장점이 있다. 하지만 마찬가지로 이러한 특성 때문에, 데이터를 중간에 삽입 혹은 삭제할 때 단점이 된다. 연속적인 블록의 구조를 갖춰야하기에, 중간에 데이터가 삽입 혹은 삭제되면 그만큼 데이터를 이동해야하기 때문이다. ### 연결 리스트의 메모리 관리 반면에 연결 리스트가 생성될 때는 7바이트의 메모리가 한 곳에 있을 필요가 없다. 한 바이트는 어딘가에 있고, 다음 바이트는 메모리의 완전히 다른 곳에 저장될 수 있다. 각 노드는 다음 노드에 대한 정보들 밖에 없기 때문에, 특정 데이터에 접근하려면 모두 순회해야하기에 배열보다 시간이 오래걸린다는 단점이 있다. 반대로 데이터를 삽입 혹은 삭제할때 배열과 같이 연속적인 블록 형태를 유지할 필요가 없기에, 유연하게 가능하다. ## 메모리 할당 방식 배열은 정적, 연결 리스트는 동적 데이터 구조를 가진다. 정적 데이터 구조는 구조가 생성될 때 크기와 메모리 양을 정한다. 따라서 구조의 크기가 커지거나 작아지고 요소가 추가되거나 제거되더라도 항상 주어진 크기와 메모리 양이 필요하게 된다. 만약, 정적 데이터 구조에 더 많은 요소를 추가해야 하는데 메모리가 충분하지 않다면, 데이터를 복사하고 더 많은 메모리로 재생성하여 요소를 추가해야 한다. 반면 동적 데이터 구조는 앞서 살펴봤듯, 구조가 생성될때 크기와 메모리 양을 정할 필요 없다. 따라서 더 많은 요소를 추가하거나 제거하더라도, 메모리는 축소 혹은 확장될 수 있다. ![](/Data%20Structure/img/datastructure_memory_allocation.png) # 가상 메모리 구현 일부 운영체제에서는 가상 메모리 의 프레임을 관리할때, 연결 리스트를 사용하기도 한다. 가상 메모리 시스템에서는 프레임에 대한 할당과 삭제가 빈번하기 일어나기에, 구조 중간의 데이터를 삽입 및 삭제에 용이한 연결 리스트를 사용한다. ![alt text](/Data%20Structure/img/datastructure_vm.png) # 출처 - [What’s a Linked List, Anyway? [Part 1]](https://medium.com/basecs/whats-a-linked-list-anyway-part-1-d8b7e6508b9d) ",
    "url": "/Data_Structure/ds_linked_list.html",
    
    "relUrl": "/Data_Structure/ds_linked_list.html"
  },"23": {
    "doc": "Map",
    "title": "Map",
    "content": "# Map - 키 하나 - 값 하나 연관되어 있는 형태의 데이터 구조. - 키를 통해 연관되는 값을 얻을 수 있다. - 연관 배열, 딕셔너리 이라고도 부른다. ![](/Data%20Structure/img/ds_map.png) # 필요성 - 키를 통해 연관되는 값을 바로 조회할 수 있는 구조 특성상, O(1) 의 시간복잡도 의 **빠른 시간으로 조회**를 할 수 있다. 저장, 삭제 또한 평균적으로 O(1) 또는 O(log n) 의 시간복잡도 로 가능하다. - 키가 문자, 숫자, 객체 등 어떠한 값도 될 수 있기에, **유연한 데이터 관리**가 가능하다. # 특징 - 기본적으로 **키 는 유일**해야 하며, **값 은 중복**될 수 있다. - 중복된 키에 값이 쓰일 경우, 일반적으로 덮어씌워진다. - 키의 데이터 타입 은 어떠한 것이든 될 수 있으나, 하나의 맵 내에서는 일관되어야 한다. - Python 의 `Dictionary` 는 여러 타입의 키를 가질 수 있지만, 권장되지 않는다. - 순서가 없으며, 정렬되어있지 않다. # 정렬된 (Ordered) / 정렬되지 않은 (Unordered) 맵 - 정렬되지 않은 맵 - **일반적인 맵의 형태** 이다.키-값 쌍의 순서를 유지하지 않는다. 따라서 맵을 순회할 때 요소가 반환되는 순서는 보장되지 않으며, 실행마다 다를 수 있다. - 조회 속도는 평균 O(1) - 일반적으로 해시 테이블(Hash Table) 을 사용하여 구현된다. - 정렬된 맵 - **키-값 쌍이 삽입된 순서를 유지**한다. 따라서 맵을 순회(iterate)하면 삽입된 순서대로 요소가 반환된다. - 일반적으로 자가 균형 이진 탐색 트리(예: 레드-블랙 트리) 를 사용하여 구현된다. - - 조회 속도는 O(log n) - **요소의 순서가 중요한 경우라면 적합**할 수 있다. (e.g. 이벤트 로그 를 저장하는 경우) ## 정렬된 맵이 정렬되지 않은 맵보다 조회 속도가 느린 이유 - 보통 구현하는 방식에 의해 발생한다. 정렬된 맵은 보통 자가 균형 이진 탐색 트리를 사용 하여 구현하기 때문에, 트리 구조를 따라 조회해야하는 것이 그 이유. - 따라서, 키를 알면 값을 알 수 있는 일반적인 맵의 장점은 정렬된 맵에는 적용되지 않는 다고 볼 수 있다. # 프로그래밍 언어 에서의 맵 ## C++ - `std::map` : 정렬된 맵 - `std:unordered_map` : 정렬되지 않은 맵 ## Java - `HashMap` : Java 에서 가장 일반적으로 사용되는 맵 구현체. Hash Table 을 통해 구현한다. 스레드 세이프 하지않아 추가적인 동기화 작업이 필요하다. - `ConcurrentHashMap`: 여러 스레드에서 동시에 접근할 수 있도록 설계된 스레드 안전한 맵 구현체 이다. 외부 동기화 없이도 동시 접근이 가능하여, 멀티스레드 환경에서 사용하기 적합하다. - `TreeMap` : 정렬된 맵. ### Hashmap, Hashtable - 데이터 구조 단계에서 둘은 동일하지만, Java 에서 구현체로 사용될때 동기화를 지원하느냐, 하지않느냐 의 차이점을 가진다. - 따라서, Hashmap 은 스레드 세이프 하지않고, HashTable 은 스레드 세이프 하다. - HashMap 은 보조해시를 사용하기 때문에 보조 해시 함수를 사용하지 않는 Hashtable 에 비하여 해시 충돌이 덜 발생할 수 있어 상대적으로 성능상 이점이 있다. ## Python - `dict` : Python 의 가장 기본적인 맵 구현체. 정렬되지 않은 맵. - `collections.defaultdict`: 존재하지 않는 키에 대해 기본값을 지정할 수 있는 dict의 확장형이다. 존재하지 않는 키에 접근하면 KeyError가 발생하는 대신 기본값이 반환된다. - `collections.OrderedDict`: 정렬된 맵. # 출처 - [Hashmap vs. Hash Table: Understanding the Differences](https://ethans.co.in/blogs/hashmap-vs-hash-table-understanding-the-differences/#:~:text=The%20main%20difference%20between%20HashMaps,is%20a%20key%2Dvalue%20pair.) - [Introduction to Map – Data Structure and Algorithm Tutorials ](https://www.geeksforgeeks.org/introduction-to-map-data-structure/) ",
    "url": "/Data_Structure/ds_map.html",
    
    "relUrl": "/Data_Structure/ds_map.html"
  },"24": {
    "doc": "Set",
    "title": "Set",
    "content": "## Set ### Set이란? Set(집합)은 중복을 허용하지 않는 요소들의 모음으로, 특정 요소의 존재 여부를 빠르게 확인할 수 있는 자료구조입니다. 일반적으로 해시 기반으로 구현되어 있으며, 수학적인 집합 연산(합집합, 교집합, 차집합 등)을 효율적으로 수행할 수 있습니다. 대표적인 Set 자료구조로는 다음과 같은 것들이 있습니다. - HashSet (해시 집합): 해시 테이블을 사용하여 요소를 저장하는 방식 (Java의 HashSet, Python의 set) - TreeSet (트리 집합): 이진 탐색 트리를 사용하여 요소를 저장하는 방식 (Java의 TreeSet, C++의 std::set) - LinkedHashSet (연결 리스트 기반 집합): 요소의 삽입 순서를 유지하는 집합 (Java의 LinkedHashSet) ## Set의 장단점 ### ✅ 장점 - 중복 없는 데이터 관리 - Set은 기본적으로 중복을 허용하지 않기 때문에, 중복 요소를 자동으로 제거하는 용도로 활용할 수 있습니다. - 빠른 탐색 성능 - 해시 기반의 Set(HashSet)을 사용하면 평균적으로 O(1)의 시간 복잡도로 요소를 검색할 수 있습니다. - 트리 기반의 Set(TreeSet)을 사용하면 O(log n)의 시간 복잡도로 탐색이 가능합니다. - 집합 연산 지원 - 합집합, 교집합, 차집합 등 수학적인 집합 연산을 효과적으로 수행할 수 있습니다. ### ❌ 단점 - 인덱스를 이용한 접근 불가 - 리스트(List)와 달리 특정 인덱스의 요소에 직접 접근할 수 없습니다. 정렬이 필요한 경우 추가 비용 발생 - HashSet은 내부적으로 정렬되지 않으며, TreeSet과 같은 정렬된 Set을 사용해야 하지만, 삽입/삭제 시 O(log n)의 추가 비용이 발생합니다. 메모리 사용량 증가 - 해시 기반 Set(HashSet)은 내부적으로 해시 테이블을 사용하므로, 같은 데이터를 리스트(List)에 저장하는 것보다 더 많은 메모리를 사용합니다. ### Set의 활용 사례 1. 중복 제거 - 배열이나 리스트에서 중복된 값을 제거할 때 Set을 활용하면 간단하게 해결할 수 있습니다. ```java import java.util.HashSet; public class SetExample { public static void main(String[] args) { int[] numbers = {1, 2, 3, 4, 3, 2, 1, 5}; HashSet uniqueNumbers = new HashSet(); for (int num : numbers) { uniqueNumbers.add(num); } System.out.println(uniqueNumbers); // [1, 2, 3, 4, 5] } } ``` 2. 빠른 포함 여부 검사 ```java import java.util.HashSet; public class MembershipCheck { public static void main(String[] args) { HashSet dictionary = new HashSet(); dictionary.add(\"apple\"); dictionary.add(\"banana\"); dictionary.add(\"cherry\"); System.out.println(dictionary.contains(\"banana\")); // true System.out.println(dictionary.contains(\"grape\")); // false } } ``` - 특정 요소가 존재하는지 확인하는 contains() 메서드는 O(1)의 성능을 보이며, 리스트(List)의 contains() (O(n))보다 훨씬 빠릅니다. 3. 집합 연산 (합집합, 교집합, 차집합) ```java import java.util.HashSet; public class SetOperations { public static void main(String[] args) { HashSet setA = new HashSet(); HashSet setB = new HashSet(); setA.add(1); setA.add(2); setA.add(3); setB.add(2); setB.add(3); setB.add(4); // 합집합 (Union) HashSet union = new HashSet(setA); union.addAll(setB); System.out.println(\"합집합: \" + union); // [1, 2, 3, 4] // 교집합 (Intersection) HashSet intersection = new HashSet(setA); intersection.retainAll(setB); System.out.println(\"교집합: \" + intersection); // [2, 3] // 차집합 (Difference) HashSet difference = new HashSet(setA); difference.removeAll(setB); System.out.println(\"차집합: \" + difference); // [1] } } ``` - 두 개의 Set을 이용해 간단하게 합집합, 교집합, 차집합 연산을 수행할 수 있습니다. 4. 로그 분석 (중복된 IP 제거) - 서버 로그에서 중복된 IP 주소를 제거하여 고유 방문자 수를 구할 때 Set을 사용할 수 있습니다. ## 자료구조로서의 성능 | 연산 | HashSet (해시 테이블 기반) | TreeSet (이진 탐색 트리 기반) |----------------|-------------------------|--------------------------| **삽입 (Insertion)** | 평균 O(1), 최악 O(n) | O(log n) | **삭제 (Deletion)** | 평균 O(1), 최악 O(n) | O(log n) | **검색 (Search)** | 평균 O(1), 최악 O(n) | O(log n) | **정렬 유지 여부** | ❌ (정렬되지 않음) | ✅ (자동 정렬) | - HashSet은 내부적으로 해시 테이블을 사용하여 O(1)의 빠른 탐색 성능을 제공하지만, 해시 충돌이 발생할 경우 O(n)까지 성능이 저하될 수 있습니다. - TreeSet은 이진 탐색 트리를 사용하여 자동 정렬되며 O(log n)의 성능을 유지하지만, 해시 기반 Set보다 삽입/삭제가 느립니다. ### ✔ 어떤 Set을 선택해야 할까? - 순서가 중요하지 않고 빠른 탐색이 필요할 때 → HashSet - 정렬이 필요한 경우 → TreeSet - 삽입 순서를 유지해야 할 때 → LinkedHashSet ",
    "url": "/Data_Structure/ds_set.html",
    
    "relUrl": "/Data_Structure/ds_set.html"
  },"25": {
    "doc": "스택 &amp; 큐",
    "title": "스택 &amp; 큐",
    "content": "# 스택 & 큐 데이터가 저장된 순서에 따라 데이터를 읽어올 수 있는 자료 구조 ## **스택(Stack)** ![](/Data_Structure/img/ds_stack_queue_1.png) - LIFO(Last In, First Out) - 새로운 데이터를 맨위에 추가하고 맨 위의 원소부터 제거한다. - 1 → 2→ 3→ 4 ⇒ 4 → 3 → 2→ 1 - **기본 연산** - `enqueue`: 데이터를 스택에 삽입 - `dequeue`: 스택의 맨 위에서 데이터를 제거하고 반환 - **활용 사례** - 함수 호출과 반환(콜 스택) - 실행 취소 - 웹 브라우저의 뒤로 가기/앞으로 가기 - 깊이 우선 탐색(DFS) ### 깊이 우선 탐색 막다른 골목에 도달할 때까지 한 경로로 진행한다. 마지막 골목에서는 이전 분기로 돌아가 다음 경로로 진행할 수 있는지 확인한다. 깊이 우선 탐색은 스택을 사용해 앞으로 탐색해야 할 목록을 유지하고, 다음 진행 대상으로 최근에 삽입된 경로를 선택한다. ![](/Data_Structure/img/ds_stack_queue_2.png) ## **큐(Queue)** ![](/Data_Structure/img/ds_stack_queue_3.png) - **정의**: FIFO(First In, First Out) - 먼저 들어간 데이터가 가장 먼저 제거된다. - 1 → 2→ 3→ 4 ⇒ 1 → 2→ 3→ 4 - **기본 연산**: - `enqueue`: 데이터를 큐에 삽입 - `dequeue`: 큐에서 맨 앞의 데이터를 제거. - **활용 사례** - 프로세스 스케줄링 - 프린터 작업 대기열 - 네트워크 패킷 처리 - 너비 우선 탐색(BFS) ### 너비 우선 탐색 큐를 이용해 각 단계에서 가장 오래 기다린 경로를 탐색한다. 더 깊이 들어가기 전에 같은 깊이의 여러 방향을 먼저 탐색한다. ![](/Data_Structure/img/ds_stack_queue_4.png) ## **변형된 구조** ### **원형 큐 (Circular Queue)** - 배열 기반 큐는 데이터가 추가/삭제되면서 사용되지 않는 공간이 생기는데(메모리 낭비) 원형 큐는 이를 개선하기 위해 배열을 순환 구조로 연결한다. - 큐의 끝에 도달하면 다시 배열의 처음으로 돌아가 작업을 수행한다. - 고정된 크기로도 메모리 효율이 높다. - 활용 - 네트워크 버퍼 empty ![](/Data_Structure/img/ds_stack_queue_5.png) - 삽입과 삭제는 `(index + 1) % size`를 이용한다. ### **우선순위 큐 (Priority Queue)** - 데이터가 삽입될 때 특정 우선순위를 기준으로 정렬된다. - 제일 높은 우선순위의 데이터를 가장 먼저 처리한다. - 활용 - 운영 체제의 프로세스 스케줄링. - 네트워크 패킷 전송. ### **이중 끝 큐 (Deque, Double-ended Queue)** - 양쪽에서 삽입과 삭제가 가능한 큐 - 큐와 스택의 역할을 모두 수행 가능해 유연한 데이터 처리가 가능하다. | 변형 구조 | 특징 | 활용 사례 | --- | --- | --- | 원형 큐 | 순환 배열 기반 큐 | 네트워크 버퍼 | 우선순위 큐 | 우선순위 기반 데이터 처리 | 프로세스 스케줄링, 네트워크 패킷 전송 | 데크 | 양쪽에서 삽입/삭제 가능 | 브라우저, 슬라이딩 윈도우 | https://devuna.tistory.com/22 https://medium.com/swlh/stacks-and-queues-simplified-ef0f838fc534 https://www.programiz.com/java-programming/queue [원형 큐](https://mengu.tistory.com/110) [우선순위 큐](https://lipcoder.tistory.com/100) ",
    "url": "/Data_Structure/ds_stack_queue.html",
    
    "relUrl": "/Data_Structure/ds_stack_queue.html"
  },"26": {
    "doc": "트리와 그래프의 공통점",
    "title": "트리와 그래프의 공통점",
    "content": "## 트리와 그래프의 공통점 트리와 그래프는 여러 개의 **노드(Node)와 간선(Edge)** 으로 이루어져 있는 자료구조로 데이터를 연결하여 표현하는 데 사용된다. ### **1. 기본 구성 요소** - **노드(Node, 정점)**: 데이터를 저장하는 기본 단위 - **간선(Edge, 엣지)**: 노드 간의 관계(연결)를 나타냄 → 예: `A → B` (A에서 B로 이동 가능) ### **2. 네트워크 및 관계를 표현하는 데 사용** - 모두 **객체 간의 관계나 연결을 표현**하는 데 적합하다. - **예** - 네트워크 라우팅(컴퓨터 간 연결) - 조직도, 폴더 구조 등 ### **3. 탐색 방법이 동일하다** 트리와 그래프 모두 **DFS(깊이 우선 탐색)** 및 **BFS(너비 우선 탐색)** 을 사용할 수 있다. - **DFS(Depth-First Search, 깊이 우선 탐색)** → 한 방향으로 끝까지 탐색한 후 되돌아가는 방식 → 예: 미로 찾기, 백트래킹 문제 - **BFS(Breadth-First Search, 너비 우선 탐색)** → 가까운 노드부터 탐색하며, 계층적으로 방문하는 방식 → 예: 최단 경로 찾기 (네비게이션, 지하철 노선 탐색) ### **4. 방향 개념 적용 가능** - 트리와 그래프 모두 **방향성(Directed)과 무방향성(Undirected)** 을 가질 수 있다. - **방향**: 부모 → 자식으로만 이동 가능 - **무방향**: 양방향 이동 가능 ### 차이점 - 트리는 그래프의 한 종류지만 순환이 없는 방향 그래프이다. - 그래프는 순서 없이 노드 간의 관계가 자유롭다. - 트리는 모든 노드가 연결되어 있지만, 그래프는 연결되지 않은 노드가 있을 수 있다. ## **트리(Tree)** ![](/Data%20Structure/img/ds_tree_graph_1.png) - 계층적 구조로, 부모-자식 관계로 연결된 노드들의 집합이다. - 하나의 루트 노드와 0개 이상의 하위 트리로 구성되어 있다. - 트리의 각 노드는 하나의 데이터와 자식 노드에 대한 포인터를 가진다. - 순환하지 않는 무방향 그래프 구조다. ### 용어 1. **노드(Node)**: 데이터를 저장하는 기본 단위. 2. **루트(Root)**: 트리의 최상단 노드. 3. **자식 노드(Child)**: 특정 노드가 가리키는 다음 단계의 노드. 4. **부모 노드(Parent)**: 특정 노드를 가리키는 상위 노드. 5. **리프 노드(Leaf)**: 자식이 없는 끝 노드. 6. **서브트리(Subtree)**: 특정 노드를 루트로 하는 트리 구조. ### 종류 - **이진 트리**: 각 노드가 두 개의 자식 노드를 가질 수 있는 트리. - **이진 탐색 트리(BST)**: 왼쪽 서브트리는 부모보다 작은 값, 오른쪽 서브트리는 부모보다 큰 값을 가지는 이진 트리. - **AVL 트리**: 자가 균형 이진 탐색 트리. 높이 차이를 1로 유지. - **힙(Heap)**: 완전 이진 트리 ### 활용 - 트리는 계층적 데이터 표현 - 파일 및 폴더 - 검색 - 삽입, 삭제 및 검색에 효율적 - 데이터 베이스 인덱스 ### **트리의 탐색** 전위, 중위, 후위 [이진 트리] (https://github.com/Hi-Tech-Study/CS-Study/blob/main/Data%20Structure/ds_binary_tree.md) ### **트리의 한계** 1. **노드 간 다대다(M:N) 관계를 표현할 수 없다.** - 트리는 기본적으로 부모-자식 관계(1:N)만을 표현할 수 있다. - 현실에서는 하나의 노드가 여러 부모(혹은 상위 개체)와 연결되는 경우도 있다. - 한 학생이 여러 개의 수업을 듣는 경우 (수업-학생) 2. **순환(Loop) 구조를 표현할 수 없다.** - 트리는 사이클(순환)이 없는 구조여야 한다. - 현실에서는 순환이 필요한 경우 - 네트워크에서 백업 경로를 설정할 때 (라우팅) - 교통 경로에서 순환 노선이 존재할 때 (지하철 노선) 1. **특정 노드 간의 직접적인 연결이 어렵다.** - 트리는 부모-자식 관계를 따라가야 하므로, 멀리 떨어진 노드 간 연결이 어렵다. ## **그래프(Graph)** 그래프는 노드와 노드 간의 관계로 이루어져 있다. 트리는 계층적 관계를 표현하는 데 유리하지만, 다대다 관계나 순환이 필요한 경우 확장이 어렵다. 따라서 그래프를 활용하면 더 유연한 구조를 만들 수 있다. 1. **더 복잡한 관계 모델링 가능** 2. **유연한 데이터 탐색 및 경로 최적화 가능** - 트리는 특정 노드까지 도달하는 경로가 한 가지뿐이지만, 그래프에서는 **여러 경로를 비교하고 최적의 경로**를 찾을 수 있다. - **네트워크 라우팅** - 트리: 한 노드가 장애가 나면 그 아래 모든 노드가 영향을 받음. - 그래프: 여러 경로가 존재하면 장애 발생 시 다른 경로로 우회 가능. 3. **순환 및 상호 연결이 필요한 시스템을 모델링 가능** - 트리는 한 번 설정되면 변경하기 어렵지만, 그래프는 동적으로 관계를 추가하거나 변경할 수 있다. - 사용자 간의 관계, 커뮤니티 구조 등 ### **그래프의 종류** ![](/Data%20Structure/img/ds_tree_graph_2.png) - **방향 그래프(Directed Graph, Digraph)** - 간선에 방향이 있는 그래프. - 한쪽 방향으로만 이동할 수 있다. - **무방향 그래프(Undirected Graph)** - 간선에 방향이 없는 그래프. - 양쪽 방향으로 이동할 수 있다. - **가중치 그래프(Weighted Graph)** - 간선에 가중치가 부여된 그래프. - 거리, 비용, 우선순위 등을 나타내는데 사용한다. - **순환 그래프(Cyclic Graph)** - 모든 정점이 서로 연결된 그래프. - 경로를 따라가면 다시 자기 자신으로 돌아온다. --- | 항목 | 트리(Tree) | 그래프(Graph) | --- | --- | --- | 구조 | 계층적 구조 | 네트워크 형태 | 방향성 | 보통 방향성 있음 | 방향, 무방향 모두 가능 | 사이클 | 없음(비순환) | 있을 수도 있음 | 연결성 | 모든 노드가 연결됨 | 연결되지 않은 노드 가능 | 탐색 | DFS, BFS | DFS, BFS, 다익스트라 등 다양한 탐색 | https://yoongrammer.tistory.com/68 [https://velog.io/@kwontae1313/트리와-그래프에-대해-알아보자](https://velog.io/@kwontae1313/%ED%8A%B8%EB%A6%AC%EC%99%80-%EA%B7%B8%EB%9E%98%ED%94%84%EC%97%90-%EB%8C%80%ED%95%B4-%EC%95%8C%EC%95%84%EB%B3%B4%EC%9E%90) https://yozm.wishket.com/magazine/detail/2411/ ",
    "url": "/Data_Structure/ds_tree_graph.html",
    
    "relUrl": "/Data_Structure/ds_tree_graph.html"
  },"27": {
    "doc": "자료구조",
    "title": "자료구조",
    "content": "# 자료구조 - 시간복잡도, 공간복잡도, Big - O 표기법 - 선형 자료구조 - 배열 - 벡터(동적 배열) - 연결 리스트 - 스택 & 큐 - 비선형 자료구조 - 트리 & 그래프 - 이진 트리, 이진 탐색 트리 - 우선순위 큐 & 힙 - 맵 - 셋 - 해시 테이블 ",
    "url": "/Data_Structure/readme_DS.html",
    
    "relUrl": "/Data_Structure/readme_DS.html"
  },"28": {
    "doc": "백업(Backup)과 복구(Recovery)",
    "title": "백업(Backup)과 복구(Recovery)",
    "content": "# 백업(Backup)과 복구(Recovery) - Mysql 8.4를 기준으로 작성했습니다. --- ## 백업의 유형 백업은 여러가지 기준에 따라 유형으로 나뉩니다. - 백업 방식: 물리적 / 논리적 - 백업 대상: 전체 백업 / 증분 백업 - 서버 상태: 로컬 백업 / 서버 백업 - 백업 장소: 온라인 백업 / 오프라인 백업 ### 물리적 백업과 논리적 백업 - 물리적 백업(Physical Backup) - 개념 - 데이터베이스 **파일과 디렉토리를 원본 그대로 복사**하여 백업하는 방식입니다. - 특징 - 하드웨어에 종속적 - 복구는 동일하거나 유사한 하드웨어 특성을 갖춘 곳에만 가능합니다. - 동일한 서버 환경을 구성시 사용하기 좋습니다. - 빠른 속도 - 파일과 디렉토리를 그대로 복사하기 때문에, 백업과 복구시 따로 변환 과정이 없어 빠릅니다. - 대용량의 데이터에 대해 백업 및 복구할 때 사용하기 좋습니다. - 주의점 - 서버가 운영 중 이라면, 백업 중 내용을 변경하지 못하도록 잠금한 후 진행해야합니다. - 실행중이지 않다면 바로 진행할 수 있습니다. - DB 외에도 관련 파일(로그나 구성 파일등)이 포함될 수 있습니다. - `mysqlbackup`이나 파일 복사 명령어(`cp`, `scp`, `tar`, `rsync` 등)를 통해 백업할 수 있습니다. - 같은 설정과 로그 상태를 재현: DB 외에도 관련 파일(로그나 구성 파일등)이 포함될 수 있습니다. - 로그: MySQL 에러 로그 등, 구성 파일: MySQL 설정 파일(my.cnf 등) - 논리적 백업 - 개념 - 논리적 DB구조(`CREATE DATABASE`, `CREATE TABLE`)와 내용(`INSERT`, 구분된 텍스트 파일)으로 표현된 정보를 저장 하는 방식입니다. - 특징 - 높은 휴대성 - 명령어를 다시 실행하는 방식으로 진행되기 때문에, 하드웨어에 종속되지 않습니다. - 다른 하드웨어, 운영체제로 이관시 사용하기 좋습니다. - 느린 속도 - 서버가 DB 정보를 논리적인 형식으로 변환해야 하기 때문에 물리적 백업보다 느립니다. - 서버 중지 불필요 - 서버는 실행 중인 상태여야 가능하지만, 잠금할 필요는 없습니다. - 운영 중인 서비스에 큰 영향 없이 백업을 진행할 수 있습니다. - `mysqldump`이나 `INTO OUTFILE`을 통해 백업할 수 있습니다. ### 온라인 백업과 오프라인 백업 - 온라인 백업(Online Backup, Hot Backup) - 개념 - 서버가 **실행 중인** 상태에서 백업을 진행하는 방식입니다. - 특징 - 운영 중인 서비스나 다른 클라이언트는 데이터를 읽을 수 있습니다. - 적절한 잠금 필요: 데이터 백업과 복구시에 데이터의 무결성을 위해, 적절한 잠금 처리가 필요합니다. - 오프라인 백업(Offline Backup, Cold Backup) - 개념 - 서버가 **중지된** 상태에서 백업을 진행하는 방식입니다. - 운영서버가 아닌 복제(Replica)서버를 오프라인으로 전환하여 백업하는 방식도 있습니다. - 특징 - 오프라인이기 때문에, 모든 서비스가 중지됩니다. - 간단한 백업 절차: 서버가 중지되어 데이터 무결성이 지켜집니다. - Warm Backup - 개념 - 온라인과 오프라인 중간의 개념을 의미합니다. - 서버는 실행 중이지만, 데이터 수정이 불가능한 상태에서 백업하는 방식 - 특징 - 데이터는 읽을 수 있지만, 수정할 수 없는 상태로 백업하는 것을 의미 합니다. ### 로컬 백업과 원격 백업 - 로컬 백업(Local Backup) - 개념 - 백업하는 서버와 백업의 대상 서버가 동일한 호스트에서 백업하는 방식입니다. - 백업 수행 서버 = 백업 대상 서버 - 특징 - 속도와 안정성: 동일한 서버에서 수행되어 빠르고 안정적입니다. - 물리적 백업: 물리적 백업시, 주로 로컬 백업 방식을 이용합니다. - 원격 백업(Remote Backup) - 개념 - 백업하는 서버와 백업의 대상 서버가 다른 호스트에서 백업하는 방식입니다. - 백업 수행 서버 != 백업 대상 서버, 백업 수행 서버와 백업 대상 서버는 네트워크를 통해 통신하며 백업하는 방식힙니다. - 특징 - 물리적 백업: 물리적 백업시, 백업 파일의 목적지는 원격지로 설정(`scp`, `rsync` 등을 이용)할 수 있습니다. 도구에 따른 비교 - `mysqldump` - 로컬과 원격 관계없이 사용할 수 있습니다. - 저장 위치 - SQL 형식: 클라이언트(명령어를 실행한 곳)에 저장됩니다. - `--tab`옵션 사용시(CSV 파일형식 등): 서버(명령어를 수행하는 곳)에 저장됩니다. - `SELECT … INTO OUTFILE` - 로컬과 원격 관계없이 사용할 수 있습니다. - 저장 위치: 항상 서버측(명령어를 수행하는 곳)에 저장됩니다. - 물리적 백업 - 주로 로컬 백업 방식을 이용합니다. - 백업 파일의 목적지를 원격지로 설정(`scp`, `rsync` 등을 이용)할 수 있습니다. > `mysqldump` > > - 기본 사용 > - SQL 형식으로 출력되며, 표준출력에 보여집니다. > - `>` 또는 `>>`연산자를 이용해, 파일로 저장합니다. > - `--tab` 옵션 사용 > - 각 테이블에 대해 2개의 파일이 하나의 디렉토리에 생성됩니다. > - 데이터 파일:데이터의 내용이 csv 와 같은 형식(tab을 구분자로 한 형식)의 텍스트 파일 > - 테이블 구조: 테이블 구조를 정의하는 SQL파일 ### 스냅샷(Snapshot) 백업 - 개념 - 파일 시스템 상태를 그대로 캡처하여 보관하는 방식입니다. - 파일 시스템의 상태를 논리적으로 복사하는 방식(실제 파일 데이터를 전체 복사하는 것이 아님)입니다. - 특징 - **일부 파일 시스템(LVM, ZFS, veritas Volume Manager)에서 지원하는 방식**으로, DB에서 지원하는 방식이 아닙니다. - 따라서 DB에서 직접 복구에 사용되지 않습니다. - 복구시 활용 - 스냅샷을 통해 파일 시스템 자체를 특정 시점으로 롤백합니다. - 스냅샷 파일을 별도의 디렉토리에 마운트해, 스냅샷 내의 데이터를 복사합니다. ### 전체 백업과 증분 백업 - 전체 백업(Full Backup) - 개념 - 전체 데이터를 특정 시점에 1번 백업하는 방식입니다. - 특징 - 완전한 복구 가능 - 특정 시점의 상태를 완전히 복원할 수 있습니다. - 백업 시점 이후 내용이 변경되었다면, 최신 상태가 아닐 수 있습니다. - 백업 파일 크기: 서버에 존재하는 모든 데이터를 백업하기 때문에 큽니다. - 백업 속도: 백업 파일의 크기가 커서 느립니다. - `mysqldump`, `mysqlbackup` 등을 이용해 전체 데이터를 백업합니다. - 증분 백업(Point-in-Time Backup) - 개념 - 변경된 데이터만 추가로 백업하는 방식입니다. - 전체 백업과 조합하여 사용합니다. - 전체 백업 이후의 변경된 데이터를 백업합니다. - 특징 - 복구 - 전체 백업을 먼저 복원 -> 변경사항을 순차적용 - 백업 파일 크기: 변경된 데이터만 백업하므로 백업 파일의 크기가 작습니다. - 백업 속도: 백업 파일 크기가 작아 빠릅니다. - `Binary Log`를 이용하여 변경 사항을 기록합니다. - `Binary Log`를 활성화하면 데이터 변경 사항이 로그 파일에 기록합니다. - 특정 시점까지만 복구할 수 있습니다. ## 백업 스케줄링, 압축, 암호화 백업 스케줄링, 압축, 암호화는 백업 절차를 자동화 하는데 유용합니다. DB에서는 직접 제공하지 않아, 다른 솔루션을 이용해야합니다. - 예시 - 스케줄링: linux의 crontab, windows scheduler 등을 이용해 백업 주기 설정 - 압축: gzip, tar, zip을 이용해 백업 파일 압축 - 암호화: openssl 등을 이용해 백업 파일 암호화 ## 백업 전략 > 다양한 백업 방식을 아는 것보다 중요한건, 이를 이용해 실무에서 백업을 하고 문제상황이 생겼을 때 백업을 이용해 복구하는 것입니다. > 그러기 위해서는 백업 정책을 정의하는 것이고, 백업 정책에서 중요한 것은 정기적인 백업이 이루어져야 하며, 백업 후 복구 가능성을 항상 점검해야 합니다. mysql에서 제공하는 예시를 통해 어떻게 정기적인 백업을 설정해야하고,이를 복구시에 이용할지에 대해 알아봅시다. ### 전체 백업 이용하기 > 물리적 백업을 할 수도 있고, 논리적인 백업을 할 수도 있겠지만, 여기서는 mysqldump를 이용한 논리적 백업을 이용합니다. 가장 부하가 적은 시간대에 전체 백업을 수행합니다. > 일요일 오후 1시에 전체 백업을 수행, 백업할 테이블은 InnoDB라고 가정 ```shell $> mysqldump --all-databases --source-data --single-transaction > backup_sunday_1_PM.sql ``` -> 현재 시점에 전체 데이터를 백업해 파일(`backup_sunday_1_PM.sql`)을 만들라는 의미 - `--all-databases`: 모든 database를 백업합니다. - `--source-data`: 백업 시점의 `Binary Log`파일의 이름과 위치를 덤프 파일에 기록합니다. - `--single-transaction`: InnoDB 테이블에 대한 **일관된 읽기** 제공하여 데이터 무결성을 보장합니다. > 일관된 읽기 > > - 다른 클라이언트가 데이터 테이블에 변경한 사항은 mysqldump 프로세스에서 볼 수 없도록 함 > - 만약, 백업 작업에 비트랜잭션 테이블이 포함된 경우 일관성을 위해 백업 중에 변경되지 않아야 합니다. > - For example, 백업 중에 MySQL 계정에 대한 관리 변경 이후에 주기적으로 백업한다면, (이전 백업파일은 삭제하고, 생략가능) 다시 전체 백업을 진행합니다. 복원시에는 아래와 같은 명령어를 이용해 복원할 수 있습니다. ```shell $> mysql mysqldump --single-transaction --flush-logs --source-data=2 --all-databases > backup_sunday_1_PM.sql ``` -> 현재 시점에 전체 데이터를 백업해 파일(`backup_sunday_1_PM.sql`)을 만들고, 이후의 변경 데이터는 `Binary Log`에 저장하도록 설정하는 의미 - `--flush-logs`: 백업 시 로그를 플러시하여 새로운 `Binary Log` 파일을 시작합니다. - `--source-data=2`: 현재 `Binary Log` 파일과 포지션 정보를 백업 파일에 기록합니다. ```text -- Position to start replication or point-in-time recovery from -- CHANGE REPLICATION SOURCE TO SOURCE_LOG_FILE='gbichot2-bin.000007',SOURCE_LOG_POS=4; ``` - 1번째 줄: 덤프 파일(=`backup_sunday_1_PM.sql`)에는 \"gbichot2-bin.000007\" `Binary Log` 파일이나 그 이상에 기록된 변경 사항 이전에 작성된 모든 변경 사항이 포함되어 있습니다. - 백업 후 기록된 모든 데이터 변경 사항은 덤프 파일(=`backup_sunday_1_PM.sql`)에는 없지만, \"gbichot2-bin.000007\" `Binary Log` 파일 이상에는 존재합니다. 이후에 주기적으로 백업을 수행한다면, `mysqladmin flush-logs` 명령어를 이용해 새 `Binary Log`에 이후 변경 데이터를 저장하도록 합니다. 순서 정리 1. 1일 오후 1시: `mysqldump`를 이용해 전체 데이터 백업 + 이후 변경 데이터는 `Binary Log`에 저장 - 전체 데이터: `backup_sunday_1_PM.sql`에 저장 - 변경 데이터: `gbichot2-bin.000007`에 저장 2. 8일 오후 1시: `mysqladmin flush-logs`로 새로운 변경 데이터 저장 - 변경 데이터: `gbichot2-bin.000008`에 저장 - 이전 데이터가 삭제되지 않고, `gbichot2-bin.000007`에 저장된 변경데이터를 `gbichot2-bin.000008`에 저장 3. 15일 오후 1시: `mysqladmin flush-logs`로 새로운 변경 데이터 저장 - 변경 데이터: `gbichot2-bin.000009`에 저장 - 이전 데이터가 삭제되지 않고, `gbichot2-bin.000008`에 저장된 변경데이터를 `gbichot2-bin.000009`에 저장 복원시에는 전체 백업 데이터를 이용해 복원한 후, `Binary Log`파일을 순서대로 적용해 복원합니다. - 전체 데이터 복원 ```shell $> mysql mysqlbinlog gbichot2-bin.000007 gbichot2-bin.000008 | mysql ``` ### 주의 백업 데이터가 누적되면 용량이 커질 수 있으니, 적절한 주기로 백업데이터를 삭제하거나 압축하여 관리해야합니다. ### 고려사항 - 클라이언트가 DB에 접근하는 주요 시간: 사용량이 적은 기간이 예측된다면, 백업을 예약하는 것이 좋습니다. - 변경 사항이 발생하는 주기: 잦은 변경사항이 있다면, 전체 백업과 증분 백업을 고려하세요. - DB의 변경 범위: DB 전체가 변경되는지, 일부분만 변경되는지에 따라 부분 백업이나 전체 백업을 부분 백업을 진행하세요. - 백업을 위한 디스크 공간 - 백업을 유지할 기간: 비즈니스 로직에서 유지되어야하는 기간을 고려하며 백업 일정을 설정하고, 백업 데이터를 삭제시에 삭제해도 유지되어야하는 기간에 대해서는 관계가 없는지 확인해야합니다. - 백업 테스트: 백업을 테스트 하기 전까지는 제대로 백업이 되는지 알 수 없고, 복원에 사용될 수 있을지 알 수 없습니다. ### 참고 자료 - [Mysql docs - Chapter 9 Backup and Recovery](https://dev.mysql.com/doc/refman/8.4/en/backup-and-recovery.html) - [microsoft learn - SQL Server 데이터베이스 백업 및 복원](https://learn.microsoft.com/ko-kr/sql/relational-databases/backup-restore/back-up-and-restore-of-sql-server-databases?view=sql-server-ver16) ",
    "url": "/Database/db_backup_recovery.html",
    
    "relUrl": "/Database/db_backup_recovery.html"
  },"29": {
    "doc": "데이터베이스(Database) 기초",
    "title": "데이터베이스(Database) 기초",
    "content": "## 데이터베이스(Database) 기초 > 데이터베이스(Database)는 여러 사람이 공유하고 사용할 목적으로 체계적으로 조직한 데이터의 집합을 의미합니다. 데이터베이스를 효율적으로 제어 및 관리하기 위해 DBMS(DataBase Management System)를 사용합니다. ### 데이터베이스란? - 정의 - 공유, 통합, 저장, 운영되는 데이터의 집합 - 여러 응용 시스템(프로그램)들이 동시에 데이터를 활용할 수 있도록 물리적으로나 논리적으로 조직화해둔 것 - 특징 - 실시간 접근성: 사용자가 원할 때마다 실시간으로 데이터에 접근 가능 - 지속적인 변화: 새로운 데이터의 삽입, 삭제, 갱신이 계속 이루어짐 - 동시 공유: 여러 사용자가 동시에 접근하여 데이터를 활용 가능 - 내용 참조: 데이터의 물리적 주소(위치)가 아닌, 실제 데이터 값을 참조 - 데이터베이스 내부에 있는 데이터들은 특정 DBMS마다 정의된 쿼리 언어(SQL)를 통해 삽입, 삭제, 수정, 조회 등을 수행할 수 있습니다. ![](/Database/img/db_basic_1.png) - 데이터베이스 위에 DBMS가 위치하여 응용 프로그램의 데이터 사용을 제어하고 관리합니다. ### 엔티티(Entity) - 개체라는 뜻으로 사람, 장소, 물건, 사건, 개념 등 여러 개의 속성을 지닌 명사 - 자바의 Class라고 생각하시면 됩니다! - 실제로 존재하는 개념과 추상적인 개념을 모두 표현할 수 있습니다. - 실제로 존재하는 것: 학생 DB - 추상적인 개념: 결제 - 약한 엔티티와 강한 엔티티 - 독립적으로 존재할 수 있는지에 따라 약한/강한 엔티티로 구분할 수 있습니다. - A가 존재해야만 B가 존재한다면 A는 약한 엔티티, B는 강한 엔티티입니다. - 예를 들어, 건물과 방을 놓고 보았을 때 방은 건물이 있어야만 존재할 수 있으므로 건물은 약한 엔티티, 방은 강한 엔티티가 됩니다. ### 릴레이션(Relation) - 데이터베이스에서 정보를 구분하여 저장하는 기본 단위 - 엔티티와 관련된 데이터를 데이터베이스는 릴레이션 하나에 담아서 관리합니다. 즉, 엔티티가 데이터베이스에서 관리될 때, 릴레이션이라고 합니다. - 릴레이션을 DBMS에서는 테이블, NoSQL 데이터베이스에서는 컬렉션이라고 합니다. ### 속성(Attribute) - 릴레이션에서 관리하는 구체적이고 고유한 이름을 갖는 정보 - 관리해야할 필요가 있는 속성들만이 엔티티의 속성이 됩니다. - 속성별로 타입을 정의하여 테이블을 구성합니다. - 자동차 엔티티에 해당하는 속성은 차량 번호, 바퀴 수, 색상 등이 있습니다. ### 도메인(Domain) - 릴레이션에 포함된 각각의 속성들이 가질 수 있는 값의 집합 - 성별이라는 속성이 있다면 이 속성이 가질 수 있는 값은 {남, 여}라는 집합이 됩니다. ### 필드와 레코드(Field, Record) - 필드: 개별적인 속성을 부르는 말 - 레코드: 테이블에 쌓이는 행(row) 단위의 데이터, 튜플이라고도 함 ### 관계 - 여러 개의 테이블 사이에서 관계를 정의하는 것. - 1:1 관계 - 테이블 간의 관계가 하나씩만 존재하는 관계 - 사람 - 여권 - 1:N 관계 - 부서 - 직원 - N:M 관계 - 학생 - 강의 ### 키 ![](/Database/img/db_basic_2.png) - 테이블 간의 관계를 더 명확히 하고, 테이블 자체의 인덱스를 위해 설정된 방법, 기본기, 외래키, 후보키, 슈퍼키, 대체키가 있습니다. - 기본키 - PK 또는 프라이머리 키라고 하며, 유일성과 최소성을 만족합니다. - 테이블의 데이터 중 고유하게 존재하는 속성으로 기본키는 중복이 되지 않아야 하고 최소성을 만족해야 합니다. - 자연키 또는 인조키 중에 골라서 설정합니다. - 자연키: 테이블을 구성하는 속성 중, 따로 조치하지 않아도 고유성을 만족하는 키, 유저 테이블의 주민등록번호 - 인조키: 테이블에서 인위적으로 유저 아이디를 부여하는 키, 오라클은 sequence, MySQL은 auto increment - 그래서 보통 기본키는 인조키로 설정 - 외래키 - FK라고 하며, 다른 테이블의 기본키를 그대로 참조하는 값으로 개체와의 관계를 식별하는 데 사용 - 외래키는 중복을 허용 - 고객 테이블과 제품 테이블이 있다고 했을 때, 고객의 기본키를 참조하여 제품 테이블에 외래키로 가져와 관계를 형성할 수 있습니다. - 후보키 - 기본키가 도리 수 있는 후보들이며 유일성과 최소성을 동시에 만족하는 키 - 대체키 - 후보키가 두 개 이상인 경우 어느 하나를 기본키로 지정하고 남은 후보키들을 의미 - 슈퍼키 - 각 레코드를 유일하게 식별할 수 있는 유일성을 갖춘 키 ## 참고 자료 - 면접을 위한 CS 전공지식 노트, 주홍철 ",
    "url": "/Database/db_basic.html",
    
    "relUrl": "/Database/db_basic.html"
  },"30": {
    "doc": "DB 캐싱",
    "title": "DB 캐싱",
    "content": "# DB 캐싱 ## 파레토 법칙과 캐싱 ![image.png](https://github.com/user-attachments/assets/3aa7d363-1b36-428d-8c48-5c9e7c85a5f6) **시스템 결과 중 80%가 전체 원인의 20%에서 비롯**된다는 개념에 기초하여, 파레토 법칙은 전체 데이터 중 극소수의 데이터가 대부분의 요청을 차지함을 강조합니다. 캐싱은 이 원리를 활용하여, **전체 데이터 중 빈번하게 요청되는 약 20%의 데이터를 우선적으로 캐싱함으로써 전체 시스템의 효율성을 높이고 응답 속도를 향상**시키는 전략입니다. ## 캐시 데이터 원본보다 더 빠르고 효율적으로 액세스할 수 있는 임시 데이터 저장소를 캐시라고 합니다. 캐시를 효과적으로 활용하려면, 캐시 대상 데이터를 신중하게 선정하는 것이 중요합니다. 특히, 다음 두 가지 유형의 데이터는 캐시 도입 시 성능 향상을 기대할 수 있습니다. - **자주 조회되면서 변경 빈도가 낮은 데이터:** 예를 들어, 제품 정보, 카테고리 목록 등은 조회 빈도가 높고 업데이트가 드물어 DB와 캐시 간의 불일치 가능성이 낮습니다. - **최신성이 엄격하게 요구되지 않는 데이터:** 실시간으로 최신 업데이트가 반영되지 않아도 되는 경우, 캐시를 사용하더라도 큰 문제가 발생하지 않습니다. ## 데이터베이스와 캐시 데이터 베이스에서 캐시를 활용하는 방법은 크게 두가지로 구분 됩니다. - **외부 캐시 서버 도입** **Redis** 같은 별도의 캐시 서버를 사용하여, **애플리케이션과 데이터베이스 사이에 빠른 임시 데이터 저장소**를 활용하는 방법입니다. - **DB 내부 캐시** 각 데이터베이스는 자체적으로 **버퍼 풀** 기능을 제공합니다. 자주 사용되는 데이터를 메모리에 저장하고 빠르게 액세스할 수 있도록 지원합니다. 이 방식은 추가 인프라 없이 데이터베이스 내부에서 자동으로 관리됩니다. ## DB 내부 캐시 : 버퍼풀 ### 버퍼풀(Buffer Pool) > 대부분의 데이터베이스 엔진마다 버퍼풀이 존재합니다. 예를 들어 MySQL에는**InnoDB 버퍼 풀,** PostgreSQL에는 **shared_buffers**이 존재합니다. > 데이터베이스 내부에는 디스크에서 읽어온 데이터 페이지를 캐시하고, 새로 작성하거나 변경된 데이터 페이지를 임시로 보관하는 공간인 버퍼풀이 있습니다. 버퍼 풀은 디스크에서 **읽어온 데이터를 이 페이지 단위로 캐싱**합니다. 예를 들어, 데이터베이스에서는 개별 행만 캐싱하는 것이 아니라, 그 행이 포함된 전체 페이지(데이터 블록)를 캐싱합니다. 한 번의 디스크 I/O로 여러 관련 데이터를 빠르게 읽어올 수 있도록 최적화 되어있습니다. > 공간적 지역성(Spatial Locality) 데이터베이스는 공간적 지역성 원칙을 기반으로 설계되어있습니다. 한 행을 조회할 때 그 행이 속한 페이지의 다른 행들도 곧 필요할 가능성이 높다고 가정합니다. > 데이터베이스는 데이터 조회시 버퍼 풀을 확인하여 작업을 처리합니다. 요약하면 다음과 같습니다: 1. **버퍼 풀 확인:** 데이터 읽기/쓰기 작업 전에, 데이터베이스는 메모리에 있는 버퍼 풀에서 요청된 데이터 페이지를 찾습니다. 2. **Cache Hit (캐시 히트):** 요청한 데이터 페이지가 버퍼 풀에 있으면, 디스크 접근 없이 바로 해당 페이지를 사용하여 빠르게 작업을 수행합니다. 3. **Cache Miss (캐시 미스):** 요청한 데이터 페이지가 버퍼 풀에 없으면, 디스크에서 해당 페이지를 읽어와 버퍼 풀에 로드한 후 작업을 진행합니다. 데이터베이스는 기본적으로 **버퍼풀, 실행 계획 캐시, 메타데이터 캐시, 트랜잭션 로그 버퍼 등 내부 캐시 메커니즘을 통해 성능을 최적화**합니다.그러나 이러한 내부 캐시는 데이터 베이스 자원을 직접적으로 이용하기 때문에, 용량 제한, 동시성 처리로 인한 부하와 관련된 한계가 있습니다. 애플리케이션 전반에서 자주 사용되는 데이터나 쿼리 결과를 별도로 캐싱하여 DB 부하를 줄이고 응답 속도를 개선하기 위해서는 Redis 같은 **외부 캐시 서버** 도입을 고려하는 것이 좋습니다. ## 외부 캐시 서버 도입(**Remote Cache**) : Redis ![image.png](https://github.com/user-attachments/assets/920a2d73-a5bc-4a51-9263-db327c1a9168) **Redis** 같은 별도의 캐시 서버를 사용하여, **애플리케이션과 데이터베이스 사이에 빠른 임시 데이터 저장소**를 활용하는 방법입니다. 외부 캐시 서버를 도입하면 다음과 같은 장점을 얻을 수 있습니다. - 데이터베이스 부하 감소 - 반복적인 데이터 요청을 외부 캐시가 처리함으로써, 데이터베이스에 대한 직접적인 요청 횟수를 줄이고 부하를 낮출 수 있습니다. - 확장성 및 분산 처리 - 여러 애플리케이션 인스턴스가 동일한 캐시 데이터를 공유할 수 있어, 분산 환경에서의 확장성이 좋아집니다. - 유연한 캐시 관리 - TTL(Time-To-Live) 설정, 다양한 데이터 구조 지원 등으로 캐시 정책을 세밀하게 조정할 수 있습니다. ## 캐싱 전략 캐시를 사용하면 **데이터 정합성 문제**에 직면할 수 있습니다. > 데이터 정합성이란, 동일한 데이터가 캐시(Cache Store)와 데이터베이스(Data Store) 두 곳에 저장될 때, 두 저장소 간의 데이터 값이 일치하지 않는 현상을 말합니다. 예를 들어, 어떤 게시글의 좋아요 개수가 캐시에는 10으로 저장되어 있지만, 데이터베이스에는 7로 저장될 수 있습니다. 이는 데이터 조회 시, 캐시에 저장된 값을 우선 활용하기 때문입니다. > 캐시를 사용하지 않으면 모든 데이터 조회와 저장이 데이터베이스에서 이루어져 정합성 문제가 발생하지 않지만, 외부 캐시를 도입하면 동일한 데이터라도 두 저장소에서 다른 값을 가질 가능성이 있습니다. 따라서, **적절한 캐시 읽기 및 쓰기 전략을 수립**하여 데이터 불일치 문제를 최소화하면서도 빠른 성능을 확보하는 것이 매우 중요합니다 ### 캐시 읽기 전략(Read Cache Strategy) - **Look Aside** 패턴 - 데이터를 찾을 때 우선 캐시에 저장된 데이터가 있는지 우선적으로 확인하는 전략입니다. - 반복 적인 읽기가 많은 호출에 적합합니다. - 캐시 서버가 다운된되어도 DB에서 데이터를 가져올 수 있어 서비스 장애를 막을 수 있습니다. ![image.png](https://github.com/user-attachments/assets/d4fe6232-8ada-409a-9646-98a97429dd28) - **Read Through** 패턴 - 캐시에서만 데이터를 읽어오는 전략 - 데이터 조회를 전적으로 캐시에만 의존하므로, 캐시 서버가 다운되는 경우 서비스 이용에 차질이 생길 수 있다. ![image.png](https://github.com/user-attachments/assets/af0accbe-8aba-4a29-946a-44835699f07f) ### 캐시 쓰기 전략(Write Cache Strategy) - **Write Back** 패턴 - 캐시와 DB의 데이터 동기화를 비동기로 처리하는 패턴입니다. - 데이터 저장시 DB에 바로 저장하지 않고, 캐시에 모아서 일정 주기 배치 작업을 통해 DB에 반영합니다. - 캐시에 모아놨다가 DB에 반영하기 때문에 쓰기 쿼리 비용과 비용을 줄일 수 있습니다. - 하지만, 캐시에서 오류나 장애가 발생하면 아직 DB에 반영되지 않은 데이터가 손실될 위험이 있습니다. ![image.png](https://github.com/user-attachments/assets/30f01d2c-d6fd-4683-b831-f10393a0a041) - **Write Through** 패턴 - DB와 Cache에 동시에 데이터를 저장하는 전략입니다. - 데이터를 저장할 때 먼저 캐시에 저장한 다음 바로 DB에 저장합니다. - 항상 동기화가 되어있어 항상 최신정보를 보장합니다. - 매 요청마다 2단계의 write가 발생하므로 상대적으로 느리고, 빈번한 생성 및 수정이 발생하는 경우 성능 이슈 발생할 수 있습니다. ![image.png](https://github.com/user-attachments/assets/3142d90a-ad0e-492f-aa14-2b095a9849c3) - **Write Around** 패턴 - 모든 쓰기 작업은 직접 데이터베이스에 수행되며, 캐시는 쓰기 작업 시에는 사용되지 않습니다. - 캐시에는 오직 Cache Miss가 발생했을 때, 읽기 요청을 처리하기 위해 데이터가 저장됩니다. ![image.png](https://github.com/user-attachments/assets/7a2cbfb9-c384-48ad-9991-bdc4003cb7e9) ### 캐시 읽기 + 쓰기 전략 조합 읽기 전략과 쓰기 전략은 독립적으로 선택하는 것이 아니라, **서로 보완하는 형태로 함께 채택**하여 최적의 성능과 데이터 일관성을 유지합니다. - **Look Aside + Write Around 조합** ![image.png](https://github.com/user-attachments/assets/ec15c507-78e4-4af4-815c-f5c1976e5e84) - 가장 일반적으로 자주 쓰이는 조합 - **읽기(Read)** - 먼저 캐시를 확인하여(캐시 히트) 데이터가 있으면 캐시에서 반환합니다. - 캐시에 없으면(캐시 미스) DB에서 데이터를 읽어오고, 그 데이터를 캐시에 저장하여 이후 요청 시 활용합니다. - **쓰기(Write)** - 쓰기 작업은 데이터베이스에 직접 반영됩니다. - 캐시는 업데이트하지 않으므로, 이후 조회 시에는 최신 데이터가 캐시에 반영되기 전까지 DB의 값을 조회하게 됩니다. - **Read Through + Write Around 조합** ![image.png](https://github.com/user-attachments/assets/90223aad-bb3b-48bb-b4b4-b7f1f9fe988f) - **읽기(Read)** - 데이터 조회 요청 시, 무조건 캐시에서 결과를 반환합니다. - 캐시에 데이터가 없는 경우, 캐시가 대신 DB에 요청하여 데이터를 가져온 후 캐시에 저장하고, 그 값을 반환합니다. - **쓰기(Write)** - 쓰기 작업은 DB에 바로 반영됩니다. - 캐시는 별도로 갱신되지 않으므로, 쓰기 후 즉시 조회하면 캐시에는 기존 데이터가 남아 있을 수 있으며, 이후 조회 시 캐시 미스가 발생하면 최신 데이터가 DB에서 읽혀져 캐시가 갱신됩니다. - **Read Through + Write Through 조합** ![image.png](https://github.com/user-attachments/assets/d41f1df8-7899-4473-ba9e-1d9746a4a684) - **읽기(Read)** - 데이터 조회 요청 시, 무조건 캐시에서 결과를 반환합니다. - 캐시에 데이터가 없는 경우, 캐시가 대신 DB에 요청하여 데이터를 가져온 후 캐시에 저장하고, 그 값을 반환합니다. - **쓰기(Write)** - 쓰기 작업은 우선 캐시에 데이터를 저장합니다. - 동시에 캐시가 DB로 해당 데이터를 전달하여, DB에도 반영되도록 합니다. ## 참고자료 [MySQL기초[2]- 캐싱,버퍼풀 전략](https://nstgic3.tistory.com/entry/MySQL%EA%B8%B0%EC%B4%882-%EC%BA%90%EC%8B%B1%EB%B2%84%ED%8D%BC%ED%92%80-%EC%A0%84%EB%9E%B5) [[REDIS] 📚 캐시(Cache) 설계 전략 지침 💯 총정리](https://inpa.tistory.com/entry/REDIS-%F0%9F%93%9A-%EC%BA%90%EC%8B%9CCache-%EC%84%A4%EA%B3%84-%EC%A0%84%EB%9E%B5-%EC%A7%80%EC%B9%A8-%EC%B4%9D%EC%A0%95%EB%A6%AC) ",
    "url": "/Database/db_cache.html",
    
    "relUrl": "/Database/db_cache.html"
  },"31": {
    "doc": "분산형 데이터베이스",
    "title": "분산형 데이터베이스",
    "content": "# 분산형 데이터베이스 - 데이터를 한 위치가 아닌 여러 위치에 저장하는 데이터베이스 - 이는 여러 서버 또는 개별 노드로 구성된 컴퓨터 클러스터에 데이터를 배치하는 것을 의미한다. 이러한 노드는 지리적으로 분리되어 있을 수 있으며, 클라우드 데이터베이스 내의 물리적 컴퓨터 또는 가상 머신일 수 있다. # 유형 - **동종 분산 데이터베이스** : **동일한** 데이터를 저장, 데이터 모델 사용, 운영 체제에서 작동, 분산 데이터 베이스 관리 시스템 공유. 모든 노드의 유사성으로 인해 중복성을 통해 중요한 데이터 보호를 제공하고 관리를 단순화한다. - **이기종 분산 데이터베이스** : **서로 다른** 데이터를 저장, 운영 체제에서 작동, 데이터 스키마를 포함한다. 혹은, 서로 다른 사이트가 서로의 존재를 인식하지 못할 수 도 있다. 관리하기가 더 복잡하지만 이기종 분산 데이터베이스는 동종 분산 데이터베이스보다 데이터 모델, 스키마 선택 및 저장할 수 있는 데이터 유형 측면에서 더 큰 유연성을 제공한다. # 주로 사용되는 곳 - **대규모 데이터와 트래픽을 처리해야 하는 애플리케이션** : 소셜 미디어 플랫폼, 전자 상거래 사이트 등 수백만 명의 동시 사용자 및 트랜잭션을 관리해야 하는 경우. 분산 데이터베이스는 많은 노드를 추가하여 수평적으로 확장할 수 있도록 지원한다. - **높은 가용성과 장애 허용이 필수적인 환경** : 금융 서비스, 의료 시스템, 결제 처리 시스템 등 거의 지속적인 가동 시간이 필요한 경우. # 노드 노드는 분산 데이터베이스 시스템 내에 있는 개별 서버 또는 컴퓨터다(예: 물리적 구성 요소를 공유하지 않는 컴퓨터, 가상 머신, 서버). 각 노드는 데이터를 저장하고 분산 데이터베이스 관리 시스템 소프트웨어에서 실행된다. # 결함 허용 (Fault Tolerance) 하나 이상의 노드 혹은 서버의 실패에도 계속해서 정상적으로 동작할 수 있는 능력을 의미한다. 시스템의 안정성과 가용성을 보장하며, 장애가 발생했을 때에도 서비스의 중단을 최소화하는 목표를 가진다. ## 데이터 복제 서로 다른 노드 혹은 서버, 사이트에 동일한 데이터의 복사본을 만들고 유지하는 프로세스이다. 이렇게 되면, 하나의 노드 혹은 서버에서 장애가 발생하더라도, 다른 쪽에서 동일한 데이터를 제공할 수 있어 가용성이 증가한다. - **전체 복제:** 전체 복제에서 전체 데이터베이스의 완전한 복사본이 분산 데이터베이스 시스템 내의 모든 사이트로 전송된다. - **부분 복제:** 데이터베이스의 특정 부분만 필요한 경우가 있으므로 데이터베이스의 정의된 부분이 선택한 그룹에 복제된다. ## 데이터 분산(파티셔닝) 파티셔닝은 대규모 데이터 세트를 더 작고 관리하기 쉬운 부분으로 분할하는 기술로써, 분산 데이터베이스에서 효율성, 보안 및 최적의 사용자 액세스에 매우 중요하다. - **수평 파티셔닝** - 데이터 테이블을 행으로 분할하는 것을 의미. - 전체 데이터 세트를 스캔하는 대신 특정 파티션으로 쿼리를 보낼 수 있으므로 효율적인 부하 분산과 향상된 쿼리 성능을 가능하게 한다. - **수직 파티셔닝** - 데이터 테이블을 열로 분할한다. - 서로 다른 애플리케이션이나 사용자가 데이터의 서로 다른 속성에 접근할 때 특히 유용하다. 자주 접근하는 열을 격리함으로써 수직 파티셔닝은 성능을 향상시키고 네트워크를 통해 전송되는 데이터 양을 줄일 수 있다. - **해시 파티셔닝** - 지정된 키 속성에 해시 함수를 적용하여 주어진 레코드를 보유할 파티션을 결정한다. - 파티션 간에 데이터를 고르게 분산시켜 하나의 파티션이 불균형적으로 많은 트래픽을 수신하는 가능성을 최소화하는 것을 목표로 한다. ## 부하 분산 사용자 요청 및 쿼리를 데이터베이스 노드에 고르게 분산하는 기술. 이는 성능을 향상시킬 뿐만 아니라 한 노드의 오류가 다른 노드에 과부하를 일으키지 않도록 한다. 쿼리가 수신되면 부하 분산 장치는 요청을 평가하고 응답하는 데 가장 적합한 노드를 결정한다. 이 평가 중에 근접성, 현재 부하 및 기타 미리 결정된 시스템 규칙과 같은 요소가 고려된다. 이 평가 및 할당은 시스템 과부하 및 시스템 비효율성을 방지하여 사용자 대기 시간을 줄이는 데 도움이 된다. # 데이터 요청 ## 분산 요청 단일 SQL문(명령문) 으로 둘 이상의 노드(데이터베이스) 를 참조할 수 있는 하는 분산 데이터베이스의 기능. ## 라우팅 (쿼리 라우팅) ### 직접 라우팅 (Direct Routing) - 사용자가 요청에 샤딩 키를 제공하면, 해당 키를 기반으로 요청이 특정 샤드로 전달된다. - 중간 지점을 거치지 않기에 처리 속도가 빠르다. - 샤딩 키가 명확히 정의된 경우, 특정 샤드에서만 데이터를 조회하거나 수정할 경우에 사용된다. - Oracle 의 경우, 캐시를 통해 성능을 최적화 한다. ### 프록시 라우팅 (Proxy Routing) - 샤딩 키가 없거나 여러 샤드(혹은 노드) 에서 데이터를 가져와야 하는 경우 사용된다. - 여러 노드에서 데이터를 가져와야 하는 경우. - 요청과 결과가 쿼리 코디네이터를 거쳐야 하기 때문에 추가적인 네트워크 및 처리 오버헤드가 발생하여, 직접 라우팅보다 성능이 낮다. - 쿼리 코디네이터가 중간 역할을 한다. > _**쿼리 코디네이터** 는 클라이언트로부터 받은 SQL 쿼리를 분석하여 어떤 데이터가 필요한지, 어떤 연산이 수행되어야 하는지 파악하고, 최종적으로 쿼리가 효율적으로 실행되기위한 계획을 수립한다. 요청된 데이터가 어느 노드(혹은 샤드)에 저장되어 있는지 결정한다._ - 처리 과정 1. 애플리케이션은 샤딩 키 없는 SQL 쿼리를 생성. 2. 요청은 노드(샤드) 들이 아닌, 쿼리 코디네이터로 전달된다. 3. 쿼리 코디네이터는 메타데이터를 참조하여 관련된 모든 노드(샤드) 를 식별하고 쿼리를 **병렬**로 실행. 4. 각 샤드에서 처리된 결과가 코디네이터로 반환되고, 최종 결과가 애플리케이션으로 전달된다. # 데이터 동기화 - 각 노드가 독립적으로 작동할 수 있으므로, 한 노드에서 발생한 데이터 변경 사항이 다른 노드에 반영되지 않으면 데이터 불일치가 발생할 수 있음. - 두 사용자가 서로 다른 노드에서 동시에 동일한 데이터를 수정하면 시스템은 우선순위를 결정하거나 변경 사항을 병합해야 함. ## 방식 - **동기적 동기화 (Synchronous Synchronization)** : 모든 노드가 변경 사항을 확인하고 업데이트를 완료한 뒤 트랜잭션이 완료된다. 높은 일관성을 제공하기에, 중요한 금융 시스템이나 의료 데이터베이스와 같은 환경에서 적합하다. 네트워크 지연과 성능 저하가 발생할 수 있다. - **비동기적 동기화 (Asynchronous Synchronization)** : 변경 사항이 다른 노드로 전송되지만 즉시 반영되지 않고 나중에 처리된다. 성능이 뛰어나며 대규모 시스템에서 확장성이 좋다. 일시적인 데이터 불일치를 허용하므로, 강력한 일관성이 필요한 경우에는 적합하지 않다. ",
    "url": "/Database/db_distributed_database.html",
    
    "relUrl": "/Database/db_distributed_database.html"
  },"32": {
    "doc": "이벤트 소싱(Event Sourcing)과 CQRS(Command Query Responsibillity Segregation)",
    "title": "이벤트 소싱(Event Sourcing)과 CQRS(Command Query Responsibillity Segregation)",
    "content": "# 이벤트 소싱(Event Sourcing)과 CQRS(Command Query Responsibillity Segregation) ## 이벤트 소싱(Event Sourcing) 이벤트 소싱은 도메인에서 발생하는 변경 사항을 추가 전용 로그에 이벤트로 변경 불가능하게 저장하는 아키텍처 설계 패턴입니다. 이벤트에는 변화의 맥락(무엇, 언제, 왜, 누가)이 포함되어있고, 각 변경 사항이 발생한 순서대로 있어서 도메인의 현재 상태 이상을 볼 수 있습니다. ![alt text](/Database/img/db_event_sourcing_cqrs_1.png) _이벤트 소싱으로 알 수 있는 상태, 출처[Kurrent - What is Event Sourcing?](https://www.kurrent.io/event-sourcing)_ ### 예시 주문 프로세스로 알아보는 이벤트 소싱 - 기존 방식 ![alt text](/Database/img/db_event_sourcing_cqrs_5.png) 1. ORDER 생성: 고객이 200달러의 상품 주문해 청구서 발행 2. ORDER 업데이트: 청구서를 받은 고객이 비용을 지불함 ORDER의 상태가 변함 - 이벤트 소싱 ![alt text](/Database/img/db_event_sourcing_cqrs_6.png) 1. ORDER 추가: 고객이 200달러의 상품을 주문해 청구서 발행 2. ORDER PAYMENT RECEIVED 추가: 고객이 비용을 지불 3. 업데이트 된 ORDER 추가: 지불된 내용을 적용 ORDER PAYMENT RECEIVED라는 이벤트가 캡처되어 순서대로 저장 - 만약 50달러가 할인 행사가 있다면? ![alt text](/Database/img/db_event_sourcing_cqrs_7.png) - 기존 방식: ORDER에서는 200달러의 상품을 150달러에 구매했다는 사실은 알지만, 왜 그렇게 되었는지는 알 수 없습니다. - 이벤트 소싱: 50달러 할인의 내용이 DISCOUNT APPLIED 의 이벤트로 캡처되어 저장되기 떄문에, 이유에 대해서도 알 수 있습니다. 특징 - 데이터 복구 및 디버깅에 유용합니다. - 구현 복잡도고 높고, 이벤트가 많아질수록 성능 관리가 필요합니다. - 데이터 동기화 및 이벤트 스키마 변경 관리가 필요합니다. ### 핵심 내용 - 이벤트(Event) ![alt text](/Database/img/db_event_sourcing_cqrs_8.png) - 도메인에서 발생한 사실을 의미하며, 과거 시제로 언급됩니다. - 단순히 \"발생됐다\" 보다는 \"확실히 변경되었음\"의 의미입니다. - 일반적으로 이벤트 타임스탬프, 주체의 고유 식별자 등과 같은 고유한 메타데이터를 포함합니다. - 불변(immutable)데이터입니다. - 이벤트 스토어(Event Store) ![alt text](/Database/img/db_event_sourcing_cqrs_9.png) - 각 이벤트는 DB에 기록되며, 기존 DB는 \"현재 상태\"를 저장하고, 이벤트 스토어는 \"상태 변경 기록\"을 저장합니다. - 기존 DB에서 데이터는 수정할 수 있지만, 모든 상태 변경은 새로운 이벤트로 추가되며 기존 이벤트를 유지합니다. - 예시: 잘못된 주소로 청구서 발행 이벤트 발생 -> 기존 청구서 무효 이벤트 발생 -> 제대로 된 주소로 청구서 발행 이벤트 발생 => 수정하는 것이 아니라 3개의 이벤트를 저장 - 시간순으로 저장되며, 현재 상태는 저장된 이벤트를 재생(replay)하여 계산됩니다. - 예시: 현재 계좌 잔액이라는 현재 상태는 입금과 출금 이벤트를 순차적으로 처리해 계산됩니다. - 스트림(Stream) ![alt text](/Database/img/db_event_sourcing_cqrs_10.png) - 특정 객체와 관련된 모든 이벤트를 시간 순서대로 저장한 묶음입니다. - 특정 객체는 고유 식별자(보통은 auto increment)를 가지며, 상태를 검색하는 동안 이벤트 순서를 정의하는데 사용하거나 동시성 문제를 감지하는데 사용됩니다. - 특정 객체 내의 이벤트는 스트림 내에서 고유한 위치를 갖습니다. - 프로젝션(Projections) ![alt text](/Database/img/db_event_sourcing_cqrs_2.png) - 이벤트 스트림을 기반으로 특정 상태를 계산하거나, 읽기 모델(Read Model)을 생성하는 과정입니다. - 이벤트 데이터를 사용하여 현재 상태를 보여주는 \"뷰(View)\"를 만드는 것입니다. - 읽기 모델(Read Model)에서 프로젝션 ![alt text](/Database/img/db_event_sourcing_cqrs_3.png) - 쓰기 모델에서 생성된 이벤트를 가져와 읽기 모델 뷰를 계산한 것을 의미하며,이 내용은 다른 DB에 저장되어 사용될 수 있습니다. - 변환(Transformation): 기존 이벤트 데이터를 기반으로 새로운 이벤트를 생성하거나 다른 스트림(Stream)에 추가하는 과정을 의미합니다. 1. 주문 스트림(상품 추가 -> 제거 -> 추가 ...) 2. 변환 과정: 주문의 모든 이벤트를 처리 후 요약(e.g. 가격 합산)을 생성 3. 새로운 결제 이벤트 생성: 2번 과정의 결과를 기반으로 새로운 이벤트 생성 4. 결제 스트림(결제 수단 선택 -> 결제 요청 -> 완료 ...) - 쓰기 모델(Write Model)에서 프로젝션: 스트림 집계(Stream Aggregation) - 이벤트를 순서대로 처리하여 도메인 객체의 현재 상태를 계산하는 과정으로, 주요 목적은 명령(Command)이 실행되기 전에 현재 상태를 다시 계산하여 검증하는 것입니다. - 예를 들어, 상품을 배송하려면 재고가 충분한지 확인해야 하므로, 모든 재고 관련 이벤트를 처리해 현재 재고 상태를 계산합니다. - 프로젝션은 임시적인 데이터로, 언제든 삭제하거나 다시 생성할 수 있습니다. - 프로젝션은 특정 목적에 맞게 해석된 임시적인 뷰로, 현재 상태가 아닙니다. ### 주의점 - 지연 - 시스템은 다양한 시나리오에서 최종 일관성을 고려해 설계해야합니다. - event 게시 과정(application -> event store)과 event에 따라 처리되는 과정을 진행하는 중 추가 변경을 위한 이벤트가 게시되는 상황 - 동시성 - 다중 스레드 혹은 여러 애플리케이션이 동시에 이벤트를 저장하려고 할 수 있는데, 이때 순서가 바뀔 수 있고 이를 주의해야합니다. - 대부분은 모든 이벤트에 timestamp를 추가하는 것으로 방지할 수 있습니다. - 조회 - 조회시에는 재생(replay)해야지만 확인할 수 있습니다. - 스트림의 길이 - 스트림이 큰 경우, 특정 간격으로 스냅샷을 만드는 것이 좋습니다. - 모든 이벤트를 재생(replay)하지 않고, 가장 가까운 스냅샷부터 이벤트를 재생하면 현재 상태를 확인할 수 있습니다. - 불일치 - 충돌이 아니더라도, 일관성과 트랜잭션 부족에서 발생하는 불일치를 해결해야합니다. - 예를 들어, 고객이 해당 품목을 주문하는 동안 재고 감소를 알리는 이벤트가 데이터 저장소에 도착할 수 있습니다. ## CQRS(Command Query Responsibillity Segregation) 애플리케이션에 따라 쓰기 작업의 비율 차이가 높다거나, 쓰기에 대한 데이터와 읽기에 대한 데이터가 다른 등의 이유로 CRUD 아키텍처가 성능을 저하시킬 수 있습니다. CQRS는 명령(Command)과 조회(Query)의 책임(Responsibillity)을 분리(Segregation)하여 각각의 작업에 최적화된 모델을 사용하는 아키텍처 패턴입니다. - 명령(Command) - 시스템 상태를 변경하는 작업으로, 성공한다면 시스템의 상태가 변경됩니다. - 예시: 데이터의 변경(create, update, delete 요청), 비즈니스 로직과 트랜잭션 관리 - 조회(Query) - 데이터를 조회하는 작업으로, 비즈니스 로직 없이 데이터를 가져오는 것에 초점되어있으며, 시스템 상태를 변경하지 않고 실행시마다 동일한 결과를 반환합니다. - 데이터의 조회(query 부분) ![CQRS의 흐름](/Database/img/db_event_sourcing_cqrs_4.png) _CQRS의 흐름, 출처: [AWS Prescriptive Guidance - CQRS 패턴](https://docs.aws.amazon.com/ko_kr/prescriptive-guidance/latest/modernization-data-persistence/cqrs-pattern.html)_ 1. 비즈니스에서는 애플리케이션의 write API를 통해 명령(데이터 추가, 삭제 등)을 전달합니다. 2. 애플리케이션은 들어온 명령에 따라, 작업(검증, 승인, 실행 등)을 진행합니다. 3. 애플리케이션은 write DB에 데이터의 쓰기 명령을 저장합니다. 4. 데이터 쓰기가 write DB에 저장된 후, 이벤트가 트리거 되어 read DB가 업데이트 됩니다. 5. read DB에서도 데이터 쓰기가 저장됩니다. 6. 비즈니스에서는 애플리케이션의 read API를 통해 조회를 진행합니다. 7. 애플리케이션은 조회 쿼리를 read DB에서 실행합니다. ### 구성 방법 #### 단일 데이터 저장소 ![alt text](/Database/img/db_event_sourcing_cqrs_11.png) - 쓰기 모델 - 데이터를 업데이트하거나 유지하는 명령을 처리하도록 설계 - 검증 및 도메인 로직, 트랜잭션 무결성, 비즈니스 프로세스 최적화가 포함됩니다. - 읽기 모델 - 데이터 검색을 위한 쿼리를 제공하도록 설계 - 프레젠테이션 계층에 최적화된 DTO, 프로젝션(view)을 생성하는데 중점을 둡니다. - 도메인 로직을 피함으로써 쿼리 성능과 응답성을 향상 시킵니다. ### 분리된 데이터 저장소 별도의 데이터 저장소를 사용하는 경우 둘 다 동기화 상태를 유지해야 합니다. 일반적으로 쓰기 모델이 데이터베이스를 업데이트할 때 이벤트를 게시하고 읽기 모델이 이를 사용하여 데이터를 새로 고치는 방식입니다. ![alt text](/Database/img/db_event_sourcing_cqrs_12.png) - 읽기 데이터 저장소 - 쿼리에 최적화된 자체 데이터 스키마를 사용할 수 있습니다. - 쓰기 저장소의 읽기 전용 복제본이거나 다른 구조를 가질 수 있습니다. ### 특징 - 각각 최적화: 쓰기와 읽기 작업의 성격이 다르기 때문에, 각각에 최적화된 데이터 모델이나 기술을 사용하는 것이 좋습니다. - 명령에는 nosql, 읽기에는 RDB와 같이 DB 조합해 구현할 수 있다. - 읽기 데이터 저장소: 실체화된 뷰를 저장하면 애플리케이션은 쿼리할 때 복잡한 조인을 피할 수 있습니다. - 관심사 분리: 쓰기 측은 일반적으로 복잡한 비즈니스 로직을 처리, 읽기 측은 단순하게 유지하고 쿼리 효율성에 집중 - 메시징 과제: 동기화 유지시 메시징 처리에 대한 문제를 고려해야합니다. - 일관성 문제: 저장소가 분리된 방식에서는 일관성 문제가 발생할 수 있습니다. ## 이벤트 소싱과 CQRS의 관계 > “You need to look at CQRS not as being the main thing. CQRS was a product of its time and meant to be a stepping stone towards the ideas of Event Sourcing.” > > : (번역 내용을 간단히 요약하자면)CQRS가 중요한게 아니다. CQRS는 이벤트 소싱을 향한 디딤돌이였다. > > \"A Decade of DDD, CQRS, Event Sourcing\"에서 Greg Young 이벤트 소싱은 시스템 상태를 이벤트로 저장하며, CQRS와 결합하면 강력한 확장성과 유연성을 제공합니다. ![alt text](/Database/img/db_event_sourcing_cqrs_13.png) - 쓰기 측(Write Side): 상태 변경이 일어나는 곳으로, 상태변경을 이벤트 생성하고 저장합니다. - e.g. check out - 읽기 측(Read Side): 조회하는 작업을 하는 곳으로, 저장된 이벤트를 기반으로 데이터를 조회하기 위한 읽기 모델을 생성합니다. - e.g. Get order overview ![alt text](/Database/img/db_event_sourcing_cqrs_14.png) - 사용자가 명령(Command)을 실행하면 쓰기 측에서 이벤트가 생성됩니다. - 생성된 이벤트는 이벤트 저장소에 기록되며, 프로젝션이 이를 구독하여 읽기 모델을 업데이트합니다. - 읽기 모델은 사용자 인터페이스(UI)나 보고서에서 데이터를 빠르게 조회할 수 있도록 최적화된 형태로 제공됩니다. ![alt text](/Database/img/db_event_sourcing_cqrs_15.png) - 프로젝션은 원래 단일 스트림만 구독해 특정 데이터를 터리했지만, 실제 비스니스 요구상황에서는 여러 개의 스트림을 읽어 읽기 모델을 생성해야하는 경우가 많습니다. ![alt text](/Database/img/db_event_sourcing_cqrs_16.png) - 더 확장한다면, 이처럼 모든 이벤트 스트림을 읽어야하는 경우도 발생합니다. (e.g. dashboard) - 이런 상황에서는 집계 아이디(Aggregate ID)가 매우 중요합니다. - 각 이벤트는 특정 도메인 객체(e.g. 고객, 주문 etc)와 연관되어있습니다. - 이 연관성을 나타내는 것이 집계 아이디(Aggregate ID) 또는 식별자 입니다. - 프로젝션은 여러 이벤트 스트림에서 데이터를 가져올 때, 이 식별자를 기준으로 데이터를 연결하고 통합합니다. ## 출처 - [Kurrent - What is Event Sourcing?](https://www.kurrent.io/event-sourcing) - [Kurrent - Event Sourcing and CQRS](https://www.kurrent.io/blog/event-sourcing-and-cqrs) - [AWS Prescriptive Guidance - CQRS 패턴](https://docs.aws.amazon.com/ko_kr/prescriptive-guidance/latest/modernization-data-persistence/cqrs-pattern.html) - [microsoft learn- event-sourcing](https://learn.microsoft.com/ko-kr/azure/architecture/patterns/event-sourcing) - [microsoft learn- CQRS](https://learn.microsoft.com/ko-kr/azure/architecture/patterns/cqrs) 출처는 아니지만 관련된 글 - [우아한형제들 기술블로그 - [배민스토어] 배민스토어에 이벤트 기반 아키텍처를 곁들인…](https://techblog.woowahan.com/13101/) - [AWS Prescriptive Guidance - 이벤트 소싱 패턴](https://docs.aws.amazon.com/ko_kr/prescriptive-guidance/latest/cloud-design-patterns/event-sourcing.html) ",
    "url": "/Database/db_event_sourcing_cqrs.html",
    
    "relUrl": "/Database/db_event_sourcing_cqrs.html"
  },"33": {
    "doc": "실행 계획(EXPLAIN) 분석",
    "title": "실행 계획(EXPLAIN) 분석",
    "content": "# 실행 계획(EXPLAIN) 분석 ## EXPLAIN이란? - SQL 실행 전에 MySQL이 어떤 방식으로 쿼리를 처리할지 예측해주는 명령어입니다. - 실행 계획을 통해 **쿼리 최적화 포인트를 파악**할 수 있습니다. - 복잡한 SQL일수록 EXPLAIN은 필수입니다. ```java # 사용예시 EXPLAIN SELECT * FROM users WHERE age > 30; ``` ## EXPLAIN 기본 구성(MySQL 8.0 기준) - **`id`** - `id`는 실행 계획의 각 SELECT 문을 구분하는 고유 식별자입니다. - 숫자가 클수록 나중에 실행되며, 동일한 `id` 값을 가진 경우 병렬적으로 실행될 수도 있습니다. - 서브쿼리가 포함된 경우 여러 개의 `id`가 표시됩니다 - **`select_type`** - `select_type`은 SELECT 문이 어떤 형태로 작성되었는지를 나타냅니다. - MySQL 옵티마이저가 쿼리를 어떻게 분류하고 처리하는지를 이해할 수 있는 단서가 됩니다. | 값 | 설명 | --- | --- | `SIMPLE` | 서브쿼리나 UNION이 없는 단순 SELECT 문입니다. | `PRIMARY` | 가장 바깥쪽의 SELECT 문입니다. | `SUBQUERY` | WHERE 절이나 SELECT 절 안에 포함된 서브쿼리입니다. | `DERIVED` | FROM 절 안의 서브쿼리입니다. 실행 시 파생 테이블로 처리됩니다. | `DEPENDENT SUBQUERY` | 외부 쿼리 컬럼에 의존하는 서브쿼리입니다. | `UNION` | UNION 또는 UNION ALL 문에서 첫 번째 SELECT 문을 제외한 나머지 SELECT 문입니다. | `DEPENDENT UNION` | 외부 쿼리에 의존하는 UNION SELECT 문입니다. | `UNION RESULT` | UNION 결과를 저장하는 임시 테이블을 SELECT 하는 부분입니다. | - **`type`** - `type`은 옵티마이저가 테이블에 접근하는 방식을 나타냅니다. - 실행 계획에서 가장 중요하게 보는 항목 중 하나이며, 쿼리의 성능을 좌우합니다. - `type`의 목표는 **최소한 `range` 이상**을 사용하는 것입니다. `ALL`이나 `index`만 사용된다면 인덱스 추가를 고려해야 합니다. | 값 | 설명 | --- | --- | `ALL` | 전체 테이블 스캔입니다. 인덱스를 사용하지 않으므로 가장 느립니다. | `index` | 인덱스를 처음부터 끝까지 스캔합니다. ALL 보다는 낫지만 여전히 비효율적일 수 있습니다. | `range` | 인덱스 범위를 검색합니다. (예: `age > 30`) | `ref` | 특정 값에 대해 인덱스를 통해 여러 행을 검색합니다. | `eq_ref` | 유일 인덱스(PK 또는 UNIQUE)에 의해 정확히 하나의 행이 검색됩니다. | `const` | 상수 값을 기반으로 하나의 행만 조회할 때 사용됩니다. | `system` | 하나의 행만 있는 테이블에서 사용됩니다. 거의 사용되지 않습니다. | - `possible_keys` - `possible_keys`는 해당 쿼리에서 사용될 수 있는 인덱스 목록입니다. - 옵티마이저가 고려할 수 있는 모든 인덱스를 보여줍니다. - 이 값이 `NULL`이면 사용 가능한 인덱스가 없다는 의미이므로, 인덱스 추가를 검토해야 합니다. - **`key`** - `key`는 실제로 사용된 인덱스를 나타냅니다. - `possible_keys`에 여러 인덱스가 나열되어 있더라도, 그 중 `key`에 표시된 하나만 선택됩니다. - `NULL`이면 인덱스를 사용하지 않았음을 의미합니다. - `key_len` - `key_len`은 MySQL이 인덱스를 사용할 때 몇 바이트를 사용했는지를 나타냅니다. - 복합 인덱스를 사용하는 경우, 일부 컬럼만 사용되었다면 그에 맞는 길이만 계산됩니다. - 해당 값이 작을수록 인덱스 전체가 활용되지 않았을 가능성이 있습니다. - `ref` - `ref`는 인덱스 검색 시 사용된 상수 값이나 컬럼을 의미합니다. - 조인 조건에 의해 어떤 방식으로 인덱스를 탐색했는지를 파악할 수 있습니다. - 예: `const`, `func`, `table_name.column_name` 등이 표시될 수 있습니다. - **`rows`** - `rows`는 MySQL 옵티마이저가 예측한 탐색 대상 행의 수입니다. - 실제 결과 행 수가 아니라, 내부 통계와 조건에 따라 예측된 값입니다. - 서브쿼리나 조인에서 이 값이 너무 크면 성능 저하가 발생할 수 있으며, 이 경우 인덱스 추가 또는 쿼리 구조 개선이 필요합니다. - **`Extra`** - `Extra`는 쿼리 실행 과정에서 발생하는 추가적인 정보나 조건을 설명합니다. - 쿼리 성능에 큰 영향을 미치는 힌트들이 포함되므로, 반드시 주의 깊게 확인해야 합니다. | 값 | 설명 | --- | --- | `Using where` | WHERE 절을 통해 조건을 필터링하고 있습니다. | `Using index` | 인덱스만으로 데이터를 처리하였으며, 테이블 접근이 발생하지 않습니다. (커버링 인덱스) | `Using temporary` | 쿼리 수행 시 임시 테이블을 사용하고 있습니다. (GROUP BY, ORDER BY 등에서 발생) | `Using filesort` | 정렬 작업을 위해 메모리나 디스크 기반 정렬을 수행하고 있습니다. 성능 저하의 주요 원인입니다. | `Range checked for each record` | 조인 대상 테이블에 적절한 인덱스가 없어, 각 레코드마다 범위 조건을 검사하고 있습니다. | `Using join buffer` | 조인 버퍼를 사용하여 블록 단위 조인을 수행하고 있습니다. | `Not exists` | LEFT JOIN 시 조건을 만족하는 행을 찾으면 이후 탐색을 중단합니다. | `Distinct` | 중복을 제거하기 위해 이미 처리한 값과 동일한 Row는 건너뜁니다. | `Using index for group-by` | GROUP BY 작업이 인덱스를 통해 처리되어 효율적으로 동작합니다. | ## 예시1) WHERE 조건에 인덱스가 없는 경우 ### - 쿼리문 ```sql SELECT * FROM employees WHERE last_name = 'Kim'; ``` ### - EXPLAIN 결과 | id | select_type | table | type | key | rows | Extra | --- | --- | --- | --- | --- | --- | --- | 1 | SIMPLE | employees | ALL | NULL | 300000 | Using where | ### - 해석 - `table = employees` - employees 테이블을 대상으로 탐색합니다. - `select_type = SIMPLE` - 서브쿼리나 UNION 없는 단순 SELECT입니다. - `type = ALL` - **Full Table Scan**입니다. - 인덱스를 사용하지 않고 테이블 전체를 처음부터 끝까지 훑습니다. - `key = NULL` - **사용된 인덱스가 없습니다**. - `rows = 300000` - **MySQL 옵티마이저가 예상하는 탐색 대상 행의 수**입니다. - **MySQL 옵티마이저가 내부 통계정보를 기반으로 계산한 추정값**입니다. - `Extra = Using where` - 조건문을 사용하여 필터링을 하고 있습니다. ### - 문제점 - `type = ALL`: 전체 테이블 스캔 - `key = NULL`: 인덱스 미사용 - 데이터 건수가 많을 경우 성능 저하 ### - 개선 방법 - `last_name` 컬럼에 인덱스를 생성합니다. ### - 개선 후 Explain 결과 | id | select_type | table | type | key | rows | Extra | --- | --- | --- | --- | --- | --- | --- | 1 | SIMPLE | employees | ref | idx_last_name (앞서 생성해준 인덱스) | 50 | Using where | ## 예시 2) ORDER BY + LIMIT 시 정렬 인덱스 없는 경우 ### - 쿼리문 ```sql SELECT * FROM employees ORDER BY hire_date DESC LIMIT 10; ``` ### - EXPLAIN 결과 | id | select_type | table | type | key | rows | Extra | --- | --- | --- | --- | --- | --- | --- | 1 | SIMPLE | employees | ALL | NULL | 300000 | Using filesort | ### - 해석 - `table = employees` - employees 테이블을 대상으로 탐색합니다. - `select_type = SIMPLE` - 서브쿼리나 UNION 없는 단순 SELECT입니다. - `type = ALL` - **Full Table Scan**입니다. - 인덱스를 사용하지 않고 테이블 전체를 처음부터 끝까지 훑습니다. - `key = NULL` - **사용된 인덱스가 없습니다**. - `rows = 300000` - **MySQL 옵티마이저가 예상하는 탐색 대상 행의 수**입니다. - **MySQL 옵티마이저가 내부 통계정보를 기반으로 계산한 추정값**입니다. - `Extra = Using filesort` - `Using filesort`는 MySQL이 **ORDER BY 절에 의해 정렬을 직접 수행해야 할 때** 표시됩니다. - 즉, 원하는 정렬 순서를 만들기 위해 **메모리나 디스크에 데이터를 임시로 정렬**하는 과정을 거친다는 뜻입니다. - 정렬에 사용된 컬럼이 인덱스에 포함되어 있고, 그 인덱스 순서대로 정렬이 가능하다면 filesort를 사용하지 않습니다. ### - 문제점 - 정렬 인덱스 없습니다. - 데이터 건수가 많을 경우 성능 저하문제가 발생합니다. ### - 개선 방법 - 정렬 기준 컬럼에 **정렬 방향까지 포함된 인덱스**를 생성합니다. ```sql CREATE INDEX idx_hire_date_desc ON employees(hire_date DESC); ``` ### - 개선 후 EXPLAIN 결과 | id | select_type | table | type | key | rows | Extra | --- | --- | --- | --- | --- | --- | --- | 1 | SIMPLE | employees | index | idx_hire_date_desc | 10 | Using index | ## 정리 - `id`, `select_type`, `type`, `key`, `rows`, `Extra` 컬럼을 중심으로 실행 계획을 분석합니다. - 특히 `type`이 `ALL`(Full Table Scan)이거나 `Extra`에 `Using filesort`, `Using temporary`가 있다면 쿼리 성능 개선이 필요합니다. - 인덱스가 어떻게 사용되었는지를 `possible_keys`, `key`, `key_len`, `ref`를 통해 정밀하게 확인해야 합니다. ",
    "url": "/Database/db_explain.html",
    
    "relUrl": "/Database/db_explain.html"
  },"34": {
    "doc": "Index? 그게뭔데!",
    "title": "Index? 그게뭔데!",
    "content": "## Index? 그게뭔데! 먼저 인덱스는 테이블에서 내가 자주 사용하는 컬럼들을 중심으로 서브테이블을 생성해놓는 것이라고 생각해도 좋을거같다. 테이블에는 많은 정보가 있고 기본적으로 PK를 기준으로 정렬되어있기 때문에 PK가 아닌 다른 데이터로 검색하려면 전체 데이터에서 찾을 수 밖에 없다. 그래서 검색에 자주 사용되는 컬럼을 주로 인덱스로 지정하면, 해당 컬럼에 대한 데이터를 사본으로 들고 있으며 그 컬럼을 기준으로 정렬 해놓는다. 그리고 그 컬럼에서 원하는 데이터를 찾으면, 그 데이터가 실제 테이블에서는 어느 위치인지에 대해 값을 가지고 있게 된다. 그래서 인덱스를 추가하면 속도가 빨라지지만, 데이터를 중복으로 저장하게되며 디스크의 용량을 더 차지하게 된다. 그리고 데이터의 추가, 수정이 생길때마다 인덱스에서도 처리를 해야해서 데이터 처리 속도는 느려진다. 그래서 꼭 필요한 곳에서만 사용되어야한다. 여기까지는 나를 포함해 많은 분들이 알고 있을 것이다. ## 도대체 어떻게 빨라질 수 있는거야? 그럼 정확히 인덱스는 어떻게 사용될까? 그리고 또 언제 사용될까? - `where`절을 빠르게 찾을때 - 여러 인덱스가 있다면, 가장 적은 수의 행을 찾는 인덱스를 사용 - 다중 열 인덱스가 있다면, 왼쪽부터 순서에 맞는 경우 - e.g. 인덱스 - col1, col2, col3, 사용 - col1 / col1, col2 / col1, col2, col3 - 동일한 유형과 크기로 선언됐을때: varchar(10)과 char(15)는 안되고, varchar(10)과 char(10)은 가능! - select에 컬럼이 모두 인덱스 내에 있는 경우(=[커버링 인덱스](#언제-사용될까-커버링-인덱스)) - `MIN()`, `MAX()`를 이용하는 컬럼이 인덱스에 있을때 - `ORDER BY`와 `GROUP BY` 에 해당하는 컬럼이 인덱스에 있을때 > 커버링 인덱스 > 쿼리에서 검색한 모든 열을 포함하는 인덱스 > 이런 경우에는 실제 table에서 검색하지 않고, 인덱스에서만 검색하는 것으로 끝냄! > 그래서 disk I/O를 절약하게 된다. 만약 index를 추가했는데, 속도가 같다면 `EXPLAIN`을 이용해 **해당 인덱스가 사용되고 있는지 확인** 할 수 있다. ## Index는 어떻게 생긴거야? MySQL을 기준으로 보자면, 크게 4가지의 인덱스 구조가 있는데 각 구조를 확인해보자. ### B-TREE Index (Balanced Tree) 실제 이진 탐색 트리에서 확장된 구조로, 원래는 자식 노드를 2개밖에 가지지 못하는 트리구조에서 N개의 자식을 가질 수 있도록 했다. 이진 탐색 트리는 부모 노드를 기준으로 작은 값은 왼쪽, 큰 값은 오른쪽에 있는 자식노드 값으로 저장했는데 이와 달리 부모노드에 여러개의 데이터를 넣을 수 있고, 자식노드는 각 부모노드의 데이터를 기준으로 삼아 범위가 설정된다. ![b-tree 구조 시각화](/Database/img/db_index_b_tree.png) _b-tree 구조 시각화, 출처 : [[MySQL] B-Tree로 인덱스(Index)에 대해 쉽고 완벽하게 이해하기](https://mangkyu.tistory.com/286)_ 이와같이 부모가 (N-1)의 데이터를 가지면, 그 데이터를 기준으로 N개의 자식 노드가 생기게된다. 그리고 각 자식노드도 같은 구조의 서브트리를 갖게된다. 특징 : 보통 index라고 했을 때 가장 많이 사용되고, index의 기본 구조로 설정되어있다. : 항상 오름차순으로 정렬이 된다. : 이진 탐색을 이용할 수 있기에 `O(log N)`의 속도로 탐색 가능해 검색 속도가 빠르다. : 범위 검색(`=`,``, `>=`,`BETWEEN`)에 적절하다. 단, 상수 문자열(='검색어')의 경우 와일드카드(`%`)가 **문자열 시작에 포함된다면** 사용되지 않는다. : 단점은 데이터의 삽입/삭제시 균형을 유지해야해서 비용이 발생하게된다. 삽입시에 노드의 데이터가 가득차면 분할을 발생시키고, 삭제시에는 병합하거나 재배열을 통해 트리의 균형을 유지한다. > B-tree에 더 궁금하거나 자세히 알고싶다면, 공부하면서 찾은 좋은 자료를 소개한다. > > [데이터베이스 인덱스는 왜 'B-Tree'를 선택하였는가](https://helloinyong.tistory.com/296) > : 왜 index에서 B-tree를 구조를 기본으로 사용하게 되었는지에 대해 정리한 글로, 다양한 자료구조까지 같이 설명하고 있다. > > [(1부) B tree의 개념과 특징, 데이터 삽입이 어떻게 동작하는지를 설명합니다! (DB 인덱스과 관련있는 자료 구조)](https://www.youtube.com/watch?v=bqkcoSm_rCs&list=PLcXyemr8ZeoREWGhhZi5FZs6cvymjIBVe&index=26) > : B-tree에 대해 다양한 시각 자료를 통해 쉽게 설명하고 있다. ### Hash Index Hash는 이름에서 유추하듯 해시함수를 이용한 구조로, HashMap과 같은 구조로 key값을 hash 함수결과에 따라 결정된다. 그래서 HashMap과 같이 `O(1)`매우 빠른 검색속를 자랑한다. 그런데 기본인덱스로 설정되지 않은 이유는 뭘까? hash index는 `=` 연산에서만 사용된다는 점이다. 우리는 DB에서 검색시 등가비교(`=`)보다 범위 검색(`=`,``, `>=`,`BETWEEN`, `LIKE`)을 더 자주 이용하는데, hash index는 해시 결과를 기반으로 하는 인덱스라 범위 검색이 불가능하다. 특징 : 등가비교에서는 `O(1)`의 매우 빠른 속도로 조회된다. MySQL의 MEMORY 엔진에서만 지원, InnoDB에서는 Hash Index를 자동으로 생성하는 Adaptive Hash Index를 사용한다. : 범위 검색, 정렬(ORDER BY), 그룹화(GROUP BY)가 필요한 경우에는 사용될 수 없다. : 해시 충돌 발생시에는 Linked List 또는 Open Addressing 방식이 사용된다. 어디에 사용되면 좋을까? : Key-Value 기반의 빠른 조회가 필요한 경우(session_id, API token 같은 고유한 값 조회시) : 자주 조회되지만 업데이트가 거의 없는 데이터 ### Inverted Index 문장을 단어(토큰) 단위로 분해하여, 각 단어가 어떤 문서에 포함되는지를 색인하는 방식이다. elasticsearch에서도 `text`타입에 대해서는 inverted index가 생성되는데 이와 같다. 토큰이라고 하면, `MySQL is fast`라는 문장이 있을 때 특정 기준(ex. 공백)으로 잘라낸 `MySQL`, `is`, `fast`와 같은 것을 말한다. 텍스트 필드의 모든 단어를 자동으로 색인하고, 역색인 구조를 생성하여 빠른 검색을 가능하게 한다. ![inverted-index 구조 시각화](/Database/img/db_index_inverted_index.png) _inverted-index 구조 시각화_ 왼쪽이 기존 방식이였다면, 오른쪽이 inverted indexd에 해당된다. 특징 : 자연어 검색에 최적화 되어있어 LIKE '%검색어%'보다 훨씬 빠르다. : 대신 데이터의 삽입/삭제 시마다 역색인에 대한 비용이 발생하게 된다. - 삽입 - 데이터를 전부 토큰화 -> (이 데이터에만 있는 토큰이라면 역색인하는 단어에 추가하고) -> 데이터의 key 값을 저장한다. - 삭제 - 해당 데이터와 연결된 모든 단어를 역색인에서 제거한다. : 정확한 값 검색이나 숫자나 날짜필드에 대한 검색에서는 권장되지 않는다. 어디에 사용되면 좋을까? : 검색어가 포함된 문서를 찾는 경우(사용자가 입력한 검색어를 포함하는 문서를 빠르게 찾을 수 있음) : 자연어 처리(NLP) 기반 검색 ### R-Tree Index R-tree는 다차원 데이터를 저장하는 트리 구조로, B-Tree처럼 계층적 구조를 가진다. 대신 저장되는 데이터가 B-TREE는 1차원 데이터를 R-TREE는 다차원(2D, 3D)데이터를 저장한다는 차이가 있다. 다차원 데이터란 여러 개의 값(좌표)로 표현되는 데이터로 예시로는 위치 정보, 3D 모델, 색상 정보 등이 있다. MySQL은 공간 정보의 저장 및 검색을 위해 `POINT`, `LINE`, `POLYGON`, `GEOMETRY`라는 데이터 타입을 제공한다. > 공간 데이터 타입 > MySQL에는 OpenGIS 클래스에 해당하는 공간 데이터 유형이 있는데 아래와 같다. > ![공간 데이터 타입](/Database/img/db_index_geo_type.png) > _공간 데이터 타입, 출처 : [[Real MySQL 8.0] R-Tree와 전문 검색 인덱스](https://jjingho.tistory.com/169) > > GEOMETRY > : 모든 공간 데이터를 위한 일반적인 공간 데이터 타입입니다. ￼ > POINT > : X, Y 좌표를 나타내는 0차원 지리 공간 데이터입니다. > LINESTRING > : 선분의 집합을 나타내는 1차원 지리 공간 데이터입니다. > POLYGON > : 면을 나타내는 2차원 지리 공간 데이터입니다. > > 이 외에도 MULTIPOINT, MULTILINESTRING, MULTIPOLYGON, GEOMETRYCOLLECTION가 있는데, 이는 공식 문서를 참고하자. 특징 : B-tree 구조로 이진 탐색을 통해 조회된다. : B-tree는 1차원 데이터로 비교가 쉬웠는데, R-tree는 다차원 데이터로 [Bounding Box](#r-tree-index-bounding-box)를 비교하는 방식을 이용한다. 부모 노드는 자식 노드들의 Bounding Box를 포함하는 구조를 가진다. : 검색시에는 `ST_Contains(A, B)`, `ST_Within(A, B)`, `ST_Intersects(A, B)`, `ST_Distance(A, B)`등을 이용해 범위 검색을 하게 된다. : 속도의 향상을 위해서는 Bounding Box 크기와 겹치는 영역 최소화하는 것과 트리가 너무 한쪽으로 치우치지 않도록 유지하게 한다. > Bounding Box > : 다차원 공간 데이터를 감싸는 최소한의 직사각형이다. > > ![bounding box](/Database/img/db_index_bounding_box.png) > _Bounding Box, 출처 : [[Real MySQL 8.0] R-Tree와 전문 검색 인덱스](https://jjingho.tistory.com/169)_ 어디에 사용되면 좋을까? : 위치 기반 검색과 지리 정보 시스템(GIS)에 적합 : 지도 데이터, 경로 탐색, 공간 분석, 이미지 검색 등에서 자주 활용 ",
    "url": "/Database/db_index.html",
    
    "relUrl": "/Database/db_index.html"
  },"35": {
    "doc": "조인(JOIN)",
    "title": "조인(JOIN)",
    "content": "## 조인(JOIN) ### 조인이란? 조인이란 데이터베이스에서 두 개 이상의 테이블을 연결(결합)하여 데이터를 조회하는 방법을 말합니다. 보통 두 테이블 간에 공통으로 갖고 있는 컬럼(키 값)을 이용해, 하나의 테이블처럼 데이터를 추출하는 데에 사용됩니다. ### 조인의 종류 조인은 크게 다음과 같은 유형으로 나눌 수 있습니다. 1. **INNER JOIN (내부 조인)** 2. **LEFT (OUTER) JOIN (왼쪽 외부 조인)** 3. **RIGHT (OUTER) JOIN (오른쪽 외부 조인)** 4. **FULL (OUTER) JOIN (전체 외부 조인)** - MySQL에서는 직접 지원하지 않음 5. **CROSS JOIN (교차 조인)** 아래에서 각각의 조인 유형과 MySQL 예시를 살펴보겠습니다. --- ## 1. INNER JOIN (내부 조인) 두 테이블에서 조인 조건에 일치하는 행만 반환합니다. 즉, 두 테이블 모두 조건에 부합하는 데이터가 있을 때만 결과가 나옵니다. #### 문법 ```sql SELECT [칼럼 목록] FROM 테이블A INNER JOIN 테이블B ON 테이블A.조인컬럼 = 테이블B.조인컬럼; ``` #### 예시 ```sql -- 예시로 'employees' 테이블과 'departments' 테이블이 있다고 가정 -- employees(department_id), departments(department_id) SELECT e.employee_id, e.name, d.department_name FROM employees e INNER JOIN departments d ON e.department_id = d.department_id; ``` - `employees` 테이블과 `departments` 테이블에서 `department_id`가 동일한 행만 추출합니다. - `employees` 테이블에 있는 부서 정보와, `departments` 테이블에 있는 상세 부서명을 함께 조회할 수 있습니다. ![](/Database/img/db_join_1.png) --- ## 2. LEFT (OUTER) JOIN (왼쪽 외부 조인) 왼쪽 테이블(LEFT에 명시된 테이블)을 기준으로, 조인 조건에 맞는 행은 매칭하고, 맞지 않는 행이 있어도 왼쪽 테이블의 데이터는 모두 반환합니다(오른쪽 테이블에서 매칭되는 값이 없으면 NULL로 표시). #### 문법 ```sql SELECT [칼럼 목록] FROM 테이블A LEFT JOIN 테이블B ON 테이블A.조인컬럼 = 테이블B.조인컬럼; ``` #### 예시 ```sql SELECT e.employee_id, e.name, d.department_name FROM employees e LEFT JOIN departments d ON e.department_id = d.department_id; ``` - `employees` 테이블 기준으로 모든 직원을 보여줍니다. - 직원이 소속된 부서가 존재하지 않는 경우(매칭되는 `department_id`가 없는 경우), `department_name` 컬럼은 NULL이 됩니다. ![](/Database/img/db_join_2.png) --- ## 3. RIGHT (OUTER) JOIN (오른쪽 외부 조인) LEFT JOIN과 반대로, 오른쪽 테이블(RIGHT에 명시된 테이블)을 기준으로 모든 행을 반환합니다. 조인 조건이 맞지 않는 경우 왼쪽 테이블 값이 NULL로 표시됩니다. #### 문법 ```sql SELECT [칼럼 목록] FROM 테이블A RIGHT JOIN 테이블B ON 테이블A.조인컬럼 = 테이블B.조인컬럼; ``` #### 예시 ```sql SELECT e.employee_id, e.name, d.department_name FROM employees e RIGHT JOIN departments d ON e.department_id = d.department_id; ``` - `departments` 테이블에서 모든 부서를 다 보여주고, 소속 직원을 조인합니다. - 어떤 부서에 소속된 직원이 없다면, 해당 부서 행의 직원 정보(employee_id, name)는 NULL이 됩니다. ![](/Database/img/db_join_3.png) --- ## 4. FULL (OUTER) JOIN (합집합 조인) 두 테이블에서 일치하는 모든 행 + 왼쪽 테이블만 갖는 행 + 오른쪽 테이블만 갖는 행을 모두 보여주는 조인입니다. 즉, 조건에 만족하지 않는 행까지 모두 표기합니다. **MySQL에서는 FULL OUTER JOIN을 직접 지원하지 않기 때문에**, 다음과 같은 방식으로 `LEFT JOIN`과 `RIGHT JOIN`을 `UNION`으로 결합해 구현할 수 있습니다. #### 예시 ```sql SELECT e.employee_id, e.name, d.department_name FROM employees e LEFT JOIN departments d ON e.department_id = d.department_id UNION SELECT e.employee_id, e.name, d.department_name FROM employees e RIGHT JOIN departments d ON e.department_id = d.department_id; ``` - 이렇게 하면 두 결과를 합쳐서 완전한 조인 효과를 낼 수 있습니다. ![](/Database/img/db_join_4.png) --- ## 5. CROSS JOIN (교차 조인) 교차 조인은 두 테이블의 모든 행을 곱(Cartesian Product)하여 반환합니다. 테이블 A에 n개 행, 테이블 B에 m개 행이 있으면 결과는 n×m행이 됩니다. #### 문법 ```sql SELECT [칼럼 목록] FROM 테이블A CROSS JOIN 테이블B; ``` #### 예시 ```sql SELECT e.name, d.department_name FROM employees e CROSS JOIN departments d; ``` - `employees` 테이블의 모든 직원과 `departments` 테이블의 모든 부서가 조합된 형태로 결과가 나옵니다. - 실제 비즈니스 로직에서는 잘 사용되지 않지만, 특정 경우(모든 가능한 조합이 필요한 경우)에만 사용합니다. ## 간단 정리 - **INNER JOIN**: 조건에 맞는 행만 - **LEFT JOIN**: 왼쪽 테이블 기준으로 모두 + 오른쪽 일치 - **RIGHT JOIN**: 오른쪽 테이블 기준으로 모두 + 왼쪽 일치 - **FULL JOIN**: 양쪽 테이블 모두(단, MySQL에서는 LEFT + RIGHT + UNION으로 사용) - **CROSS JOIN**: 카테시안 곱(조건 없이 모든 행 조합) ## 참고 자료 - MySQL 공식 문서: https://dev.mysql.com/doc/ - 면접을 위한 CS 전공지식 노트, 주홍철 ",
    "url": "/Database/db_join.html",
    
    "relUrl": "/Database/db_join.html"
  },"36": {
    "doc": "데이터 마이그레이션 정리 노트",
    "title": "데이터 마이그레이션 정리 노트",
    "content": "# 데이터 마이그레이션 정리 노트 ## 데이터 마이그레이션 정의 **데이터 마이그레이션(Data Migration)**은 한 시스템이나 환경에서 다른 시스템이나 환경으로 데이터를 이동하는 전체 프로세스를 의미합니다. 일반적으로 시스템 교체, 업그레이드, 통합 또는 분리 시 수행하며, 데이터의 손실 없이 정확하게 이동하고 서비스 중단(다운타임)을 최소화하는 것이 중요합니다. 일반적으로 다음과 같은 상황에서 수행됩니다. - 구형 데이터베이스 시스템에서 최신 데이터베이스 시스템으로 교체할 때 - 온프레미스(On-premise) 환경에서 클라우드 환경으로 데이터를 이전할 때 - 하나 이상의 데이터베이스 시스템을 통합하거나, 시스템을 분리할 때 ### 주요 용어 정리 - ETL: 데이터 추출, 변환, 적재 프로세스 - 스키마 매핑: 원본과 대상 데이터베이스 간 스키마 연결 및 조정 - 데이터 정합성: 데이터가 원본과 대상 간 일치하는 상태 - 다운타임: 시스템 서비스가 일시적으로 중단되는 시간 - CDC: 실시간으로 데이터 변경을 캡처해 복제하는 기술 ## 데이터 마이그레이션 5단계 데이터 마이그레이션은 일반적으로 다음과 같은 절차로 진행됩니다. 1. 계획(Planning) - 이전할 데이터의 범위 및 일정 계획 수립 - 위험 요소 평가 및 대응 방안 마련 2. 추출(Extract) - 기존 시스템에서 데이터를 추출(Export) 3. 변환(Transform) - 새 시스템에 맞게 데이터 형태(스키마 등)를 변경 및 정제(Cleansing) 4. 적재(Load) - 변환된 데이터를 새로운 시스템에 삽입(Import) 5. 검증(Validation) - 이전 후 데이터 정합성 및 무결성 확인 ## 데이터 마이그레이션 기법 ### 전체 덤프 및 로드 방식(Full Dump & Load) - **정의**: 데이터를 전체적으로 덤프(Export)한 후 일괄적으로 새로운 환경에 로드(Import) - 방법: 데이터베이스의 백업 파일을 생성한 뒤 새로운 시스템에 복원하는 과정을 예시로 들수 있다. - **장점**: 구현이 간단함 - **단점**: 서비스 중단(다운타임) 발생 가능 - **적용 상황**: 작은 데이터 규모, 다운타임 허용 가능한 환경 ### ETL(Extract, Transform, Load) - **정의**: 데이터를 추출(Extract), 변환(Transform), 적재(Load)하는 과정 - 방법: 원본시스템에서 데이터 추출 -> 대상 시스템에 맞도록 데이터 형식 변환/정제 -> 변환된 데이터를 대상에 적재 - **장점**: 복잡한 데이터 변환 로직의 적용과 데이터 정제 가능, 데이터 품질을 높일 수 있음 - **단점**: 실시간 처리가 어려움 - **적용 상황**: 데이터 스키마 변경, 데이터 정제 필요 환경 - 배치(batch) 처리로 이루어지는 경우가 많음 ### CDC(Change Data Capture) - **정의**: 변경된 데이터를 실시간으로 캡처하여 지속적으로 복제 - 방법: 변경 데이터 캡처 기술을 활용한 방법으로, 원본 데이터베이스에서 일어나는 변경(insert/update/delete)만 실시간 포착 -> 대상 데이터베이스에 적용 - 초기 마이그레이션 시 전체 데이터를 한 번 적재 -> 이후부터 발생하는 변경 사항만 지속적으로 동기화 함으로써 거의 실시간 데이터 복제를 구현 -> 마이그레이션 과정 동안에도 소스와 대상 데이터베이스가 최대한 일치하도록 유지 가능하여 무중단/최소중단 마이그레이션이 가능 - **장점**: 다운타임 최소화 또는 무중단 마이그레이션 가능 - **단점**: 초기 설정 복잡 - 적용 상황: 대용량 데이터 및 24×7 서비스 환경 ### 직접 쿼리 기반 이관 방식 - **정의**: SQL 쿼리를 사용해 데이터베이스 간 직접 데이터 이전 - **장점**: 중간 과정 없이 바로 데이터 이전 가능 - 예를 들어 애플리케이션 코드에서 두 DB를 연결해 INSERT ... SELECT 문을 실행하면, 중간 파일 없이도 한 데이터베이스에서 다른 데이터베이스로 데이터를 바로 복사 - 데이터베이스 링크를 활용하여 원본 DB의 테이블을 대상으로 직접 조회 및 적재하는 방식 - **단점**: 시스템 부하 발생 가능 - 적절한 트랜잭션 관리와 네트워크 대역폭 확보 등이 필요 - **적용 상황**: 소량 데이터 이관, 즉각적인 데이터 이전 필요 시 ## 데이터 마이그레이션 과정 1. **사전 준비 및 스키마 구성** - 원본과 동일한 스키마 구조를 생성하여 준비 2. **데이터 추출(백업)** - `mysqldump` 등 도구로 데이터 추출 3. **데이터 로드(적재)** - 덤프 파일을 새로운 DB에 로드 4. **데이터 검증** - 레코드 수 및 데이터 정합성 검증 5. **서비스 전환 및 모니터링** - 서비스 연결 전환 후 성능 및 데이터 모니터링 ## 5. MySQL 쿼리 예제 **테이블 생성** - 데이터베이스 마이그레이션을 수행할 때 활용할 수 있는 간단한 MySQL 쿼리 예시는 다음과 같습니다. (원본 데이터베이스를 old\\_database, 대상 데이터베이스를 new\\_database라고 가정)&#x20; - 테이블 생성 예: 새로운 DB에 원본 테이블과 동일한 구조의 테이블을 생성하는 SQL입니다. ```sql CREATE TABLE new_database.Employees LIKE old_database.Employees; ``` **데이터 복사** - 데이터 복사 예: 원본 DB에서 대상 DB로 데이터를 일괄 복사하는 SQL입니다. (Employees 테이블의 모든 컬럼 데이터를 한 번에 이전) ```sql INSERT INTO new_database.Employees SELECT * FROM old_database.Employees; ``` **데이터 검증** - 데이터 검증 예: 마이그레이션 전후 두 테이블의 레코드 수를 비교하여 데이터가 빠짐없이 복사되었는지 확인합니다. - 아래 쿼리의 결과가 일치하면 레코드 수가 동일하기 때문에 데이터가 모두 옮겨졌음을 러프하게 확인할 수 있습니다. ```sql SELECT COUNT(*) FROM old_database.Employees; SELECT COUNT(*) FROM new_database.Employees; ``` ## 6. 마이그레이션 사례 ### 레거시 시스템에서 신규 시스템으로 이관 - ETL 도구를 이용한 데이터 추출, 변환, 적재 - 주말 유지보수 시간을 활용하여 서비스 연결 전환 ### 온프레미스에서 클라우드로의 마이그레이션 - 전체 데이터 덤프 후 클라우드 DB 복원 - CDC 방식으로 실시간 데이터 동기화 - 무중단 서비스 전환을 실현 ## 참고 자료 - [AWS 데이터 마이그레이션](https://aws.amazon.com/ko/what-is/data-migration) - [IBM 데이터 마이그레이션](https://www.ibm.com/kr-ko/think/topics/data-migration) - [CDC는 무엇이고, 어떤 것을 할 수 있을까?](https://monday9pm.com/what-is-the-cdc-and-what-can-it-do-2cd4a002b061) ",
    "url": "/Database/db_migration.html",
    
    "relUrl": "/Database/db_migration.html"
  },"37": {
    "doc": "정규화",
    "title": "정규화",
    "content": "# 정규화 - 데이터 중복을 최소화하고 데이터 무결성을 유지하기 위한 데이터베이스 설계 기법 - 데이터를 구조적으로 체계화하여 이상 발생을 방지함 ### 필요성 - 데이터 중복 제거 - 데이터 무결성 유지 - 데이터베이스 저장 공간 최적화 - 삽입, 갱신, 삭제 이상 방지 --- ## 정규형(Normal Forms) ### 제1정규형(1NF: First Normal Form) - 하나의 칸에는 하나의 값만 - 모든 컬럼이 원자값(Atomic Value)을 가져야 함 #### **정규화 전** | 고객ID | 이름 | 전화번호 | --- | --- | --- | 1 | 홍길동 | 010-1234-5678, 02-9876-5432 | #### 1NF 변환 | 고객ID | 이름 | 전화번호 | --- | --- | --- | 1 | 홍길동 | 010-1234-5678 | 1 | 홍길동 | 02-9876-5432 | --- ### 제2정규형(2NF: Second Normal Form) - 중요한 정보는 자기 테이블에 - 1NF를 만족하면서, 부분 함수 종속 제거 #### 1NF | 주문ID | 고객ID | 고객이름 | 상품ID | 상품명 | --- | --- | --- | --- | --- | 101 | 1 | 홍길동 | A1 | 모니터 | 102 | 2 | 이순신 | B2 | 키보드 | #### 2NF (고객과 주문 테이블 분리) | 고객ID | 고객이름 | --- | --- | 1 | 홍길동 | 2 | 이순신 | 주문ID | 고객ID | 상품ID | --- | --- | --- | 101 | 1 | A1 | 102 | 2 | B2 | 상품ID | 상품명 | --- | --- | A1 | 모니터 | B2 | 키보드 | --- ### 제3정규형(3NF: Third Normal Form) - 중간 정보는 따로 정리 - 2NF를 만족하면서, 이행적 함수 종속 제거 #### 2NF (고객 주소 테이블 분리) | 주문ID | 고객ID | 고객주소 | --- | --- | --- | 101 | 1 | 서울시 강남구 | 102 | 2 | 부산시 해운대구 | #### 3NF | 고객ID | 고객주소 | --- | --- | 1 | 서울시 강남구 | 2 | 부산시 해운대구 | 주문ID | 고객ID | --- | --- | 101 | 1 | 102 | 2 | --- ### BCNF(Boyce-Codd Normal Form) - 3NF를 만족하면서 모든 결정자가 후보 키 #### **3NF** | 교수ID | 강의실 | 과목 | --- | --- | --- | P1 | R101 | 수학 | P1 | R102 | 물리 | P2 | R201 | 화학 | 관계 1. `교수ID → 과목` 관계 2. `강의실 → 교수ID` 특정 강의실에서 특정 교수만 강의한다는 제약이 있다고 할 때, **강의실**은 기본 키가 아님에도 **결정자 역할**을 한다. #### 왜 분리해야 할까? - 강의실이 결정자 역할을 하지만 **후보 키가 아님** - BCNF **규칙에 위반됨** #### BCNF 강의 배정 테이블 | 교수ID | 과목 | --- | --- | P1 | 수학 | P1 | 물리 | P2 | 화학 | 강의실 배정 테이블 | 강의실 | 교수ID | --- | --- | R101 | P1 | R102 | P1 | R201 | P2 | `강의실 → 교수ID` 종속성 제거 **모든 결정자가 후보 키**. --- ### 제4정규형(4NF: Fourth Normal Form) - BCNF를 만족하면서 **다중 값 종속 제거** 다중 값 종속 - 한 개의 키 속성이 두 개 이상의 독립적인 속성과 다대다 관계를 가질 때 발생 - 한 테이블에서 한 속성이 특정되었을 때, 다른 속성이 독립적으로 여러 값을 가질 수 있는 경우 문제가 됨 #### BCNF + 다중 값 종속 | 학생ID | 수강 과목 | 동아리 | --- | --- | --- | S1 | 수학 | 축구 | S1 | 수학 | 야구 | S1 | 영어 | 축구 | S1 | 영어 | 야구 | 관계 1. `학생ID → 수강 과목` (한 학생이 여러 과목을 수강 가능) 관계 2. `학생ID → 동아리` 관계도 있음 (한 학생이 여러 동아리 가입 가능) 수강 과목과 동아리는 서로 관계x. 만약 학생이 동아리를 변경하면 수강 과목까지 함께 수정해야 함 #### 4NF 학생-수강 과목 테이블 | 학생ID | 수강 과목 | --- | --- | S1 | 수학 | S1 | 영어 | 학생-동아리 테이블 | 학생ID | 동아리 | --- | --- | S1 | 축구 | S1 | 야구 | `학생ID → 수강 과목` / `학생ID → 동아리`가 **독립적으로 관리** --- ### 제5정규형(5NF: Fifth Normal Form) - 다대다 관계가 여러 개 얽힌 경우 - 조인으로 인한 불필요한 중복 제거 - 조인을 줄이고 불필요한 분해를 방지해서 최적의 테이블 구조를 찾기 #### 조인 종속 - 하나의 릴레이션을 여러개의 릴레이션으로 분해하였다가, 다시 조인했을 때 데이터 손실이 없는 것 - 조인 종속성이 만족되면, 데이터를 분해한 후 다시 조인해도 원래 데이터를 복원할 수 있음 #### 5NF가 필요한 이유 4NF까지 진행하면 **모든 다중 값 종속이 제거**되어 중복이 최소화되지만 테이블이 과하게 분해되면서, 조인 시 불필요한 중복이 발생할 수 있음 #### 강의 배정 시스템 (4NF + 조인 중복 발생) | 학생ID | 과목ID | 교수ID | --- | --- | --- | S1 | C1 | P1 | S1 | C1 | P2 | S1 | C2 | P1 | S2 | C1 | P1 | S2 | C2 | P2 | - 학생(S) → 과목(C), - 학생(S) → 교수(P), - 과목(C) → 교수(P) #### 테이블 분리 1. **학생 - 과목** | 학생ID | 과목ID |---|---| S1 | C1 | S1 | C2 | S2 | C1 | S2 | C2 | 2. **과목 - 교수** | 과목ID | 교수ID |---|---| C1 | P1 | C1 | P2 | C2 | P1 | C2 | P2 | 3. **학생 - 교수** | 학생ID | 교수ID |---|---| S1 | P1 | S1 | P2 | S2 | P1 | S2 | P2 | - **S1이 C1을 P1에게 듣는 것인지 P2에게 듣는 것인지 알 수 없음** - 학생이 어떤 교수에게 어떤 과목을 듣는지 정보가 유실 결과적으로, 원래 테이블 구조에서 조인으로 인한 중복 문제를 해결하는 5NF로 데이터 분해가 필요 | 학생ID | 과목ID | 교수ID | --- | --- | --- | S1 | C1 | P1 | S1 | C1 | P2 | S1 | C2 | P1 | S2 | C1 | P1 | S2 | C2 | P2 | https://superohinsung.tistory.com/111 https://velog.io/@wg_cat/%EC%A0%9C-15%EC%A0%95%EA%B7%9C%ED%99%94-%EA%B8%B0%EB%B2%95 https://velog.io/@wisdom-one/%EC%A0%95%EA%B7%9C%ED%99%94Normalization https://www.geeksforgeeks.org/difference-between-4nf-and-5nf/ ",
    "url": "/Database/db_normal_forms.html",
    
    "relUrl": "/Database/db_normal_forms.html"
  },"38": {
    "doc": "파티셔닝 (Partitioning)",
    "title": "파티셔닝 (Partitioning)",
    "content": "# 파티셔닝 (Partitioning) - 단일 데이터베이스 내에서 데이터를 테이블로 분할하는 행위 혹은 방법. - 같은 데이터베이스 내에서 데이터가 관리된다. - 분할된 데이터는 하나의 서버에 저장된다. ## 수평 파티셔닝 ![](/Database/img/db_partitioning_sharding_horizontal.png) - 테이블의 행(row)을 기준으로 데이터를 나누어, 여러 테이블로 분산한다. - 주로 데이터베이스의 용량이 커지면서 성능 저하가 예상될때, 이를 막기 위해 사용됩니다. ## 수직 파티셔닝 ![](/Database/img/db_partitioning_sharding_vertical.png) - 테이블의 열을 기준으로 데이터를 나누어, 여러 테이블로 분산한다. - 자주 사용하는 열과 그렇지 않은 열을 나누어 저장할수 있기에, 쿼리 성능을 향상시킬 수 있다. - 민감한 정보에 제한을 걸어서 접근을 방지할 수 있다. # 샤딩 (Sharding) - 동일한 스키마를 가지고 있는 데이터를 여러 데이터베이스(및 서버) 에 분산한다. - 데이터와 트래픽이 많이 쌓이고 몰리는, 규모가 큰 애플리케이션에서 사용. ## 수평 파티셔닝과 샤딩 - 데이터를 행으로 나눈다는 점에서 **수평 파티셔닝**의 일종으로 볼 수 있다. - 수평 파티셔닝과 샤딩은 모두 단순히 행을 기준으로 나누는 것 뿐아니라, 다양한 기준으로 데이터를 나눌 수 있다. - 특정 키를 해싱한 결과에 따라 - 범위에 따라 (e.g. 사용자 ID 1 ~ 999 까지) - 데이터 값이 특정 목록에 포함된 유무에 따라 (e.g. 한국1, 한국2, 미국 1, 미국2) - 하나의 서버에서 관리하는 수평 파티셔닝과 달리, **여러 서버로 분산된 환경에서 관리하는 점에서 주요한 차이점**을 가진다. # 비교 | **특징** | **파티셔닝(Partitioning)** | **샤딩(Sharding)** | -------------------- | ----------------------------------------- | ----------------------------------- | **데이터 저장 위치** | 단일 서버 내에서 논리적으로 분리된 파티션 | 여러 서버에 물리적으로 분산된 샤드 | **확장성** | 주로 단일 서버 내 성능 최적화 | 물리적 확장을 통해 시스템 부하 분산 | **관리 복잡도** | 비교적 간단 | 높은 관리 및 라우팅 복잡도 | **사용 목적** | 데이터 접근성과 성능 최적화 | 대규모 트래픽 처리와 확장성 개선 | # 출처 - http://theeye.pe.kr/archives/1917 - https://aiday.tistory.com/123 - https://www.digitalocean.com/community/tutorials/understanding-database-sharding - https://data-mozart.com/partitioning-why-you-need-to-consider-it/ ",
    "url": "/Database/db_partitioning_sharding.html",
    
    "relUrl": "/Database/db_partitioning_sharding.html"
  },"39": {
    "doc": "Query Optimization(Slow Query Tuning)",
    "title": "Query Optimization(Slow Query Tuning)",
    "content": "# Query Optimization(Slow Query Tuning) 데이터베이스의 성능을 높이기 위해 SQL 쿼리를 분석하고 최적화하는 과정 ## **슬로우 쿼리 원인** 1. **인덱스 미사용 또는 잘못된 인덱스** - 적절한 인덱스가 없거나 과도한 인덱스를 사용하면 쿼리 성능이 저하 2. **불필요한 풀 테이블 스캔** - 적은 양의 데이터를 사용할 경우, 풀 테이블 스캔을 할 경우 성능 저하 3. **잘못된 조인 (JOIN) 순서 및 방식** - 조인의 순서나 방식에 따라 성능 차이가 큼 4. **과한 서브쿼리 사용** - 서브쿼리는 JOIN, EXISTS, IN으로 변경하는 것이 더 효율적일 수 있음 5. **트랜잭션 및 락 대기** - 긴 트랜잭션이 다른 쿼리들의 대기 상태를 유발할 수 있으므로 트랜잭션을 최소화하고 적절한 커밋 시점을 설정해야 함 ## 옵티마이저 힌트 옵티마이저 힌트는 **DBMS가 실행 계획을 최적화할 때 개발자가 특정 방식으로 실행하도록 유도하는 방법** DBMS는 보통 **통계 정보(Statistics)** 를 기반으로 자동으로 최적의 실행 계획을 선택하지만, - **잘못된 통계 정보** - **특정 실행 계획을 강제하고 싶을 때** 이런 경우에는 옵티마이저 힌트를 사용해서 직접 실행 계획을 컨트롤할 수 있다. ### 대표적인 힌트 종류 (DBMS마다 다름) | **힌트 종류** | **설명** | **사용 예시** | --- | --- | --- | **조인 방식 강제** | 특정 조인 방식을 강제함 | `/*+ USE_NL(A B) */` | **조인 순서 강제** | 테이블의 조인 순서를 지정함 | `/*+ LEADING(A B C) */` | **인덱스 사용 강제** | 특정 인덱스를 사용하도록 강제 | `/*+ INDEX(table index_name) */` | **인덱스 사용 방지** | 특정 인덱스를 사용하지 않도록 강제 | `/*+ NO_INDEX(table index_name) */` | **병렬 처리 적용** | SQL 실행을 병렬로 수행 | `/*+ PARALLEL(table 4) */` | **FULL 스캔 강제** | 테이블 풀 스캔을 강제 | `/*+ FULL(table) */` | **INDEX 스캔 강제** | 특정 인덱스를 통한 검색 강제 | `/*+ INDEX(table index_name) */` | **SORT MERGE 조인 강제** | Sort Merge Join 사용 | `/*+ USE_MERGE(A B) */` | **CARDINALITY 설정** | 특정 테이블의 예상 행 수를 지정 | `/*+ CARDINALITY(table 1000) */` | **FIRST_ROWS / ALL_ROWS** | 응답 속도 또는 전체 처리 속도 최적화 | `/*+ FIRST_ROWS(10) */` | ```sql /*+ USE_NL(A B) */ -- A, B 테이블을 Nested Loop Join 사용 /*+ USE_HASH(A B) */ -- A, B 테이블을 Hash Join 사용, B가 해시 테이블로 올라감 -- NL 조인 강제 SELECT /*+ USE_NL(usr ord) */ usr.이름, ord.상품이름, ord.주문일자 FROM T_USER usr JOIN T_ORDER ord ON usr.user_id = ord.user_id -- 해시 조인 강제 SELECT /*+ USE_HASH(usr ord) */ usr.이름, ord.상품이름, ord.주문일자 FROM T_USER usr JOIN T_ORDER ord ON usr.user_id = ord.user_id /*+ LEADING(A B C) */ -- A → B → C 순서대로 조인 강제 -- ord 테이블을 먼저 읽도록 강제 SELECT /*+ LEADING(ord usr) */ usr.이름, ord.상품이름, ord.주문일자 FROM T_USER usr JOIN T_ORDER ord ON usr.user_id = ord.user_id /*+ INDEX(table index_name) */ -- 테이블의 index_name 사용 /*+ NO_INDEX(table index_name) */ -- 테이블의 index_name 사용x -- 해시 조인, idx_user_id 인덱스 사용 SELECT /*+ USE_HASH(usr ord) INDEX(usr idx_user_id) */ usr.이름, ord.상품이름, ord.주문일자 FROM T_USER usr JOIN T_ORDER ord ON usr.user_id = ord.user_id /*+ PARALLEL(table 4) */ -- 테이블을 4개의 프로세스가 병렬로 처리하도록 강제 SELECT /*+ PARALLEL(T_ORDER 4) */ user_id, 상품이름, 주문일자 FROM T_ORDER; -- T_USER와 T_ORDER 테이블을 각각 4개의 프로세스로 병렬 처리 SELECT /*+ PARALLEL(T_ORDER 4) PARALLEL(T_USER 4) */ usr.이름, ord.상품이름, ord.주문일자 FROM T_USER usr JOIN T_ORDER ord ON usr.user_id = ord.user_id ``` ### 주의점 1. 힌트는 DBMS에 따라 다르다. 2. 힌트를 무조건 쓰면 안된다. - 옵티마이저가 최적 실행 계획을 찾는 경우가 많음 - 장기적으로 유지보수가 어려워질 수 있음 # **쿼리 최적화** ![](/Database/img/db_query_optimization_1.png) ## **1. 실행 계획(EXPLAIN, EXECUTION PLAN) 확인** **실행 계획을 분석하여 쿼리 성능을 점검**할 수 있다. - **MySQL:** `EXPLAIN SELECT ...` - **Oracle/Tibero:** `EXPLAIN PLAN FOR SELECT ...` - **PostgreSQL:** `EXPLAIN ANALYZE SELECT ...` ```sql EXPLAIN PLAN FOR SELECT /*+ full(user_id)*/ * FROM T_USER WHERE user_id= 'USER000502' SELECT SQL_ID , OPERATION , OBJECT_NAME , SEARCH_COLUMNS , COST FROM PLAN_TABLE WHERE SQL_ID IN ( '51s88agb5q2fw', '5xfxqjnpxhuvw' ) ``` ![](/Database/img/db_query_optimization_2.png) ## **2. 인덱스 최적화** ✅ - WHERE, JOIN, ORDER BY, GROUP BY에서 인덱스를 제대로 활용하고 있는가? - 불필요한 인덱스가 오히려 성능 저하를 유발하지 않는가? - 인덱스가 많은 경우 유지 관리 비용을 고려했는가? - 예상치 못한 TABLE FULL SCAN이 발생하지 않는가? - 적절한 인덱스 사용으로 풀스캔을 줄였는가? ### **인덱스 최적화 목표** - 스캔 과정에서 발생하는 비효율 줄이기 - 테이블 액세스 회수 줄이기 ```sql SELECT * FROM T_USER WHERE user_id= 'USER000502' // 조건에 해당하는 데이터가 한 건이므로 인덱스를 사용하는 방식이 좋다. SELECT * FROM T_USER WHERE 유저구분코드 = 'a001' // 유저구분코드가 'a001'인 고객 데이터가 100만 건일 때, 풀 스캔 방식이 효과적이다. ``` 인덱스는 큰 테이블에서 소량 데이터를 검색할 때 사용한다. (목차) ![](/Database/img/db_query_optimization_3.png) index range scan 을 할 때는 데이터가 정렬되어 있어야 하고 스캔 시작점과 종료점(인덱스 블록에서 스캔하는 양)이 중요 ✅ **적절한 인덱스 추가** ```sql CREATE INDEX idx_user_name ON T_USER(name); ``` - 자주 조회되는 컬럼이나 **조인 조건에 사용되는 컬럼**에 인덱스를 추가 ✅ **복합 인덱스** ```sql CREATE INDEX idx_orders_user_date ON T_ORDER(user_id, order_date); ``` - WHERE 절에 다중 컬럼을 사용할 경우 사용 - 인덱스 순서도 중요 - `WHERE user_id = 1 AND order_date = '2024-03-01'` - 인덱스 사용 가능 - user_id로 스캔 범위를 좁힐 수 있음 - `WHERE order_date = '2024-03-01'` - 모든 데이터를 조회해야 할 수 있음 ## **3. JOIN 최적화** ✅ - INNER JOIN이 OUTER JOIN보다 적절한가? - 조인 순서를 변경하면 성능이 향상되는가? - 조인 대상 테이블에 적절한 인덱스가 설정되어 있는가? ### **NL(Nested Loops) 조인** - 인덱스를 이용한 조인 - 작은 테이블을 먼저 읽고, 그 값으로 큰 테이블을 조회 - 인덱스가 잘 활용되지 않으면 성능이 저하될 수 있음 ```sql SELECT a.이름, b.상품이름, b.주문일자 FROM T_USER a, T_ORDER b WHERE a.user_id = b.user_id AND a.가입일자 = '20250101' ``` ### **NL 조인 동작 방식** 1. T_USER 테이블에서 데이터를 가져옴 - `가입일자 = '20250101'` 조건을 만족하는 유저 조회 2. 각 유저의 `user_id`로 T_ORDER 테이블을 검색 - T_USER 에서 가져온 `user_id`를 이용해 `T_ORDER` 테이블에서 해당 유저의 주문 데이터를 조회 3. 반복 - 위 과정을 모든 유저에 대해 반복 수행 ![](/Database/img/db_query_optimization_4.png) ### **실행 계획** | 단계 | 연산(Operation) | 테이블 | 액세스 방식(Access Method) | --- | --- | --- | --- | 1 | TABLE ACCESS BY INDEX ROWID | T_USER | `가입일자` 필터링 (INDEX 사용) | 2 | INDEX RANGE SCAN | idx_user_join_date | `가입일자` 인덱스 탐색 | 3 | NESTED LOOPS | | 4 | TABLE ACCESS BY INDEX ROWID | T_ORDER | `user_id` 인덱스를 통한 검색 | 5 | INDEX UNIQUE SCAN | idx_order_user_id | `user_id` 인덱스를 사용한 검색 | - T_USER에서 먼저 가입일자 조건을 필터링 (`INDEX RANGE SCAN`) - 그 결과를 기반으로 T_ORDER를 NESTED LOOPS 방식으로 반복 조회 ✅ **조인 조건에 인덱스 추가** ```sql CREATE INDEX idx_order_user_id ON T_ORDER(user_id); ``` - `T_ORDER.user_id`에 인덱스를 추가하면 `INDEX UNIQUE SCAN`이 발생하며 빠르게 조인 가능 ✅ **드라이빙 테이블 크기 줄이기** ```sql CREATE INDEX idx_user_join_date ON T_USER(가입일자); ``` - 필터링 조건이 먼저 최적화되어야 `T_USER`의 크기가 줄어들어 NL 조인의 반복 횟수가 감소함 ## **Hash Join** 두 개의 테이블 중 **작은 테이블을 메모리에 해시 테이블로 저장**한 후, 큰 테이블을 스캔하면서 해시 테이블과 조인하는 방식 1. NL 조인이 비효율적일 때 (인덱스를 활용하지 못할 때) - NL 조인은 데이터가 적을 때는 효율적이지만, **대량 데이터 조인 시 비효율적**일 수 있음 2. 드라이빙 테이블이 작을 때 ### **Hash Join동작 방식** 1. **Build** - 작은 테이블을 메모리에 올려 **해시 테이블을 생성** - 조인 키를 기준으로 해시 값을 계산하여 **버킷**에 저장. 2. **Probe** - 큰 테이블을 읽으면서 해시 테이블을 참조하여 매칭되는 행을 탐색 ```sql SELECT /*+ USE_HASH(b) */ a.이름, b.상품이름, b.주문일자 FROM T_USER a, T_ORDER b WHERE a.user_id = b.user_id AND a.가입일자 = '20250101'; ``` 1. **`T_USER`(작은 테이블)에서 `가입일자 = '20250101'` 필터링** ```sql SELECT user_id, 이름 FROM T_USER WHERE 가입일자 = '20250101'; ``` - 이 결과를 해시 테이블로 메모리에 저장 2. **`T_ORDER`(큰 테이블)를 스캔하며 `user_id`를 해시 테이블과 비교** ```sql SELECT 상품이름, 주문일자 FROM T_ORDER WHERE user_id IN (해시 테이블); ``` - `T_ORDER.user_id`를 해시 테이블에서 찾으며 빠르게 조인 ✅ **드라이빙 테이블(작은 테이블) 크기를 줄이기** ```sql SELECT /*+ USE_HASH(b) */ a.이름, b.상품이름, b.주문일자 FROM (SELECT user_id, 이름 FROM T_USER WHERE 가입일자 = '20250101') a JOIN T_ORDER b ON a.user_id = b.user_id; ``` - `T_USER`에서 미리 필터링하여 **해시 테이블 크기를 줄임** → 더 빠른 해시 매칭 가능. ✅ **해시 테이블이 너무 클 경우, Hash Partitioning 사용** ```sql ALTER TABLE T_ORDER PARTITION BY HASH (user_id); ``` - 해시 파티셔닝을 통해 데이터 분산 → 메모리 사용 최적화. ## Join Q&A ### 1. NoSQL에서는 쿼리 최적화가 있는지? ✅ NoSQL에서도 쿼리 최적화는 필요 NoSQL은 스키마가 유연하고 조인이 적다는 특성이 있지만, 데이터가 많아지면 느려지는 쿼리를 최적화해야 하는 건 같다. - RDBMS → 실행 계획 & 인덱스 튜닝을 통해 최적화 - NoSQL → 적절한 데이터 모델링 + 인덱싱 + 샤딩(Sharding) + 캐싱 ### 2. NL 조인, Hash Join도 inner join 같은 건가? ✅ NL 조인, Hash Join 은 join의 실행방식 중 하나 NL 조인과 해시 조인은 조인의 실행 방식이 다른 알고리즘으로 같은 조인을 수행하지만, 데이터를 매칭하는 방식이 다른 것 ### 3. 만약 큰 테이블과 작은 테이블이 같은 경우는 어떤 조인을 사용하는게 좋을지? ✅ 상황(인덱스, 메모리..) 에 따라 다름 **NL 조인 vs 해시 조인** | 기준 | NL 조인 | 해시 조인 | --- | --- | --- | **인덱스** | 인덱스가 있을 때 유리 (빠름) | 인덱스 없어도 빠름 | **데이터 양** | 작은 테이블 + 큰 테이블 | 두 테이블 크기가 비슷할 때 | **조인 방식** | 한쪽 테이블을 읽으며 다른 테이블 검색 (반복문) | 한쪽을 해시 테이블로 변환 후 조인 | **메모리 사용** | 적음 (인덱스 기반) | 많음 (해시 테이블 생성) | **성능** | 인덱스 최적화 시 매우 빠름 | 대량 데이터에서 빠름 | 인덱스가 있고 최적화 되어 있다 → NL 인덱스가 없다 → 해시 조인 메모리가 충분하다 → 해시 조인 결국 실행 환경에 따라 다르기 때문에 EXPLAIN PLAN을 확인해서 실제 DB에서 어떤 방식이 최적화되는지 봐야 함. ## **4. 서브쿼리 최적화** ✅ - 서브쿼리를 JOIN 또는 EXISTS로 변경하면 성능이 향상되는가? - IN 대신 EXISTS를 사용하면 더 효율적인가? ### 서브쿼리 문제점 | 문제점 | 예시 | --- | --- | --- | **반복 실행** | **상관 서브쿼리**는 메인 쿼리의 각 행마다 서브쿼리를 반복 실행함 | `WHERE EXISTS (SELECT ... WHERE o.user_id = u.user_id)` | **옵티마이저가 최적화하기 어려움** | 옵티마이저는 블록 단위로 계획을 세우는데, **서브쿼리 내부는 다른 블록**이라 예측 어려움 | 옵티마이저가 조인 방식 선택 실패 가능 | **인덱스 활용이 어려움** | 복잡하거나 상관된 서브쿼리는 **풀스캔 유도** 가능성 높음 | `IN (SELECT ...)` 구조에서 옵티마이저가 인덱스를 포기할 수 있음 | 💡 서브쿼리는 \"옵티마이저가 잘 예측하지 못하는\" 특성이 있어 주의가 필요 ### 옵티마이저는 쿼리 블록 단위로 최적화를 수행한다. - 쿼리 블록 단위로 최적화됨 → `EXISTS`, `IN`, `JOIN`은 다른 블록처럼 처리됨 - 서브쿼리의 실행 시점은 메인 쿼리 이후인 경우가 많음 - 특히 상관 서브쿼리는 메인 쿼리 한 줄당 서브쿼리 한 번 실행되므로 매우 비효율적 ```sql SELECT 이름 FROM T_USER u WHERE 가입일자 = '20250101' AND EXISTS ( SELECT 1 FROM T_ORDER o WHERE o.user_id = u.user_id AND o.상품이름 = '라면' ); SELECT 이름 FROM T_USER u WHERE 가입일자 = '20250101' SELECT 1 FROM T_ORDER WHERE user_id = :user_id -- 블록 1의 user_id 값을 하나씩 바인딩 받아 실행 AND 상품이름 = '라면' ``` ### 예시 ### 서브쿼리 (느릴 수 있음) ```sql SELECT 이름 FROM T_USER WHERE user_id IN ( SELECT user_id FROM T_ORDER WHERE 상품이름 = '라면' ) ``` - `T_ORDER` 먼저 수행 - `T_USER`를 조건 비교로 필터링 - 옵티마이저가 **인덱스 사용 안 할 수 있음** - **대용량 비추**, 소규모라면 괜찮음 ### JOIN (일반적으로 더 효율적) ```sql SELECT DISTINCT u.이름 FROM T_USER u JOIN T_ORDER o ON u.user_id = o.user_id WHERE o.상품이름 = '라면' ``` - 옵티마이저가 **해시 조인 / NL 조인 / 병렬 처리 등 다양한 선택 가능** - 인덱스 사용 가능 - **전체적으로 가장 안정적이고 빠름** ### EXISTS (조건만 확인) ```sql SELECT 이름 FROM T_USER u WHERE EXISTS ( SELECT 1 FROM T_ORDER o WHERE o.user_id = u.user_id AND o.상품이름 = '라면' ); ``` - `T_USER` 한 건씩 조회하며 `T_ORDER`에 조건 만족하는 것 있으면 탈출 - 조건이 **존재 여부**일 때 매우 효율적 - **중복 제거 불필요**, 빠른 탈출 덕분에 쿼리 시간 단축 가능 ### 비교 | JOIN | EXISTS | IN | --- | --- | --- | --- | 가장 효율적인 기본 방식 | ✅ | ✅ (존재 확인) | ❌ (옵티마이저 예측 어려움) | 대용량 적합 | ✅ | 주의 필요 | ❌ | 인덱스 활용 | 최적화됨 | 가능 | 어려움 | 실행계획 최적화 | 유리 | 비교적 유리 | 불리 | 추천 상황 | **실제 데이터를 함께 보여줄 때** | 조건 충족하는 데이터가 **존재하는지만 확인**할 때 | 서브쿼리 결과가 **작고 고정된 범위**일 때 | **서브쿼리** → 간단한 조건이나 상관관계 없는 서브쿼리 일 때 추천 ## 트랜잭션 및 락 대기 ✅ - 트랜잭션 유지 시간을 최소화하여 락 대기를 줄였는가? - 적절한 커밋 타이밍을 설정하여 롤백 부담을 줄였는가? | 트랜잭션 | 하나의 논리적 작업 단위 (`BEGIN ~ COMMIT/ROLLBACK`) | DB에 변경이 필요한 최소 범위로 한정 | --- | --- | --- | 락(Lock) | 데이터 무결성을 위한 배타 제어 수단 | 행 단위 락(Row-level Lock)을 유도하도록 SQL 설계 | 락 대기(Lock Wait) | 선행 트랜잭션이 락을 해제하지 않아서 후속 쿼리가 멈추는 현상 | 락이 오래 지속되면 블로킹 발생 | 블로킹 | 특정 트랜잭션이 다른 트랜잭션의 실행을 막는 상태 | 보통 `COMMIT` 또는 `ROLLBACK`으로 해제됨 | 교착 상태(Deadlock) | 두 트랜잭션이 서로의 락을 기다리며 영원히 대기 | DBMS가 한 트랜잭션을 강제 종료시켜 회피함 | ### 왜 트랜잭션이 길면 위험할까? ```sql -- 사용자 A BEGIN; UPDATE T_ORDER SET 상태 = '배송중' WHERE 주문번호 = 12345; -- commit; (여기서 커밋 안 함) -- 사용자 B (다른 세션) UPDATE T_ORDER SET 상태 = '완료' WHERE 주문번호 = 12345; -- B는 A가 커밋하기 전까지 '락 상태' ``` - 락이 오래 유지되면 다른 사용자도 모두 기다림 - 트랜잭션 안에서 많은 작업을 하면, **롤백 시 복구 비용**도 커짐 - 트랜잭션이 복잡해질수록 교착 상태 발생 확률도 높아짐 ### 비관적 락 vs 낙관적 락 | 비관적 락 | 낙관적 락 | --- | --- | --- | 개념 | 미리 락을 걸어 충돌을 방지 | 충돌이 날 경우 롤백 | 방법 | `SELECT ... FOR UPDATE` | `version`, `updated_at` 등 비교 | 장점 | 충돌 확실히 방지 | 락을 걸지 않아 성능 우수 | 단점 | 락 유지 시간 증가 → 성능 저하 | 충돌 시 재시도 필요 | 추천 상황 | 동시 수정 가능성 높을 때 | 대부분 읽기 전용, 충돌 드물 때 | ### 정리 | 트랜잭션 최소화 | 트랜잭션 범위를 최대한 좁힘 | --- | --- | 빠른 커밋 | 처리 로직 후 즉시 커밋 | SELECT는 트랜잭션 고려 | 가능하다면 조회 쿼리는 락을 걸지 않음 | 비관적 락 | `SELECT ... FOR UPDATE` → 락 걸린 상태로 트랜잭션 보장 (동시 수정 우려가 클 때) | 낙관적 락| 버전/타임스탬프로 변경 감지 → 충돌 시 롤백 유도 (충돌이 드물 때) | 파티셔닝 고려 | 핫스팟 테이블은 파티션 설계 | 인덱스 설계 | 불필요한 테이블 락 유발 방지 | 타임아웃 설정 | 일정 시간이 지났는데도 작업이 완료되지 않으면 강제로 중단 | --- [친절한SQL튜닝](https://www.yes24.com/product/search?query=%25EC%25B9%259C%25EC%25A0%2588%25ED%2595%259CSQL%25ED%258A%259C%25EB%258B%259D) https://escapefromcoding.tistory.com/777 [https://bommbom.tistory.com/entry/ROWID와-클리스터링-팩터CF의-관계는](https://bommbom.tistory.com/entry/ROWID%EC%99%80-%ED%81%B4%EB%A6%AC%EC%8A%A4%ED%84%B0%EB%A7%81-%ED%8C%A9%ED%84%B0CF%EC%9D%98-%EA%B4%80%EA%B3%84%EB%8A%94) [https://velog.io/@yooha9621/SQLP4장-인덱스와-조인-3.-조인-기본원리](https://velog.io/@yooha9621/SQLP4%EC%9E%A5-%EC%9D%B8%EB%8D%B1%EC%8A%A4%EC%99%80-%EC%A1%B0%EC%9D%B8-3.-%EC%A1%B0%EC%9D%B8-%EA%B8%B0%EB%B3%B8%EC%9B%90%EB%A6%AC) https://sabarada.tistory.com/175 ",
    "url": "/Database/db_query_optimization.html",
    
    "relUrl": "/Database/db_query_optimization.html"
  },"40": {
    "doc": "트랜잭션(Transaction)",
    "title": "트랜잭션(Transaction)",
    "content": "# 트랜잭션(Transaction) ## 트랜잭션(Transaction) 정의 --- 트랜잭션은 **하나 이상의 데이터 교환 또는 변경 작업을 하나의 단위로 묶어 안전하게 처리하는 것을 의미**합니다. 하나의 트랜잭션은 최종적으로 커밋(Commit) 또는 롤백(Rollback) 중 하나로 종료됩니다. ![Image](https://github.com/user-attachments/assets/20098f79-d0df-4e44-804a-55e5019319d6) - **커밋(Commit):** 모든 작업이 정상적으로 완료되어 데이터베이스에 변경사항이 영구적으로 반영됩니다. - **롤백(Rollback):** 작업 중 오류가 발생하면, 트랜잭션 시작 이전의 상태로 모든 변경 사항이 되돌려집니다. 여러 데이터에 대한 변경 작업이 모두 성공적으로 완료되어야 데이터베이스에 변경사항이 영구적으로 반영되고, 만약 작업 중 하나라도 실패하면 전체 작업이 이전 상태로 되돌아갑니다. ## 트랜잭션 ACID 속성 --- ACID는 트랜잭션은 정의하는 4가지 속성을 가리키는 약어입니다. - 원자성(Atomicity) - 모든 트랜잭션은 데이터 베이스에 모두 반영되거나 아니면 전혀 반영되지 않아야 합니다. - 트랜잭션 내의 모든 명령은 반드시 완벽하게 수행되어야하며, 하나라도 오류가 발생하면 트랜잭션내의 모든 작업 전부가 취소되어야합니다. - 일관성(Consistency) - 트랜잭션이 실행을 성공적으로 Commit을 완료하면 언제나 일관성 있는 데이터베이스 상태로 보존되어야 합니다. - 시스템이 가진 불변 속성은 트랜잭션 수행 전과 수행 후에 동일해야 합니다. - 예를 들어, 미리 정의된 무결성 제약조건은 트랜잭션과 관계없이 유지되어야 합니다. - 격리성(Isolation) - 두 개 이상의 트랜잭션이 병행적으로 실행되는 경우, 어느 한 트랜잭션이 다른 트랜잭션의 연산에 끼어들 수 없습니다. - 수행 중인 트랜잭션은 완전히 완료될 때까지, 다른 트랜잭션에서 그 수행 결과를 참조할 수 없습니다. - 이를 위해 행 단위 락, 페이지 또는 테이블 단위 락을 사용합니다. - 영속성(Durablility) - 성공적으로 완료된 트랜잭션 결과는 시스템이 고장나더라도 영구적으로 반영되어야합니다. - 시스템의 메모리뿐만 아니라 디스크나 SSD와 같은 비휘발성 저장 장치에 기록되어, 데이터베이스가 고장나더라도 복구할 수 있도록 보장합니다. ## 트랜잭션 동작 원리 --- > 정확히는, Manual Commit에서의 트랜잭션 동작 원리입니다. > ![Image](https://github.com/user-attachments/assets/8001e136-e196-4b43-a05e-d92e8ae5b746) - **커넥션 수립 및 세션 할당** - 사용자는 WAS 또는 DB 접근툴 등의 클라이언트를 통해 데이터베이스 서버에 연결 요청을 보냅니다. - 클라이언트는 데이터베이스 서버에 연결 요청을 보내고, 서버는 해당 요청에 대해 커넥션(Connection)을 맺어줍니다. - 데이터베이스 서버는 각 커넥션마다 내부적으로 세션을 할당하며, 이미 생성된 세션이 있다면 재활용하여 클라이언트의 요청을 처리합니다. - **트랜잭션 시작** - 세션 내에서 트랜잭션이 시작됩니다. - 일반적으로 `BEGIN` 또는 `START TRANSACTION` 명령을 통해 트랜잭션 경계가 설정됩니다. - 이후 실행되는 모든 SQL 명령은 이 트랜잭션의 일부로 처리됩니다. - **SQL 명령 실행** - 트랜잭션 내에서 여러 데이터 변경 작업(INSERT, UPDATE, DELETE 등) 또는 조회 작업(SELECT)이 순차적으로 실행됩니다. - 트랜잭션 내에서 이루어지는 데이터 변경 작업은 해당 세션 내에서만 임시적으로 저장되며, 트랜잭션이 커밋되기 전까지 다른 세션에서는 볼 수 없습니다. - **트랜잭션 종료: 커밋 또는 롤백** - 모든 SQL 작업이 정상적으로 완료되면, `COMMIT` 명령을 실행하여 변경사항을 영구적으로 데이터베이스에 반영합니다. - 만약 하나라도 오류가 발생하면, `ROLLBACK` 명령을 실행하여 트랜잭션 시작 전의 상태로 모든 변경사항을 취소합니다. - **세션 종료 및 커넥션 재활용** - 트랜잭션이 종료되면 해당 세션은 결과를 반영한 상태로 유지되거나, 커넥션 풀에 반환되어 재활용됩니다. - 이후 동일한 커넥션을 통해 새로운 트랜잭션을 시작할 수 있습니다. ## 추가설명 : Auto Commit vs Manual Commit --- - **Auto Commit** - 일반적으로 데이터베이스의 기본 설정입니다. - 단일 SQL 명령어마다 자동으로 트랜잭션이 생성되어 바로 커밋됩니다. - 간단한 작업에는 편리하지만, 여러 관련 작업을 하나의 단위로 묶어 처리하기에는 부적합합니다. - **Manual Commit** - 개발자가 트랜잭션의 시작과 종료를 명시적으로 관리하여 여러 SQL 명령어를 하나의 트랜잭션으로 처리할 수 있습니다. - 복잡한 비즈니스 로직이나 원자성이 중요한 경우에 사용됩니다. - 많은 애플리케이션 프레임워크에서는 트랜잭션의 원자성을 보장하기 위해 Auto Commit을 비활성화하고 Manual Commit 방식으로 트랜잭션을 관리합니다. ## 참고자료 --- [[Database] 트랜잭션의 동작 원리와 ACID 속성](https://innovation123.tistory.com/61) [[DB기초] 트랜잭션이란 무엇인가?](https://coding-factory.tistory.com/226) [[DB] 트랜잭션 (Transaction)](https://minyakk.tistory.com/59) ",
    "url": "/Database/db_transaction.html",
    
    "relUrl": "/Database/db_transaction.html"
  },"41": {
    "doc": "데이터베이스의 종류",
    "title": "데이터베이스의 종류",
    "content": "# 데이터베이스의 종류 ## 계층형 데이터베이스 ![](/Database/img/db_types_of_databases_hierarchical_db.png) ### 특징 - 데이터를 레벨 또는 순위로 배열하여 트리와 유사한 구조로 데이터를 구성한다. - 부모 데이터는 그 아래에 하나 이상의 자식 데이터를 가진다. 하나의 자식 데이터에 둘 이상의 부모 데이터를 가질 수 없다. ### 장점 / 단점 - ✅ 부모-자식 구조의 엄격하고 복잡한 탐색에 이 이루어지기 때문에, 데이터베이스에 대한 쉬운 접근과 빠른 질의 시간으로 높은 성능을 제공. - ❌ 유연성이 떨어지고 확장하기 어렵다. - ❌ 새로운 데이터를 추가하려면 계층 구조를 탐색해야 하는 경우가 많으므로 시간이 오래 걸릴 수 있다. ### 사용되는 곳 - Windows 레지스트리 - 파일 시스템 (NTFS, HFS+ 등) - XML 파일 ## 관계형 데이터베이스 (SQL 데이터베이스) ### 특징 - 데이터 간에 사전 정의된 관계가 있으며, 이러한 관계를 통해 데이터를 저장하고, 데이터에 액세스 한다. - 행(혹은 레코드) 과 열로 구성되는 테이블 형식으로 데이터를 저장한다. 행과 열은 데이터의 속성과 값 간의 다양한 관계를 나타낸다. - 각 행에 존재하는 고유 식별자인 기본 키라는 속성과, 다른 테이블의 기본 키에 대한 참조인 외래 키를 사용하여 서로 다른 테이블 간의 관계를 만들 수도 있다. - 이전까지 자주사용되었던 계층형 데이터베이스의 데이터간의 관계를 파악하는 점이 힘들다는 한계를 가능하게 해준다. 또한, 물리적 데이터 스토리지 와 데이터베이스 관리 / 사용 을 분리했다. 따라서, 물리적 데이터 스토리지를 관리할 필요 없이 데이터를 저장하고 검색할 수 있다. ### 장점 / 단점 - ✅ 전체 데이터베이스 구조를 변경하거나 기존 애플리케이션에 영향을 주지 않고 테이블이나 관계, 데이터를 추가 및 업데이트, 삭제할 수 있다. - ✅ 테이블끼리 조인하여, 다양한 데이터 간의 상호 연결에 대한 더 깊은 인사이트를 얻을 수 있다. - ✅ 일련의 제약 조건(프라이머리 키, 외래 키, 'Not NULL' 제약 조건 등)을 사용하여 데이터베이스 내에서 데이터 무결성을 적용하기 때문에, 데이터의 정확성과 신뢰성을 보장된다. - ✅ ACID(원자성, 일관성, 격리, 내구성) 규정 을 준수하여, 오류, 실패 또는 기타 잠재적 오작동에 관계없이 데이터 유효성을 보장한다. ### SQL (구조적 쿼리 언어) - 관계형 데이터베이스에 정보를 저장하고 처리하기 위한 프로그래밍 언어 - SQL 문(혹은 SQL 쿼리) 을 사용하여 데이터베이스에서 정보를 저장, 업데이트, 제거, 검색 및 검색할 수 있다. - 데이터베이스 성능을 유지 관리하고 최적화하는 데에도 사용될 수 있다. ### 사용되는 곳 - MySQL, PostgreSQL, MariaDB, Microsoft SQL Server, Oracle Database ## 비-관계형 데이터베이스 (NO-SQL 데이터베이스) ### 특징 - SQL 데이터베이스에 대한 모든 대안 데이터베이스를 포괄하는 용어로써, 특정 데이터 모델에 맞춰 설계된다는 점에서 목적별 데이터베이스라고도 불리운다. - 현대적인 애플리케이션 구축을 위한 유연한 스키마를 갖춘다. ### 장점 / 단점 - ✅ 유연한 스키마를 제공하여 보다 빠르고 반복적인 개발을 가능하게 해준다. 이같은 유연한 데이터 모델은 NoSQL 데이터베이스를 반정형 및 비정형 데이터에 이상적으로 만들어 준다. - ✅ 일반적으로 고가의 강력한 서버를 추가하는 대신 분산형 하드웨어 클러스터를 이용하여, 확장에 용이하도록 설계되었다. - ✅ 특정 데이터 모델 및 액세스 패턴에 최적화되어있다. 따라서 관계형 데이터베이스로 유사한 기능을 수행할 때보다 더 높은 성능을 얻을 수 있다. ### 유형 - **문서 데이터베이스** : JSON, BSON, XML 형식으로 데이터를 저장하며, 유연한 구조 덕분에 개발자들이 선호한다. 전자 상거래, 거래 플랫폼, 모바일 앱 개발 등에 사용된다. MongoDB가 대표적이다. - **키-값 저장소** : 키와 값의 쌍으로 데이터를 저장하는 가장 단순한 형태이다. 사용자 기본 설정, 쇼핑 카트 등에 활용되며, Redis와 Riak KV 가 있다. - **컬럼 기반 데이터베이스** : 데이터를 컬럼 단위로 저장하여 특정 컬럼에 대한 분석에 효율적이다. 데이터 압축률이 높고 읽기 속도가 빠르며, 분석 작업에 주로 사용된다. - **그래프 데이터베이스** : 데이터 요소 간의 관계를 노드와 링크로 표현하는 데 특화되어 있다. 사기 탐지, 소셜 네트워크 분석 등에 사용되며, Neo4j가 대표적이다. ### 사용되는 곳 - Redis, Firebase 의 Realtime Databse / Cloud Firestore, MongoDB ## 출처 - [geeksforgeeks - Types of Databases](https://www.geeksforgeeks.org/types-of-databases/) - [mongodb - Types of Databases](https://www.mongodb.com/resources/basics/databases/types) - [google cloud - 관계형 데이터베이스란 무엇인가요?](https://cloud.google.com/learn/what-is-a-relational-database?hl=ko) - [aws - 관계형 데이터베이스 관리 시스템이란 무엇인가요?](https://aws.amazon.com/ko/relational-database/) ",
    "url": "/Database/db_types_of_databases.html",
    
    "relUrl": "/Database/db_types_of_databases.html"
  },"42": {
    "doc": "데이터베이스",
    "title": "데이터베이스",
    "content": "# 데이터베이스 - 데이터베이스 기초 - ERD & 정규화 - 트랜잭션 & 무결성 - 데이터베이스의 종류 - RDBS & NoSQL(MySQL, PostgreSQL, Redis, MongoDB 등 예시 활용) - 인덱스 - B-Tree - 조인 - 종류, 원리 - 분산 데이터베이스의 개념 - Event Sourcing & CQRS - 백업과 복구(Backup & Recovery) - 데이터 마이그레이션 전략 - 실행 계획(EXPLAIN) 분석 - Query Optimization (Slow Query Tuning) - 파티셔닝(Partitioning)과 샤딩(Sharding) - 캐싱 ",
    "url": "/Database/readme_DB.html",
    
    "relUrl": "/Database/readme_DB.html"
  },"43": {
    "doc": "Factory Pattern",
    "title": "Factory Pattern",
    "content": "# **Factory Pattern** 정확하게는 팩토리 메서드 패턴과 추상 팩토리 패턴이 있다. ## **Simple Factory** 객체를 생성하는 부분을 분리해 불필요한 의존성을 없애는 것을 팩토리 패턴, 심플 팩토리라고 부른다. 심플 팩토리는 정확하게 말하자면 패턴은 아니며 프로그래밍에서 자주 쓰이는 관용구에 가깝다. 아래는 심플 팩토리의 예시다. ```C++ class Pizza { public: virtual void prepared(); virtual void bake(); virtual void cut(); virtual void box(); } class CheesePizza : public Pizza { //... } class PepperoniPizza : public Pizza { //... } class SimplePizzaFactory { public: virtual Pizza* createPizza(string type) { Pizza* pizza = nullptr; switch(type) { case \"CheesePizza\": pizza = new CheesePizza(); break; //... } //... return pizza; } } class PizzaStore { SimplePizzaFactory factory; public: PizzaStore(SimplePizzaFactory factory) { this.factory = factory; } static Pizza orderPizza(string type) { Pizza* pizza = createPizza(type); pizza->prepared(); pizza->bake(); pizza->cut(); pizza->box(); return pizza; } } ``` 심플 팩토리에서는 팩토리 클래스로 객체를 생성한다. 하지만 팩토리 클래스는 `prepared()`, `bake()`, `cut()`, `box()`와 같은 후처리 함수의 호출까지는 담당하지 않는다. 이 특징은 객체 생성 후 후처리가 필요한 경우에 문제가 될 수 있다. 후처리 함수를 호출하지 않거나, 함수의 존재를 몰라 새롭게 후처리 코드를 추가하는 일은 흔하게 발생한다. **팩토리 메소드 패턴**은 이런 문제를 방지할 때 필요하다. ## **Factory Method Pattern** **팩토리 메소드 패턴**은 구상 팩토리 클래스에 의존하지 않고, 객체 생성에 인터페이스를 제공하는 것이다. 아래는 이해를 돕기 위한 예제다. ```C++ class PizzaStore { public: Pizza orderPizza(String type) { Pizza* pizza = createPizza(type); pizza->prepared(); pizza->bake(); pizza->cut(); pizza->box(); return pizza; } virtual Pizza* createPizza(string type); } ``` 원래는 클래스의 인스턴스를 만드는 일을 `PizzaStore` 클래스에서 전부 처리하는 방식이었다면, 지금은 `PizzaStore`을 상속받는 서브클래스가 처리하는 방식으로 바뀌었다. 팩토리 클래스의 인스턴스에 의존적이었던 기존 코드에서 의존성이 제거되었다. 팩토리 메소드를 정리하자면 다음과 같다. - 팩토리 메소드 패턴은 객체를 생성할 때 필요한 인터페이스를 만든다. - 어떤 클래스의 인스턴스를 만들지는 서브클래스에서 결정한다 - 팩토리 메서드 패턴을 사용하면 클래스 인스턴스 생성을 서브클래스에 맡기게 된다. ## **Abstract Factory Pattern** **추상 팩토리 패턴**은 객체의 생성 과정을 추상 팩토리 객체를 이용해 진행한다. 이 방식은 제품군을 만들 때 유용하다. 예를 들어 컴퓨터를 만드려고 한다면, OS와 모니터, 본체, 주변 기기들을 만드는 팩토리가 필요할 것이다. OS의 팩토리는 마이크로소프트와 애플이 있을 것이고, 모니터는 LG와 삼성, 주변 기기들도 마찬가지로 다양한 팩토리를 가지고 있을 것이다. 이처럼 구상 팩토리 클래스를 구현하고, 실제로 팩토리를 사용할 때는 추상 팩토리의 인터페이스를 호출함으로서 의존성을 제거한다. ```C++ class AbstractFactory { public: virtual PartA* CreatePartA(); virtual PartB* CreatePartB(); } class ConcreteFactory1 { public: virtual PartA* CreatePartA() { //... } virtual PartB* CreatePartB() { //... } } class ConcreteFactory2 { public: virtual PartA* CreatePartA() { //... } virtual PartB* CreatePartB() { //... } } ``` ### 참고 - [헤드퍼스트 디자인패턴 개정판](https://www.yes24.com/Product/Goods/108192370?pid=123487&cosemkid=go16481149710577107&utm_source=google_pc&utm_medium=cpc&utm_campaign=book_pc&utm_content=ys_240530_google_pc_cc_book_pc_12203%EB%8F%84%EC%84%9C&utm_term=%ED%97%A4%EB%93%9C%ED%8D%BC%EC%8A%A4%ED%8A%B8%EB%94%94%EC%9E%90%EC%9D%B8%ED%8C%A8%ED%84%B4&gad_source=1&gclid=CjwKCAiA5Ka9BhB5EiwA1ZVtvJslHKzenw6UU2fr3tyJDb4AKzJ7X-O2jE42dZHrC54wdt-Lxu-ZWhoCjasQAvD_BwE) ",
    "url": "/Design_Pattern/dp_factory_pattern.html",
    
    "relUrl": "/Design_Pattern/dp_factory_pattern.html"
  },"44": {
    "doc": "Iterator pattern",
    "title": "Iterator pattern",
    "content": "# Iterator pattern 반복자 패턴은 반복 작업을 캡슐화하는 패턴이다. 개발을 하다보면 자료구조 안에 있는 객체에 일일이 접근해야하는 상황이 있다. 어떻게 저장했느냐에 따라 객체에 접근하는 방식이 다른데, 반복자 패턴은 객체 저장 방식을 숨기면서도 객체에 일일이 접근할 수 있게 해준다. 먼저 반복자 인터페이스를 정의한다. ```C++ template class Iterator { public: virtual bool hasNext(); virtual T next(); virtual void remove(); } ``` 그 다음 구상 클래스를 만든다 ```C++ class ArrayIterator : Iterator { int currentIndex = -1; vector myArr; public: ArrayIterator(vector myArr) { this->myArr = myArr; } bool hasNext() { return currentIndex + 1 { stack myStack; public: StackIterator(stack myStack) { this->myStack = myStack; } bool hasNext() { return !myStack.empty(); } int next() { int result = myStack.top(); myStack.pop(); return result; } void remove() { myStack.pop(); } }; ``` 이렇게 구현하고 나면 저장 방법과 데이터 타입에 구애받지 않고 반복자 패턴으로 개별 요소에 하나씩 접근할 수 있게 된다. # 참고 - [헤드퍼스트 디자인패턴 개정판](https://www.yes24.com/Product/Goods/108192370?pid=123487&cosemkid=go16481149710577107&utm_source=google_pc&utm_medium=cpc&utm_campaign=book_pc&utm_content=ys_240530_google_pc_cc_book_pc_12203%EB%8F%84%EC%84%9C&utm_term=%ED%97%A4%EB%93%9C%ED%8D%BC%EC%8A%A4%ED%8A%B8%EB%94%94%EC%9E%90%EC%9D%B8%ED%8C%A8%ED%84%B4&gad_source=1&gclid=CjwKCAiA5Ka9BhB5EiwA1ZVtvJslHKzenw6UU2fr3tyJDb4AKzJ7X-O2jE42dZHrC54wdt-Lxu-ZWhoCjasQAvD_BwE) ",
    "url": "/Design_Pattern/dp_iterator_pattern.html",
    
    "relUrl": "/Design_Pattern/dp_iterator_pattern.html"
  },"45": {
    "doc": "MVC 패턴",
    "title": "MVC 패턴",
    "content": "## MVC 패턴 ### MVC란? MVC(Model-View-Controller) 패턴은 어플리케이션을 **Model(모델)**, **View(뷰)**, **Controller(컨트롤러)**의 세 가지 역할로 구분하여 개발하는 소프트웨어 디자인 패턴입니다. 이렇게 역할을 분리하면 **유지보수**와 **확장성**이 용이해지고, **협업** 시에도 역할을 명확히 나눌 수 있어서 효율적인 개발이 가능합니다. ![](/Design%20Pattern/img/dp_mvc_1.png) ## MVC의 구성 요소 ### Model - **데이터(상태) 및 비즈니스 로직**을 담당합니다. - 데이터베이스와의 연동이나 핵심 로직을 수행하며, **뷰**나 **컨트롤러**는 모델에 직접 접근해 데이터를 얻거나 변경합니다. - 예) 회원 정보, 게시글 정보, 상품 정보 등 ### View - **사용자에게 보이는 화면(UI)**을 담당합니다. - 모델에서 받은 데이터를 시각적으로 표현하며, 사용자의 입력(이벤트) 또한 받아들입니다. - 예) HTML, JSP, Swing, JavaFX 등의 화면 요소 ### Controller - **사용자의 요청 처리** 및 **흐름 제어**를 담당합니다. - 사용자의 입력을 받아서 어떤 모델을 사용할지 결정하고, 모델에 명령을 내려 데이터를 변경하거나 조회한 뒤, 결과를 뷰에 전달합니다. - 예) Servlet, Spring Controller 등 ## MVC의 동작 흐름 1. **View**(사용자 화면)에서 이벤트(버튼 클릭, 폼 제출 등)가 발생합니다. 2. 이벤트를 **Controller**가 받아서 요청에 맞는 모델을 찾고, 필요한 연산을 수행하도록 지시합니다. 3. **Model**은 요구된 연산을 수행하거나 데이터베이스와 연동해 결과 데이터를 생성(또는 갱신)합니다. 4. **Model**에서 처리된 결과를 **Controller**가 받아, 적절한 **View**를 선택합니다. 5. 최종 결과를 담은 **View**가 사용자에게 렌더링되어 보여집니다. ![](/Design%20Pattern/img/dp_mvc_2.png) ## MVC의 장점 - **역할 분리로 인한 유지보수 용이**: 비즈니스 로직(Model)과 화면(View), 흐름 제어(Controller)가 분리되어 있어 각 부분을 독립적으로 수정하거나 교체하기가 쉽습니다. - **확장성**: 특정 기능만 바꿔야 할 때 전체 코드를 수정하지 않고, 해당 모듈(예: Model, View, Controller 중 하나)만 수정하면 됩니다. ## MVC의 단점 - **구조가 복잡해짐**: 작은 규모의 프로젝트에서는 파일이 많아지고 구조가 복잡해져 오히려 비효율적일 수 있습니다. - **데이터 바인딩/상호 의존성**: 모델과 컨트롤러, 뷰가 상호 의존관계를 가지면서 긴밀히 연결되면, 수정 시 영향 범위가 넓어질 수 있습니다. ## Java 예시 (간단 구조) 아래 예시 코드는 MVC 구조를 아주 단순화해서 나타냈습니다. ```java // Model: User.java public class User { private String name; private int age; public User(String name, int age) { this.name = name; this.age = age; } // Getter & Setter public String getName() { return name; } public void setName(String name) { this.name = name; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } } // View: UserView.java public class UserView { public void printUserDetails(String name, int age) { System.out.println(\"User: \" + name + \", Age: \" + age); } } // Controller: UserController.java public class UserController { private User model; private UserView view; public UserController(User model, UserView view) { this.model = model; this.view = view; } public void setUserName(String name) { model.setName(name); } public String getUserName() { return model.getName(); } public void setUserAge(int age) { model.setAge(age); } public int getUserAge() { return model.getAge(); } public void updateView() { view.printUserDetails(model.getName(), model.getAge()); } } // Main: Main.java public class Main { public static void main(String[] args) { // 모델 생성 User user = new User(\"Alice\", 20); // 뷰 생성 UserView view = new UserView(); // 컨트롤러에 모델과 뷰 전달 UserController controller = new UserController(user, view); // 초기 상태 출력 controller.updateView(); // 모델 정보 변경 controller.setUserName(\"Bob\"); controller.setUserAge(30); // 변경 후 출력 controller.updateView(); } } // 출력 결과 User: Alice, Age: 20 User: Bob, Age: 30 ``` 1. `User`(Model)은 사용자 데이터를 가지고 있습니다. 2. `UserView`(View)는 데이터를 출력하는 역할을 수행합니다. 3. `UserController`(Controller)는 모델과 뷰를 연결하여 데이터 변경 또는 뷰 업데이트를 담당합니다. ## MVC와 관련이 깊은 내용들 ### 1. Spring MVC - **Spring** 프레임워크에서 제공하는 MVC 구조를 이용해, **DispatcherServlet**이 컨트롤러의 역할을 수행하고, **Model**과 **View**를 각각 쉽게 관리합니다. - 컴포넌트 스캔, 의존성 주입(DI) 등을 통해 애플리케이션 전반을 구조화할 수 있습니다. ### 2. JSP & Servlet - Java 웹 프로그래밍에서 기본적으로 MVC를 구현할 수 있는 기술 스택입니다. - **Servlet**: Controller 역할(사용자 요청 처리, 로직 수행 후 JSP에 데이터 전달) - **JSP**: View 역할(모델에서 전달된 데이터를 표현, 화면 구성) - **Model**: DTO, DAO, Service 계층 등을 분리해 구성 가능 ### 3. ASP.NET MVC - Microsoft의 .NET 프레임워크 기반 웹 개발에서 사용되는 MVC 구현체입니다. - Controller, Model, View를 명확히 나누어 개발하도록 구조화되어 있습니다. ### 4. Ruby on Rails - Ruby 언어 기반의 웹 프레임워크로, MVC 패턴을 강력히 지원하며 **Convention over Configuration**(관례가 많은 부분을 대신 처리) 철학을 갖고 있습니다. ## 참고 자료 1. [면접을 위한 CS 전공지식 노트, 주홍철] 2. [Spring 공식 문서 (Spring MVC)](https://docs.spring.io/spring-framework/docs/current/reference/html/web.html#spring-web) 3. [Microsoft Docs (ASP.NET MVC)](https://learn.microsoft.com/aspnet/mvc) 4. [Ruby on Rails 공식 사이트](https://rubyonrails.org/) ",
    "url": "/Design_Pattern/dp_mvc_pattern.html",
    
    "relUrl": "/Design_Pattern/dp_mvc_pattern.html"
  },"46": {
    "doc": "MVP Architecture Pattern",
    "title": "MVP Architecture Pattern",
    "content": "# MVP Architecture Pattern MVP(Model-View-Presenter) 아키텍처 패턴 은 사용자 인터페이스 구축에 주로 사용되는 **MVC(Model-View-Controller) 아키텍처 패턴의 파생형** 이다. MVC 패턴의 **`Controller` 의 자리에** 중개자 역할을 하는, **`Presenter` 라는 것이 위치**하게 된다. ![](/Design%20Pattern/img/dp_mvp_pattern_diagram.png) - **`Model`**: 데이터와 비즈니스 로직을 처리하는 계층. API 사용, 데이터 캐싱, 데이터베이스 관리 와 같은 기능 담당. - **`View`** : 데이터를 표시하고, 유저 이벤트를 처리하는 계층. 유저 이벤트가 발생하면, `Presenter` 의 메서드를 호출한다. - **`Presenter`** : `View` 와 `Model` 사이의 중개자 역할을 하는 계층이다. `Model` 에서 데이터를 가져와 포맷팅한 후 `View`에 반환한다. 또한 `View` 인터페이스를 통한 사용자 상호작용에 반응하여 `Model`을 업데이트한다. # MVC 패턴 사용 이유와 한계점 ![](/Design%20Pattern/img/dp_mvp_pattern_mvc_why.png) 하나의 파일안에 계속 코드를 작성하면, 어떤 코드가 어디에 있는지 확인하기 어려워, 유지 보수, 변경이 어려워진다. 이런 점을 개선하기 위해 각각의 역할(`Model`, `View`, `Controller`) 에 따라 코드를 나누기 위해 MVC 패턴이 사용된다. --- 새로운 안드로이드 프로젝트를 생성하면 MVC 패턴 의 각각의 역할에 해당하는 다음과 같은 파일들이 생성된다. ![](/Design%20Pattern/img/dp_mvp_pattern_android.png) 하지만 실질적으로 안드로이드 프로젝트에서 **`Controller` 는 `View` 와 상당히 밀접하게 연결**되어 있다. 따라서, 사실상 `Controller` 는 `View` 에 속해있는 것에 가깝다고 볼 수 있다. ![](/Design%20Pattern/img/dp_mvp_pattern_android_2.png) 이러한 점 때문에, - `Controller` 와 `View` 가 밀접하게 연결 되어 있어 - **역할에 따른 분리가 실질적으로 명확하게 일어나지 않는 다는 점** - **테스트가 어렵다**는 점 - `Controller` 가 `View` 와 `Model` 을 모두 참조하기에, **프로젝트가 커질 수록 쉽게 비대**해 질 가능성 ⬆️ - **데이터와 비즈니스 로직을 처리**하는 `Model` 과 **UI 를 담당**하는 `View` 사이의 **의존성 발생** 과 같은 한계점이 발생하게 된다. # MVC 패턴과의 차이 및 개선점 - 가장 큰 개선점으로는 **비즈니스 로직을 처리하는 계층과 UI 를 처리하는 계층을 분리** 했다는 것에 있다. `View` 와 `Model` 사이의 중개자 역할을 하는 `Presenter` 의 등장으로, 기존 MVC 패턴 의 `View` 와 `Model` 사이에 있었던 의존성을 제거하게 되었다. - MVC 패턴에서는 `Controller` 가 유저 이벤트를 처리하지만, MVP 패턴에서는 이를 `View` 가 처리한다. 유저 이벤트에 대한 책임을 좀 더 명확하게 분산한다. # 한계점 - `View` 와 `Presenter` 가 밀접하게 연결되어 있다는 점 - 이로 인해 여전히 테스트가 어렵다는 점 - **보일러플레이트**(View 와 Presenter 에 대한 인터페이스) 발생 # 코드로 표현한 MVP 패턴 1. `View` 와 `Presenter` 의 인터페이스 를 포함하는 `Contract` 인터페이스 를 생성한다. ```kotlin // Boilerplate interface Contract { // `View` 인터페이스 interface `View` { fun showToast() } // `Presenter` 인터페이스 interface `Presenter` { fun onButtonClick() } } ``` 2. `Contract.Presenter` 인터페이스를 상속받는 `Presenter` 클래스 와 `Contract.View` 인터페이스를 상속받는 `Activity` 클래스를 생성한다. ```kotlin // Contract.View 인터페이스를 상속받는 Activity 클래스 // 행위에 대한 구체적인 내용 추가 class MainActivity: AppCompatActivity(), Contract.View { lateinit var presenter: MainPresenter override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) setContentView(R.layout.activity_main) presenter = MainPresenter(this) // 버튼 클릭 리스너가 호출 되면, btn.setOnClickListener { // Presenter 에게 \"버튼이 클릭되었다\" 라고 알려줌 presenter.onButtonClick() // Presenter 는 필요시, Model 업데이트와 같은 로직 실행 } } // 유저에게 보여줄 데이터 override fun showToast() { Toast.makeText(this, \"Button pressed\", Toast.LENGTH_SHORT). show() } } ``` ```kotlin // Contract.Presenter 인터페이스를 상속받는 Presenter 클래스 class MainPresenter ( private var view: Contract.View ): Contract.Presenter { override fun onButtonClick() { // View 에게 \"토스트를 보내줘\" 라고 알려줌. view.showTest() } } ``` # 출처 - [What is MVP Design Pattern?](https://medium.com/huawei-developers/what-is-mvp-design-pattern-c587feea27d7) - [Android Architecture Patterns: MVC vs MVVM vs MVP](https://daily.dev/blog/android-architecture-patterns-mvc-vs-mvvm-vs-mvp) - [[10분 테코톡] 악어의 안드로이드 MVC 부터 MVVM 까지](https://www.youtube.com/watch?v=OPXf00DX4b0&t=12s) ",
    "url": "/Design_Pattern/dp_mvp_pattern.html",
    
    "relUrl": "/Design_Pattern/dp_mvp_pattern.html"
  },"47": {
    "doc": "MVVM 패턴 정의",
    "title": "MVVM 패턴 정의",
    "content": "# MVVM 패턴 정의 ### **MVVM (Model-View-ViewModel)** 패턴은 Model View, View, Model의 약자로 프로그램의 비지니스 로직과, 프레젠테이션 로직을 UI로 명확하게 분리하는 패턴입니다. ![alt text](/Design_Pattern/img/mvvm.png) ### **Model** 데이터를 다루는 부분. 비즈니스 로직을 포함한다. - 데이터 관리 및 데이터관련 비즈니스 로직을 담당하는 부분입니다. - **데이터를 가져오고 저장하는 역할**을 수행합니다. - 보통 데이터베이스, 네트워크 요청 또는 파일 시스템과 같은 데이터 소스와 상호 작용합니다. ### **View** 레이아웃과 화면을 보여주는 역할 - 사용자 인터페이스를 담당하는 부분입니다. - 사용자가 보는 화면을 표시하고, 사용자 입력을 처리합니다. - 보통 XAML과 같은 마크업 언어를 사용하여 디자인됩니다. ### **ViewModel** - View와 Model 사이에서 중재자 역할을 수행합니다. - **뷰가 사용할 메서드와 필드를 구현합니다.** - View에서 발생하는 이벤트를 감지하고, 해당 이벤트에 맞는 비즈니스 로직을 수행합니다. - Model과 상호작용하여 데이터를 가져오거나 업데이트하고, View에 데이터를 업데이트하는 역할을 합니다. - View에 표시할 데이터를 가공하여 제공하는 역할을 합니다. # MVVM 동작 과정 ![alt text](/Design_Pattern/img/mvvm2.png) 1. 사용자의 Action들은 View를 통해 들어옵니다. 2. View에 Action이 들어오면 ViewModel에 Action을 전달합니다. 3. ViewModel은 Model에게 데이터를 요청합니다. 4. Model은 ViewModel에게 요청받은 데이터를 응답합니다. 5. ViewModel은 응답 받은 데이터를 가공하여 저장합니다. 6. View는 Data Binding을 이용해 UI를 갱신시킵니다. # MVVM 특징 **MVVM은 View와 ViewModel사이의 관계가 1대n**으로 되어있습니다. 또한 데이터 바인딩을 이용한다면 **View**와 **ViewModel** 사이의 의존성을 없앨 수 있습니다. # MVVM 단점 - 설계하기가 복잡하다. (Rx,데이터 바인딩에 대한 지식 필요) - 뷰모델이 비대해질 수 있다. - 데이터 바인딩으로 인한 메모리 소모가 심하다. - ViewModel 설계가 복잡하다는 단점이 있습니다. ",
    "url": "/Design_Pattern/dp_mvvm_pattern.html",
    
    "relUrl": "/Design_Pattern/dp_mvvm_pattern.html"
  },"48": {
    "doc": "정의",
    "title": "정의",
    "content": "## 정의 옵저버 패턴은 객체의 상태 변화를 관찰하는 관찰자들 , 즉 옵저버들의 목록을 객체에 등록하여 상태 변화가 있을 때마다 메서드 등을 통해 객체가 직접 목록의 각 옵저버에게 통지하도록 하는 디자인패턴. 쉽게 말해 어떤 객체의 상태가 변할 때 그와 연관된 객체들에게 알림을 보내는 디자인 패턴 **Observer(관찰자)** 상태 변화를 감지하는 대상이다. 옵저버에는 함수나 객체 모두 등록이 가능하다. **Obervable(객체)** 상태가 변경되는 대상이다. subscribe, unsubscribe, notify 등 행동을 처리하는 메서드를 보유하고 있어야 한다. --- ## 특징 - 옵저버 패턴은 다른 디자인패턴들과 다르게 일대 다 의 의존성을 가진다. - 주로 분산 이벤트 핸들링 시스템을 구현하는데 사용된다. - 옵저버 패턴의 핵심은 의존성을 낮추는 것(결합도를 낮추는 것)이다. --- ## 옵저버 패턴 흐름 1. 한개의 관찰 대상자와 여러개의 관찰자로 일대 다 관계로 구성되어있다. 2. 옵저버 패턴에서는 관찰 대상의 상태가 바뀌면 변경사항을 옵저버 한테 통보해준다. 3. 대상자로부터 통보를 받은 옵저버는 값을 바꿀수도 있고, 삭제하는등 적절히 대응한다. 4. 옵저버들은 언제든 대상자의 그룹에서 추가/삭제 될 수 있다. 관찰 대상 그룹에 추가되면 관찰 대상자로부터 정보를 전달받게 될 것 이며, 그룹에서 삭제될경우 더이상 관찰 대상자의 정보를 받을 수 없게 된다. ![](/Design_Pattern/img/observer1.png) --- ## 예시 유튜브 채널 → 발행자(**Obervable**) 구독자 → 관찰자(**Observer**) 유튜버가 영상을 올라면 여러명의 구독자들은 모두 영상이 올라왔다는 알림을 받는다. 이를 패턴구조로 보면, 구독자들은 해당 채널을 구독함으로써 채널에 어떠한 변화가 생기게 되면 바로 연락을 받아 탐지하는 것. 반면 구독을 해지하거나 안한 시청자들에게는 알림이 가지 않는다. ![](/Design_Pattern/img/observer2.png) --- ## 예시 코드 만약 Youtube라는 객체와 Tom, Jane, James라는 옵저버 객체가 있다면 ```jsx //**Obervable ::** 구독, 구독취소, 알림 메서드를 정의 class Youtube{ constructor(){ this.observer=[]; } subscribe(observer){ this.observer.push(observer); } unsubscribe(observer){ this.observer = this.observer.filter(obs => obs !== observer); } notifySubscriber(data){ this.observer.forEach(obs => obs.update(data)); } } //**Observer :: Obervable이 알림 메서드를 활용할 때, 알림을 받고 개별 동작을 수행할 수 있는 메서드를 정의** class Observer{ update(data){ ... //Jane 클래스가 구독한 옵저버블의 상태변화가 일어났을 때 행동해야 할 로직 } } class Jane extends Observer{ } ``` ",
    "url": "/Design_Pattern/dp_observer_pattern.html",
    
    "relUrl": "/Design_Pattern/dp_observer_pattern.html"
  },"49": {
    "doc": "프록시 패턴 (Proxy Pattern)",
    "title": "프록시 패턴 (Proxy Pattern)",
    "content": "# ## **프록시 패턴 (Proxy Pattern)** ![img](/Design_Pattern/img/dp_proxy_pattern_1.png) - 객체에 대한 접근을 제어하기 위해 대리 객체(프록시)를 제공하는 디자인 패턴 - 클라이언트가 직접 대상 객체(Real Subject)에 접근하지 않고, 프록시를 통해 제어 ### 유형 | 유형 | 설명 | 대표 예제 | --- | --- | --- | **원격(Remote) 프록시** | 네트워크를 통해 원격 객체를 호출 | 원격 API 호출, RMI, HTTP 프록시 | **가상(Virtual) 프록시** | 무거운 객체의 생성을 지연(지연 로딩) | 이미지 로딩, ORM(Lazy Loading) | **보호(Protection) 프록시** | 접근 제어(권한 관리) | 접근 권한 제어 | **캐싱(Cache) 프록시** | 자주 쓰는 데이터를 저장하여 성능 향상 | CDN, API 캐싱, DB 캐싱 | **스마트(Smart) 프록시** | 원래 객체에 추가 기능 부여 | 로깅, 암호화, 트랜잭션 | ### 예제: 이미지 업로드 **인터페이스** ```java public interface Image { void display(); } ``` **실제 객체** ```java public class RealImage implements Image { private String filename; public RealImage(String filename) { this.filename = filename; loadFromDisk(); } @Override public void display() { System.out.println(\"Displaying \" + filename); } private void loadFromDisk() { System.out.println(\"Loading : \" + filename); } } ``` **가상 프록시** 실제로 이미지는 `display()` 호출 시점에 로드된다. ```java public class ProxyImage implements Image { private RealImage realImage; private String filename; public ProxyImage(String filename) { this.filename = filename; } @Override public void display() { if (realImage == null) { realImage = new RealImage(filename); // 실제 객체를 처음 사용할 때 생성 } realImage.display(); } } ``` **클라이언트 코드** 클라이언트는 `ProxyImage`를 사용 ```java public class ProxyPattern { public static void main(String[] args) { Image image1 = new ProxyImage(\"image1.jpg\"); Image image2 = new ProxyImage(\"image2.jpg\"); // 이미지가 필요할 때 로드 image1.display(); image2.display(); } } ``` **실행 결과** ``` Loading : image1.jpg Displaying image1.jpg Loading : image2.jpg Displaying image2.jpg ``` --- ## **프록시 서버 (Proxy Server)** ![img](/Design_Pattern/img/dp_proxy_pattern_2.png) - 클라이언트와 서버 사이에 위치하여 요청을 중계하는 서버 - 보안, 성능 최적화, 익명성 보호 등의 역할 수행 - 보안 강화, 속도 개선, 우회 접속, 로깅 및 트래픽 관리 등 ### **역할** | 역할 | 설명 | 예시 | --- | --- | --- | **보안 강화** | 사용자의 실제 IP를 숨기고, 방화벽 기능 수행 | VPN | **캐싱 & 속도 향상** | 자주 방문하는 페이지를 저장하여 로딩 속도 개선 | CDN | **접근 제한** | 특정 웹사이트 차단, 기업/학교의 인터넷 정책 적용 | 사내 내부망 | **로그 & 모니터링** | 사용자 트래픽 기록, 네트워크 분석 및 감사 | 기업 보안 관리, 정부 감시 | **우회 접속** | 차단된 사이트나 지역 제한 콘텐츠 접근 가능 | 유튜브, 넷플릭스 우회 | ### **유형** | 유형 | 설명 | 예제 | --- | --- | --- | **정방향(Forward) 프록시** | 클라이언트 → 프록시 서버 → 인터넷 | 기업 내부망, VPN | **역방향(Reverse) 프록시** | 클라이언트 → 프록시 서버 → 내부 서버 | 로드 밸런싱, Nginx | **트랜스페어런트(Transparent) 프록시** | 클라이언트가 프록시를 인식하지 못함 | 기업, 공공 와이파이 | **공개(Open) 프록시** | 누구나 사용할 수 있는 프록시 | 무료 프록시 서버 | ## 프록시 패턴과 서버 | 프록시 패턴 | 프록시 서버 | --- | --- | --- | 개념 | 객체 앞에 대리 객체(Proxy)를 두어 간접 접근 | 클라이언트와 서버 사이에서 요청을 중계 | 주요 목적 | 성능 최적화, 접근 제어, 로깅 | 보안 강화, 캐싱, 익명성 제공 | 사용 위치 | 애플리케이션 내부 (코드 레벨) | 네트워크 구조 (클라이언트-서버 사이) | --- ## **프록시 서버 와 VPN** ### **프록시 서버 (Proxy Server)** - 특정 애플리케이션(웹 브라우저, 특정 프로그램)의 요청만 중계 - IP 주소를 변경하거나 웹 콘텐츠 필터링 등에 사용 - 트래픽이 **암호화되지 않으며**, 보안보다는 우회 및 캐싱이 주목적 ### **VPN (Virtual Private Network)** - 사용자의 **모든 네트워크 트래픽을 암호화**하여 보호 - **사용자의 전체 인터넷 트래픽을 보호**하여, 위치를 숨기고 감청을 방지 - 공용 네트워크에서도 안전한 통신을 보장 | 프록시 서버 | VPN | --- | --- | --- | **동작 방식** | 특정 요청(HTTP/HTTPS, DNS 등)만 중계 | 모든 네트워크 트래픽을 암호화하여 터널링 | **보안 수준** | 낮음 (일반적으로 암호화 없음) | 높음 (모든 트래픽 암호화) | **IP 숨김 기능** | 일부 가능 (웹사이트에는 숨겨짐) | 전체 네트워크에서 IP 숨김 | **속도** | 빠름 (캐싱 활용 가능) | 상대적으로 느림 (암호화로 인한 오버헤드 발생) | **익명성** | 제한적 (웹 트래픽만 보호) | 강력한 익명성 보장 | **사용 목적** | 웹 필터링, 캐싱, 차단된 콘텐츠 우회 | 보안 강화, 데이터 암호화, 감시 회피 | **프록시 서버** → 특정 요청만 중계 (웹 필터링, IP 변경, 캐싱) **VPN** → 모든 네트워크 트래픽을 암호화하여 보안 강화 👉 **보안이 중요하다면 VPN을, 단순한 IP 우회나 캐싱이 필요하다면 프록시를 사용** --- [https://inpa.tistory.com/entry/GOF-💠-프록시Proxy-패턴-제대로-배워보자](https://inpa.tistory.com/entry/GOF-%F0%9F%92%A0-%ED%94%84%EB%A1%9D%EC%8B%9CProxy-%ED%8C%A8%ED%84%B4-%EC%A0%9C%EB%8C%80%EB%A1%9C-%EB%B0%B0%EC%9B%8C%EB%B3%B4%EC%9E%90) https://refactoring.guru/design-patterns/proxy [https://effectiveprogramming.tistory.com/entry/Proxy-패턴과-그-활용](https://effectiveprogramming.tistory.com/entry/Proxy-%ED%8C%A8%ED%84%B4%EA%B3%BC-%EA%B7%B8-%ED%99%9C%EC%9A%A9) https://nordvpn.com/ko/blog/proxy-versus-vpn/ https://www.cloudflare.com/ko-kr/learning/cdn/glossary/reverse-proxy/ ",
    "url": "/Design_Pattern/dp_proxy_pattern.html",
    
    "relUrl": "/Design_Pattern/dp_proxy_pattern.html"
  },"50": {
    "doc": "노출모듈 패턴 정의",
    "title": "노출모듈 패턴 정의",
    "content": "## 노출모듈 패턴 정의 즉시 실행 함수를 통해 private, public같은 접근 제어자를 만드는 패턴 객체와 함수를 활용하여 모듈을 구조화하고 필요한 부분만을 외부에 노출시키는 방식으로 동작함 ## 노출 모듈 패턴의 구성 요소 1. **즉시 실행 함수(IIFE) ::** 노출 모듈 패턴은 즉시 실행 함수를 사용하여 모듈을 생성합니다. 이를 통해 모듈 내부의 변수와 함수들은 함수 스코프 내에 감춰져 외부에서 직접 접근할 수 없게 됩니다. 2. **프라이빗 변수 및 함수 ::** 모듈 내부에서는 외부에서 직접 접근되지 않을 프라이빗 변수와 함수들이 정의됩니다. 이들은 모듈 내부에서만 사용되며 외부에서는 접근할 수 없습니다. 3. **퍼블릭 변수 노출 ::** 모듈 외부에서 접근 가능한 변수를 명시적으로 지정하여 외부에 노출합니다. 이는 모듈의 인터페이스를 정의하며, 모듈 외부에서 사용 가능한 기능을 결정합니다. ## **노출 모듈 패턴의 장점** - **유연성과 확장성** 노출 모듈 패턴은 모듈 내부의 구현을 변경하더라도 외부 인터페이스를 그대로 유지할 수 있습니다. 이는 모듈의 구현을 수정하더라도 클라이언트 코드를 변경하지 않고도 호환성을 유지할 수 있게 함 - **테스트 용이성** 노출 모듈 패턴을 사용하면 모듈의 내부 상태와 동작을 캡슐화하고, 외부에는 필요한 기능만을 노출하기 때문에 모듈의 단위 테스트가 더 쉬워짐 - **정보 은닉** 오로지 공개된 인터페이스만 외부에 노출하여 사용자가 모듈을 좀 더 쉽고 안전하게 사용할 수 있음. ## 노출 모듈 패턴의 단점 - **모듈 간 종속성** 각 모듈이 다른 모듈의 내부 구현에 의존하는 경우, 이는 모듈 간의 결합도를 증가시킬 수 있습니다. 이는 모듈의 재사용성과 독립성을 감소시킬 수 있습니다. ## 구현 예시 ```jsx var MyModule = (function() { var privateVariable = \"This is a private variable\"; function privateFunction() { console.log(\"This is a private function\"); } function publicFunction() { console.log(\"This is a public function\"); } // 외부로 노출할 멤버를 객체로 반환합니다. return { publicFunction: publicFunction }; })(); // MyModule은 publicFunction만 외부에 노출됩니다. MyModule.publicFunction(); // 출력: \"This is a public function\" MyModule.privateVariable; // undefined (privateVariable은 외부에서 접근 불가능) MyModule.privateFunction(); // 오류 (privateFunction은 외부에서 접근 불가능) ``` --- 출처 https://geumjulee.tistory.com/52 https://velog.io/@juijeong8324/Design-Pattern-8 https://reveur1996.tistory.com/156 ",
    "url": "/Design_Pattern/dp_revealing_module_pattern.html",
    
    "relUrl": "/Design_Pattern/dp_revealing_module_pattern.html"
  },"51": {
    "doc": "싱글톤 패턴",
    "title": "싱글톤 패턴",
    "content": "# 싱글톤 패턴 ## 싱글톤 패턴(Singleton Pattern) ### 1. 싱글톤 패턴 개요 **싱글톤 패턴**은 특정 클래스에 대해 **단 하나의 인스턴스만 존재**하도록 보장하는 디자인 패턴입니다. 이 패턴은 **메모리 최적화**와 **자원 공유**가 필요한 경우에 유용합니다. - **주요 특징**: - **하나의 인스턴스만 존재**: 동일 클래스에서 객체가 중복 생성되지 않도록 보장 - **전역 접근**: 애플리케이션 어디서든 동일한 객체를 접근 가능 - **객체 재사용**: 한 번 생성된 인스턴스를 재사용하여 리소스 절약 ### 2. 싱글톤 패턴 구현 원리 ![class.jpg](https://github.com/user-attachments/assets/16408d65-183b-4f83-ae3e-43d80c2474e5) - 생성자 private 설정 : 외부에서 `new`로 인스턴스를 생성할 수 없도록 제한 - `getInstance()` 메서드 이용: 이미 생성된 인스턴스를 반환하는식으로 구성 ### 3. 싱글톤 패턴 구현 기법 모두 싱글톤을 지향한다는 점은 같지만 장단점이 존재합니다. 각 코드 기법들은 단점들이 존재하며, 최종적으로는 6번, 7번을 사용하여 싱글톤을 구현하는것을 권장합니다. 1. Eager Initialization 2. Static block initialization 3. Lazy initialization 4. Thread safe initialization 5. Double-Checked Locking 6. Bill Pugh Solution 7. Enum ### 4. 각 기법 설명 ### (1) **Eager Initialization** - 한번만 미리 만들어두는, 가장 직관적인 방법 - 객체가 사용 되기 전에 즉시 초기화가 이루어져, 애플리케이션 실행 초기에 메모리 적재 ```java class Singleton { // 싱글톤 클래스 객체를 담을 인스턴스 변수 private static final Singleton INSTANCE = new Singleton(); // 생성자를 private로 선언 (외부에서 new 연산자 X) private Singleton() {} public static Singleton getInstance() { return INSTANCE; } } ``` - 장점 - `멀티 쓰레드 환경`에서도 안전 : 인스턴스가 `static final` 변수 - 단점 - 메모리 낭비 : 인스턴스를 사용하지 않더라도 메모리에 적재 - 예외 처리 불가 : 애플리케이션의 **시작 시점**에 싱글톤 인스턴스 생성에 실패한 경우 ### (2) Static block Initialization - `static block`을 이용해 예외를 잡는 방법 - static block : 클래스가 로딩되고 클래스 변수가 준비된 후 자동으로 실행되는 블록을 말합니다. - 싱글톤 인스턴스는 클래스가 로딩 되는 시점에 생성 ```java class Singleton { // 싱글톤 클래스 객체를 담을 인스턴스 변수 private static Singleton instance; // final X // 생성자를 private로 선언 (외부에서 new 사용 X) private Singleton() {} // static 블록을 이용해 예외 처리 static { try { instance = new Singleton(); } catch (Exception e) { throw new RuntimeException(\"싱글톤 객체 생성 오류\"); } } public static Singleton getInstance() { return instance; } } ``` - 장점 - 예외 처리 가능 : static block - 단점 - (이론상) 메모리 낭비 : 클래스 로딩과 동시에 객체가 생성되기 때문에 초기화 시점과 실제 사용 시점이 맞지 않으면 메모리 낭비 이슈 존재 ### (3) Lazy Initialization - 객체 생성에 대한 관리를 내부적으로 처리하는 방식 - 외부에서 `getInstance()`를 호출 했을 때, 초기화 진행 - 인스턴스 변수의 null 유무에 따라 초기화 하거나 이미 만들어진 인스턴스를 반환하도록 설계 ```java class Singleton { // 싱글톤 클래스 객체를 담을 인스턴스 변수 private static Singleton instance; // 생성자를 private로 선언 (외부에서 new 연산자 X) private Singleton() {} // 외부에서 정적 메서드를 호출하면 그제서야 초기화 진행 (lazy) public static Singleton getInstance() { if (instance == null) { instance = new Singleton(); // 오직 1개의 객체만 생성 } return instance; } } ``` - 장점 - 초기화 지연 : 위의 자원낭비(메모리 낭비)의 한계점을 극복 - 단점 - `Thread Safe` 하지 않음 : 멀티쓰레드 환경에서 싱글톤을 지킬 수 없음 1. `스레드 A`, `스레드 B`가 존재한다고 가정 2. `스레드 A`가 If문을 평가하고 인스턴스 생성 코드로 진입 (instance가 null) 3. `쓰레드 A`가 인스턴스를 생성하기 전에 `스레드 B`가 If문을 평가하게 된다면? 4. `스레드 B`가 If문을 평가하는 시점에도 instanc가 null이기 때문에 인스턴스 생성 코드로 진입 5. 결과적으로 스레드 A와 B가 인스턴스 초기화 코드를 두번 실행 (원자성 결여) - Test Code ```java import static org.junit.jupiter.api.Assertions.*; import org.junit.jupiter.api.Test; class SingletonTest { @Test void multi_thread() throws InterruptedException { // 여러 스레드를 만들어서 동시에 Singleton.getInstance() 호출 Runnable task = () -> { Singleton instance = Singleton.getInstance(); System.out.println(\"Thread: \" + Thread.currentThread().getName() + \" - Instance: \" + instance); // 객체 주소가 동일한지 확인 (모든 스레드에서 동일한 객체를 참조해야 함) assertSame(Singleton.getInstance(), instance); }; // 10개의 스레드 실행 Thread[] threads = new Thread[10]; for (int i = 0; i synchronized 키워드는 멀시 쓰레드 환경에서 각 쓰레드가 순차적으로 접근하도록 합니다. 즉 쓰레드가 해당 메서드를 실행하는 동안 다른쓰레드가 접근하지 못하도록 lock을 걸어서 경쟁상태(race condition)이 발생하지 않도록 합니다. > > > ![multiThread.jpg](https://github.com/user-attachments/assets/f7c18228-0a75-478e-89db-edba11100e71) > ```java class Singleton { private static Singleton instance; private Singleton() {} // synchronized 메서드 public static synchronized Singleton getInstance() { if (instance == null) { instance = new Singleton(); } return instance; } } ``` - 장점 - Thread Safe - 단점 - 동기화 처리작업으로 `Overhead` 발생 ### (5) Double-Checked Locking - 인스턴스를 호출할 때마다 `synchronized` 동기화가 실행되지 않고, 최초 초기화시에만 동기화가 실행되도록 설계 - 인스턴스 필드에 `volatile` 키워드를 붙여주어야 함 ```java class Singleton { private static volatile Singleton instance; // volatile 키워드 적용 private Singleton() {} public static Singleton getInstance() { if (instance == null) { // 메서드에 동기화 거는게 아닌, Singleton 클래스 자체를 동기화 걸어버림 synchronized (Singleton.class) { if(instance == null) { instance = new Singleton(); // 최초 초기화만 동기화 작업이 일어나서 리소스 낭비를 최소화 } } } return instance; // 최초 초기화가 되면 앞으로 생성된 인스턴스만 반환 } } ``` - 장점 - 성능 향상 : 이미 인스턴스가 생성된 경우 동기화 작업이 필요 없음 - 단점 - `Thread Safe` 이슈 : JVM에 따라서 여전히 Thread Safe 하지 않은 경우가 발생하기 때문에 사용을 지양 ### (6) Bill Push Solution(LazyHolder) - 권장되는 두가지 방법 중 하나 - 클래스 안에 내부 클래스(holder)를 두어 클래스가 로드되는 시점을 이용한 방법 - 내부 클래스인 `SingleInstanceHolder`는 `getInstance()` 호출시에 클래스 로드 및 초기화 - 멀티쓰레드 환경에서 안전하고 `Lazy Loading`(나중에 객체 생성)도 가능한 완벽한 싱글톤 기법 - static 메서드에서는 static 멤버만 호출 할 수 있기 때문에 내부 클래스를 static으로 설정 ```java class Singleton { private Singleton() {} // static 내부 클래스를 이용 // Holder로 만들어, 클래스가 메모리에 로드되지 않고 getInstance 메서드가 호출되어야 로드됨 private static class SingleInstanceHolder { private static final Singleton INSTANCE = new Singleton(); } // 해당 메서드 호출시 SingleInstanceHolder 클래스 초기화 public static Singleton getInstance() { return SingleInstanceHolder.INSTANCE; } } ``` - 세부 설명 1. 내부 클래스를 static으로 선언하여, 싱글톤 클래스가 초기화되어도 `SingleInstanceHolder` 내부 클래스는 메모리에 로드되지 않음 2. `getInstnce()` 메서드를 외부에서 호출할 때, `SingleInstanceHolder` 내부 클래스의 `static 멤버를 반환`하게 되는데, 이 때 내부 클래스가 한번 초기화되면서 싱글톤 객체를 최초 생성 및 리턴 3. 마지막으로 `final`을 지정함으로서 재할당 방지 - 한계점 - `Reflection API`, `직렬화/역직렬화`를 이용하면 임의로 싱글톤 파괴할 수 있음 ### (7) Enum 이용 - 권장되는 두가지 방법 중 하나 - `enum` 클래스 : 애초에 멤버를 만들때 private으로 만들고 한번만 초기화하기 때문에 `Thread safe` - `enum`내에서 상수 뿐만아니라 변수나 메서드를 선언해 사용할 수 있기 때문에 이를 활용하여 싱글톤 클래스처럼 응용이 가능 ```java enum SingletonEnum { INSTANCE; private final Client dbClient; SingletonEnum() { dbClient = Database.getClient(); } public static SingletonEnum getInstance() { return INSTANCE; } public Client getClient() { return dbClient; } } ``` - 장점 - `Reflection`을 통한 공격에도 안전 - 단점 - `Enum` 클래스는 `Enum` 클래스 외에는 상속이 불가능 - 멀티톤 클래스로 마이그레이션 해야할 때 처음부터 코드를 다시 짜야함 ### 5. 싱글턴 패턴의 문제점 - 모듈간의 의존성 - 하나의 인스턴스를 여러 개의 모듈에서 참조하는 경우 클래스간 결합도가 높아짐 - 테스트 어려움 : - 생성 방식이 제한적이기 때문에 Mock으로 대체하기 어려움 - 다른 객체들과 자원을 공유하고 있기 때문에, 테스트시 항상 인스턴스 상태 초기화 필요 - 다중 서버 - 다중 서버인 경우 독립적으로 다른 메모리 공간에 있기 때문에 싱글톤 객체의 유일성을 보장받을 수 없음 ### 6. 결론 - 싱글톤 패턴은 **효율적인 자원 관리에** 유용하지만, 위에서 언급한 **문제점**들을 충분히 고려 - **직접 구현**하는 대신, **검증된 프레임워크**나 **라이브러리**를 사용하여 싱글톤을 관리하는 것이 더 안전하고 효율적 - 예를 들어, `Spring Framework`에서는 의존성 주입(DI)을 통해 싱글톤 패턴을 안전하게 관리할 수 있으며, **멀티스레드 환경**과 **분산 시스템**을 고려한 다양한 기능을 제공 ### 6. 참고 - [Java 객체 지향 디자인패턴 - 한빛 미디어](https://product.kyobobook.co.kr/detail/S000001057516) - [헤드 퍼스트 디자인패턴 - 한빛 미디어](https://product.kyobobook.co.kr/detail/S000001810483) - [싱글톤Singleton-패턴-꼼꼼하게-알아보자](https://inpa.tistory.com/entry/GOF-%F0%9F%92%A0-%EC%8B%B1%EA%B8%80%ED%86%A4Singleton-%ED%8C%A8%ED%84%B4-%EA%BC%BC%EA%BC%BC%ED%95%98%EA%B2%8C-%EC%95%8C%EC%95%84%EB%B3%B4%EC%9E%90) - [GoF 디자인 패턴: 싱글톤 패턴](https://www.youtube.com/watch?v=OwOEGhAo3pI&list=PLfI752FpVCS_v_sc8Q6V9QQN7GhoyktKD) ",
    "url": "/Design_Pattern/dp_singleton_pattern.html",
    
    "relUrl": "/Design_Pattern/dp_singleton_pattern.html"
  },"52": {
    "doc": "전략패턴(Strategy Pattern) 개요",
    "title": "전략패턴(Strategy Pattern) 개요",
    "content": "## 전략패턴(Strategy Pattern) 개요 ### 전략 패턴이란? > 전략 패턴은 실행 중, 즉 런타임에 원하는 알고리즘 전략을 선택하여 동적으로 동작을 변경할 수 있도록 하는 행위 디자인 패턴입니다. > 여기서 ‘**전략**’ 이란, **특정 목표를 달성하기 위한 행동 계획**을 의미합니다. 즉, 어떤 일을 수행하기 위한 여러 알고리즘이 존재할 때, 전략 패턴을 통해 필요에 따라 손쉽게 알고리즘 교체할 수 있습니다. ### 전략패턴 구조 ![strategy.png](https://github.com/user-attachments/assets/d2f7f956-d894-4017-b7b1-49eb07903084) - 전략 알고리즘 구현체 : 알고리즘, 행위, 동작을 정의한 구현체 - 전략 인터페이스 : 모든 전략 구현체에 대한 공용 인터페이스 - 컨텍스트 : 날고리즘을 실행해야할 때마다 해당 알고리즘과 연결된 전략 객체의 메서드를 호출 - 클라이언트 : 특정 전략 객체를 컨텍스트에 전달함으로써 전략을 등록하거나 변경하여 전략 알고리즘을 실행한 결과를 얻음 ### GoF의 디자인 패턴 책에서는 전략패턴 1. 동일 계열의 알고리즘 군을 정의하고 → 전략 알고리즘 구현체로 정의 2. 각각의 알고리즘을 캡슐화하여 → 인터페이스로 추상화 (추상화된 알고리즘) 3. 이들을 상호 교환이 가능하게 만든다. → 합성(composition)으로 구현 4. 알고리즘을 사용하는 컨텍스트와 상관없이 독립적으로 → 컨텍스트 객체를 수정하지 않고 5. 알고리즘을 변경할 수 있게 한다. → 새로운 전략 객체를 추가하여 메소드 동작을 변경할 수 있다. --- ## 전략 패턴 특징 ### 전략 패턴 사용 시기 - 전략 알고리즘의 여러 버전 또는 변형이 필요할때 클래스화를 통해 관리 - 알고리즘의 동작이 런타임에 실시간으로 교체되어야할 ### 전략 패턴 주의점 - 알고리즘(전략 구현체)이 많아 질수록 관리해야할 객체의 수가 늘어난다는 단점 - 알고리즘이 많지 않고 자주 변경되지 않는다면, 전략패턱은 프로그램의 복잡도만 높일 수 있음 - 개발자는 적절한 전략을 선택하기 위해 각 전략 간의 차이점을 파악해야 함 --- ## 간단한 전략 패턴 예제 > 사람은 인사를 하는 프로그램 작성 > > - 다양한 방식으로 인사할 수 있어야한다. > - 인사의 종류는 다양하다. > - 예를 들어 정중한 인사와 캐주얼한 인사가 있다. > - 유행에 따라 새로운 인사법이 추가 될 수 있다. ![strategy_sample.png](https://github.com/user-attachments/assets/ca98bcf8-0f68-4d8b-b840-014d33e17030) - **Person 클래스**는 인사 행동을 수행할 수 있는 컨텍스트 역할을 하며, - **GreetingStrategy** 인터페이스를 통해 다양한 인사 방법(전략)을 캡슐화하고, - **FormalGreeting**과 **CasualGreeting** 같은 구체적 전략 클래스를 만들어, - 필요에 따라 인사 방식을 동적으로 교체할 수 있도록 구현할 수 있습니다. --- ## 실무에서 찾아보는 Strategy 패턴 ### Java - Collections의 sort() 메서드 - **컨텍스트(Context):** - `Collections.sort()`는 정렬 알고리즘을 내부적으로 실행하는 **컨텍스트** - 이 메서드는 정렬 방식을 직접 구현하는 대신, 외부에서 전달받은 `Comparator` 객체에 의존하여 정렬 기준을 결정 - **전략(Strategy):** - `Comparator` 인터페이스는 두 객체를 비교하는 `compare()` 메서드를 정의 - 이 메서드의 구현이 **구체적인 전략(Concrete Strategy)** 역할을 합니다. - **동적 교체:** - 실행 중에 서로 다른 `Comparator` 구현체를 전달함으로써 정렬 기준(전략)을 쉽게 변경 가능 ```java public class StrategyInJava { public static void main(String[] args) { List numbers = new ArrayList(); numbers.add(2); numbers.add(1); numbers.add(3); numbers.add(5); numbers.add(4); Collections.sort(numbers, new IntegerComparator()); System.out.println(numbers); } } class IntegerComparator implements Comparator { public IntegerComparator() { } @Override public int compare(Integer o1, Integer o2) { return o1 - o2; } } ``` ",
    "url": "/Design_Pattern/dp_strategy_pattern.html",
    
    "relUrl": "/Design_Pattern/dp_strategy_pattern.html"
  },"53": {
    "doc": "디자인패턴",
    "title": "디자인패턴",
    "content": "# 디자인패턴 - 싱글톤 패턴 - 팩토리 패턴 - 전략 패턴 - 옵저버 패턴 - 프록시 패턴 & 프록시 서버 - 이터레이터 패턴 - 노출모듈 패턴 - MVC 패턴 - MVP 패턴 - MVVM 패턴 ",
    "url": "/Design_Pattern/readme_DP.html",
    
    "relUrl": "/Design_Pattern/readme_DP.html"
  },"54": {
    "doc": "쿠키 &amp; 세션",
    "title": "쿠키 &amp; 세션",
    "content": "# 쿠키 & 세션 ## 쿠키와 세션을 사용하는 이유? HTTP 프로토콜의 특징이자 약점을 보완하기 위해서 사용한다. ### HTTP 프로토콜의 특징 1. Connectionless 프로토콜 (비연결 지향) 클라이언트가 서버에 요청(Request)을 했을 때, 그 요청에 맞는 응답(Response)을 보낸 후 연결을 끊는 처리방식이다. * HTTP 1.1 버전에서 커넥션을 계속 유지하고, 요청(Request)에 재활용하는 기능이 추가되었다. (HTTP Header)에 keep-alive 옵션을 주어 커넥션을 재활용하게 한다. HTTP 1.1 버전에선 디폴트(default) 옵션이다. * HTTP가 TCP위에서 구현되었기 때문에(TCP : 연결 지향, UDP : 비연결 지향) 연결 지향적이라고 할 수 있다는 얘기가 있어 논란이 있지만, 아직까진 네트워크 관점에서 keep-alive는 옵션으로 두고, 서버 측에서 비연결 지향적인 특성으로 커넥션 관리에 대한 비용을 줄이는 것이 명확한 장점으로 보기 때문에 비연결 지향으로 알아두었다. 2. Stateless 프로토콜   커넥션을 끊는 순간 클라이언트와 서버의 통신이 끝나며 상태 정보는 유지하지 않는 특성이 있다. * 클라이언트와 첫 번째 통신에서 데이터를 주고받았다 해도, 두 번째 통신에서 이전 데이터를 유지하지 않는다. * 하지만, 실제로는 데이터 유지가 필요한 경우가 많다. ## 쿠키(Cookie) HTTP의 일종으로 사용자가 어떠한 웹 사이트를 방문할 경우, 그 사이트가 사용하고 있는 서버에서 사용자의 컴퓨터에 저장하는 작은 기록 정보 파일이다. HTTP에서 클라이언트의 상태 정보를 클라이언트의 PC에 저장하였다가 필요시 정보를 참조하거나 재사용할 수 있다. ### Cookie 유형 | 쿠키 종류| 특징 |---|---|Session Cookie|일반적으로 만료시간(Expire Date)를 설정하고 메모리에만 저장되며, 브라우저 종료 시 쿠키를 삭제|Persistent Cookie|장기간 유지되는 쿠키이다. 파일로 저장되어 브라우저 종료와 관계없이 사용할 수 있다.|Secure Cookie| HTTPS 프로토콜에서만 사용하며, 쿠키 정보가 암호화되어 전송된다.|Third-Party Cookie| 방문한 도메인과 다른 도메인의 쿠키이다. 일반적으로 광고 배너 등을 관리할 때 유입 경로를 추적하기 위해 사용한다.| ### 쿠키 특징 1. 이름, 값, 만료일(저장기간), 경로 정보로 구성되어 있다. 2. 클라이언트에 총 300개의 쿠키를 저장할 수 있다. 3. 하나의 도메인 당 20개의 쿠키를 가질 수 있다. 4. 하나의 쿠키는 4KB(=4096byte)까지 저장 가능하다. ### 쿠키의 동작 순서 1. 클라이언트가 페이지를 요청한다. (사용자가 웹사이트에 접근) 2. 웹 서버는 쿠키를 생성한다. 3. 생성한 쿠키에 정보를 담아 HTTP 화면을 돌려줄 때, 같이 클라이언트에게 돌려준다. 4. 넘겨받은 쿠키는 클라이언트가 가지고 있다가(로컬 PC에 저장) 다시 서버에 요청할 때 요청과 함께 쿠키를 전송한다. 5. 동일 사이트 재방문 시 클라이언트의 PC에 해당 쿠키가 있는 경우, 요청 페이지와 함께 쿠키를 전송한다. * 사용 예시 1. 방문 사이트에서 로그인 시, \"아이디와 비밀번호를 저장하시겠습니까?\" 2. 팝업창을 통해 \"오늘 이 창을 다시 보지 않기\" 체크 ## 세션(Session) 일정 시간 동안 같은 사용자(브라우저)로부터 들어오는 일련의 요구를 하나의 상태로 보고, 그 상태를 유지시키는 기술이다. 여기서 일정 시간은 방문자가 웹 브라우저를 통해 웹 서버에 접속한 시점부터 웹 브라우저를 종료하여 연결을 끝내는 시점을 말한다. 즉, 방문자가 웹 서버에 접속해 있는 상태를 하나의 단위로 보고 그것을 세션이라고 한다. ### 세션 특징 웹 서버에 웹 컨테이너의 상태를 유지하기 위한 정보를 저장한다. 웹 서버의 저장되는 쿠키(=세션 쿠키) 브라우저를 닫거나, 서버에서 세션을 삭제했을 때만 삭제가 되므로, 쿠키보다 비교적 보안이 좋다. 저장 데이터에 제한이 없다. (서버 용량이 허용하는 한에서) 각 클라이언트에 고유 Session ID를 부여한다. Session ID로 클라이언트를 구분해 각 요구에 맞는 서비스를 제공 ### 세션의 동작 순서 1. 클라이언트가 페이지에 요청한다. 2. 서버는 접근한 클라이언트의 Request-Header 필드인 Cookie를 확인하여, 클라이언트가 해당 session-id를 보냈는지 확인한다. 3. session-id가 존재하지 않는다면 서버는 session-id를 생성해 클라이언트에게 넘겨준다. 4. 클라이언트는 서버로부터 받은 session-id를 쿠키에 저장한다. 5. 클라이언트는 서버에 요청시 이 쿠키의 session-id 값을 같이 서버에 전달한다. 6. 서버는 전달받은 session-id로 session에 있는 클라이언트 정보를 가지고 요청을 처리 후 응답한다. * 사용 예시 * 화면을 이동해도 로그인이 풀리지 않고 로그아웃하기 전까지 유지 ## 쿠키와 세션의 차이 1. 저장 위치 * 쿠키: 클라이언트(브라우저) * 세션: 서버 2. 보안성 * 쿠키: 클라이언트에 저장되어 있어 상대적으로 취약 * 세션: 서버에서 관리되어 보안성이 높음 3. 라이프사이클 * 쿠키: 설정된 만료 기간까지 유지 * 세션: 브라우저 종료시 삭제 4. 속도 * 쿠키: 클라이언트에 저장되어 있어 빠름 * 세션: 서버의 처리가 필요해 상대적으로 느림 보통 쿠키와 세션의 차이에 대해서 저장 위치와 보안에 대해서는 잘 알고 있지만, 사실 가장 중요한 것은 라이프사이클이다. ## 라이프사이클 비교 | 단계 | 쿠키(Cookie) | 세션(Session) |------|--------------|---------------| 생성 시점 | - Set-Cookie 헤더로 생성- JavaScript로 직접 생성 | - 최초 요청 시 세션 ID 생성- 주로 로그인 시점 | 유지 기간 | - Session Cookie: 브라우저 종료까지- Persistent Cookie: 만료 시간까지 | - 브라우저 종료까지- 서버 설정 타임아웃까지 | 소멸 조건 | - 만료 시간 도달- 브라우저 쿠키 삭제- 브라우저 종료 | - 브라우저 종료- 세션 타임아웃- 서버 재시작- 명시적 로그아웃 | ## 주요 특성 비교 | 특성 | 쿠키(Cookie) | 세션(Session) |------|--------------|---------------| 지속성 | 명시적 만료 시간 설정 가능 | 브라우저 컨텍스트에 종속 | 갱신 방식 | 만료 시 자동 삭제 | 활동마다 타임아웃 리셋 가능 | 제어권 | 클라이언트 제어 | 서버 제어 | ## 일반적인 사용 사례 | 용도 | 쿠키(Cookie) | 세션(Session) |------|--------------|---------------| 로그인 관련 | 자동 로그인, 아이디 저장 | 로그인 인증 정보 | 쇼핑몰 | 장바구니(비로그인) | 장바구니(로그인) | 사용자 설정 | 테마, 언어 설정 | 사용자 권한 정보 | 임시 데이터 | 설문 진행 상태 | 결제 진행 정보 | ## 보안 고려사항 | 항목 | 쿠키(Cookie) | 세션(Session) |------|--------------|---------------| 데이터 노출 | 클라이언트에서 확인 가능 | 서버에서만 확인 가능 | 변조 위험 | 있음 | 상대적으로 낮음 | 적합한 데이터 | 민감하지 않은 정보 | 중요한 사용자 정보 | ",
    "url": "/Network/cookie_and_session.html",
    
    "relUrl": "/Network/cookie_and_session.html"
  },"55": {
    "doc": "네트워크의 기초",
    "title": "네트워크의 기초",
    "content": "# 네트워크의 기초 ### 네트워크 ![](/Network/img/network_basic_1.png) 컴퓨터 등의 장치들이 통신 기술을 이용하여 구축하는 연결망 노드(node)와 링크(link)가 서로 연결되어 있으며 리소스를 공유하는 집합 *노드: 서버, 라우터, 스위치 등 네트워크 장치 ## 처리량과 지연시간 ### 좋은 네트워크 많은 처리량을 처리할 수 있으며 지연 시간이 짧고 장애 빈도가 적으며 좋은 보안을 갖춘 네트워크 ### 처리량 링크를 통해 전달되는 단위 시간당 데이터 양, 일반적으로 얼만큼의 트래픽을 처리했는지를 의미 단위는 bps(bits per second, 초당 전송 또는 수신되는 비트 수)를 사용 처리량은 사용자들이 많이 접속할 때마다 커지는 트래픽, 네트워크 장치 간의 대역폭(주어진 시간 동안 네트워크 연결을 통해 흐를 수 있는 최대 비트 수), 네트워크 중간에 발생하는 에러, 장치의 하드웨어 스펙에 영향을 받습니다. ![](/Network/img/network_basic_2.png) ### 지연 시간 지연 시간(latency)이란 요청이 처리되는 시간, 어떤 메시지가 두 장치 사이를 왕복하는 데 걸린 시간을 의미 매체 타입(유선, 무선), 패킷 크기, 라우터의 패킷처리 시간에 영향을 받음 ![](/Network/img/network_basic_3.png) ## 네트워크 토폴로지와 병목 현상 ### 네트워크 토폴로지 노도와 링크가 어떻게 배치되어 있는지에 대한 방식이자 연결 형태를 의미 - 트리 토폴로지 ![](/Network/img/network_basic_4.png) 계층형 토폴로지라고 하며 트리 형태로 배치한 네트워크 구성 장점: 노드의 추가, 삭제가 쉽습니다. 단점: 특정 노드에 트래픽이 집중될 때 하위 노드에 영향을 끼칠 수 있습니다. - 버스 토폴로지 ![](/Network/img/network_basic_5.png) 중앙 통신 회선 하나에 여러 개의 노드가 연결되어 공유하는 네트워크 구성 근거리 통신망 (LAN)에서 사용 장점: 설치 비용이 적고 신뢰성이 우수하며 중앙 통신 회선에 노드 추가/삭제가 쉬움 단점: 스푸핑이 가능함 *스푸핑: LAN 상에서 송신부의 패킷을 송신과 관련 없는 다른 호스트에 가지 않도록 하는 스위칭 기능을 마비시키거나 속여서 특정 노드에 해당 패킷이 오도록 처리하는 것 ![](/Network/img/network_basic_6.png) - 스타 토폴로지 ![](/Network/img/network_basic_7.png) 중앙에 있는 노드에 모두 연결된 네트워크 구성 장점: 노드 추가 및 에러를 탐지하기 쉽고 패킷의 충돌 발생 가능성이 적습니다. 특정 노드에 장애가 발생해도 쉽게 에러를 발견할 수 있고, 장애 노드가 중앙 노드가 아닐 경우 다른 노드에 끼치는 영향이 적습니다. 단점: 중앙 노드에 장애 발생시 네트워크 전체가 마비되며 설치 비용이 고가입니다. - 링형 토폴로지 ![](/Network/img/network_basic_8.png) 각각의 노드가 양 옆의 두 노드와 연결하여 전체적으로 고리처럼 하나의 연속된 길을 통해 통신을 하는 망 구성 방식, 데이터는 노드에서 노드로 이동하게 되며, 각각의 노드는 고리 모양의 길을 통해 패킷 처리 장점: 노드 수가 증가되어도 네트워크상의 손실이 거의 없고 충돌이 발생되는 가능성이 적고 노드의 고장 발견을 쉽게 할 수 있습니다. 단점: 네트워크 구성 변경이 어렵고 회선에 장애가 발생하면 전체 네트워크에 영향을 끼칩니다. - 메시 토폴로지 ![](/Network/img/network_basic_9.png) 망형 토폴로지라고도 하며 그물망처럼 연결되어 있는 구조 장점: 한 단말 장치에 장애가 발생해도 여러 개의 경로가 존재하므로 네트워크를 계속 사용 가능하고 트래픽 분산 처리도 가능합니다. 단점: 노드의 추가가 어렵고 구축 비용과 운용 비용이 고가입니다. ### 병목 현상 > 토폴로지가 중요한 이유는 병목 현상을 찾을 때, 중요한 기준점이 되기 때문입니다. 병목(bottleneck)현상은 전체 시스템의 성능이나 용량이 하나의 구성 요소로 인해 제한을 받는 현상을 말합니다. 예시: 서비스에서 이벤트를 열었을 때 트래픽이 많이 생기고 그 트래픽을 잘 관리하지 못하면 병목 현상이 생겨 사용자는 웹 사이트로 들어가지 못합니다. - 회선 추가 전 ![](/Network/img/network_basic_10.png) 가정: 위 그림 같은 구조의 서비스를 만들었을 때, 병목 현상이 발생하여 사용자가 서비스를 이용하면 지연 시간이 길게 발생합니다. 관리자가 지연 시간을 짧게 줄이기 위해 대역폭을 크게 설정했음에도 성능 개선이 이루어지지 않았습니다. - 회선 추가 후 ![](/Network/img/network_basic_11.png) 해결: 관리자는 네트워크 토폴리지가 어떻게 되어 있나 확인하고, 서버와 서버 간 그리고 게이트웨이로 이어지는 회선을 추가해서 병목을 해결했습니다. 이처럼 네트워크가 어떤 토폴로지를 갖는지, 또한 어떠한 경로로 이루어져 있는지 알아야 병목 현상을 올바르게 해결 가능합니다. ## 네트워크 분류 > 네트워크는 규모를 기준으로 분류할 수 있습니다. - LAN : 사무실과 개인적으로 소유 가능한 규모 근거리 통신망을 의미하며 같은 건물이나 캠퍼스 같은 좁은 공간에서 운영됩니다. 전송 속도가 빠르고 혼잡하지 않습니다. - MAN : 서울시 등 시 정도의 규모 대도시 지역 네트워크를 나타내며, 도시 같은 넓은 지역에서 운영, 전송 속도는 평균입니다. LAN보다 더 많이 혼잡합니다. - WAN : 세계 규모 국가 또는 대륙 같은 넓은 지역에서 운영합니다. 전송속도는 느리고 MAN보다 혼잡합니다. ## 네트워크 성능 분석 명령어 애플리케이션 코드상에는 전혀 문제가 없는데 사용자가 서비스로부터 데이터를 가져오지 못하는 상황이 발생되기도 하며, 이는 네트워크 병목 현상일 가능성이 있습니다. 이를 해결하기 위해서는 네트워크 관련 테스트와 네트워크 무관 테스트를 진행하여 네트워크가 문제임을 확인 후, 네트워크 성능 분석을 해야 합니다. ### 병목 현상의 주된 원인 - 네트워크 대역폭 - 네트워크 토폴로지 - 서버 CPU, 메모리 사용량 - 비효율적인 네트워크 구성 네트워크 관련 테스트와 네트워크와 무관한 테스트를 통해 ‘네트워크로부터 발생한 문제점’인 것을 확인한 후 네트워크 성능 분석 필요. ### 1. ping ping(Packet INternet Groper)은 네트워크 상태를 확인하려는 대상 노드를 향해 일정 크기의 패킷을 전송하는 명령어입니다. 해당 노드의 패킷 수신 상태와 도달하기까지 시간 등을 알 수 있으며 해당 노드까지 네트워크가 잘 연결되어 있는지 확인할 수 있습니다. ping은 TCP/IP 프로토콜 중에 ICMP 프로토콜을 통해 동작합니다. 네트워크 정책상 ICMP나 traceroute를 차단하는 대상의 경우 ping 테스트 불가합니다. ![](/Network/img/network_basic_12.png) SKT에 ping을 보내는 화면 ### 2. netstat netstat 명령어는 접속되어 있는 서비스들의 네트워크 상태를 표시하는데 사용되며 네트워크 접속, 라우팅 테이블, 네트워크 프로토콜 등 리스트를 보여줍니다. 주로 서비스의 포트가 열려 있는지 확인할 때 사용합니다. ![](/Network/img/network_basic_13.png) ### 3. nslookup DNS에 관련된 내용을 확인하기 위해 사용합니다. 특정 도메인에 매핑된 IP를 확인하기 위해 사용합니다. ![](/Network/img/network_basic_14.png) ### 4. tracert 윈도우에서는 tracert이고 리눅스에서는 traceroute라는 명령어로 실행 됩니다. 목적지 노드까지 네트워크 경로를 확인할 때 사용하는 명령어입니다. 목적지 노드까지 구간들 중 어느 구간에서 응답 시간이 느려지는디 등을 확인할 수 있습니다. ![](/Network/img/network_basic_15.png) ## 네트워크 프로토콜 표준화 > 네트워크 프로토콜이란 다른 장치들끼리 데이터를 주고받기 위해 설정된 공통된 인터페이스입니다. IEEE또는 IETF라는 표준화 단체가 정함. ",
    "url": "/Network/network_basic.html",
    
    "relUrl": "/Network/network_basic.html"
  },"56": {
    "doc": "CORS",
    "title": "CORS",
    "content": "# **CORS** ## 출처(Origin) ![](/Network/img/network_cors_1.png) [토스](https://docs.tosspayments.com/resources/glossary/cors) ### origin = protocol + host + port Origin 헤더는 **HTTP 요청이 시작된 출처**를 나타낸다. 프로토콜, 호스트, 포트가 모두 일치하는 경우 같은 출처라고 한다. --- ## **동일 출처 정책 (Same-origin policy, SOP)** 하나의 출처에서 불러온 문서나 스크립트가 **다른 출처에서 가져온 리소스와 상호 작용할 수 있는 방법을 제한**하는 보안 메커니즘이다. 하지만 웹 생태계가 발전하며 여러 서비스 간 데이터 교환이 중요해졌다. 기본적으로 서로 다른 출처끼리는 리소스를 주고받지 못하기 때문에, 개발자들은 **JSONP** 같은 우회 방법을 사용해야 했다. ### 만약 동일 출처 정책이 없다면? 1. **악의적인 사이트가 사용자의 정보에 접근**할 수 있다. - 쿠키나 세션 정보 같은 인증 정보를 이용해 사용자의 데이터를 탈취할 수 잇다. 2. **민감한 데이터 유출** - 사용자가 은행 사이트에 로그인한 상태에서, 악의적인 웹사이트가 은행의 API를 호출해 사용자의 계좌 정보를 가져갈 수 있다. 3. **CSRF 공격** - 악의적인 사이트가 다른 출처의 웹사이트에 요청을 보내 사용자가 원하지 않는 행동(예: 송금)을 할 수 있다. 따라서 SOP 정책으로 다른 출처의 스크립트가 실행되지 않도록 브라우저에서 사전에 방지한다. --- ## **교차 출처 리소스 공유**(Cross-Origin Resource Sharing, **CORS** ) ✅ SOP의 한계를 극복하기 위해 등장한 것이 **CORS** ✅ CORS는 막는 것이 아니라 **허용**해주는 메커니즘 CORS(Cross-Origin Resource Sharing)는 **웹 브라우저가** 자신의 출처가 아닌 다른 출처에서 리소스를 요청할 때, 해당 요청을 허용할지 결정하는 HTTP 헤더 기반 웹 보안 메커니즘이다. 브라우저의 기본 보안 정책인 동일 출처 정책(Same-Origin Policy)을 완화하기 위해 등장했다. **👉 즉, SOP 정책을 위반해도 CORS 정책에 따르면 다른 출처의 리소스라도 허용한다.** ### **CORS의 필요성** 1. 보안 유지 - 브라우저가 불필요한 데이터 접근은 막고 서버가 허용한 출처에서만 데이터를 공유한다. 2. 웹 서비스 간 유연성을 확보 - SOP를 보완하여 보안을 유지하면서도 데이터 공유가 가능하다 ### **CORS 동작 원리** **단순 요청(Simple Request)** - 다음 조건을 모두 만족하는 요청 1. HTTP 메서드가 `GET`, `POST`, `HEAD` 중 하나 2. 커스텀 헤더를 사용하지 않고, 브라우저가 기본적으로 설정하는 헤더만 포함 3. `XMLHttpRequest`나 `fetch` API를 사용하며 `withCredentials`가 `false`일 때 - 단순 요청의 흐름 ![](/Network/img/network_cors_2.png) 1. **브라우저 → 서버 (요청)** 브라우저는 요청을 보낼 때 **`Origin` 헤더**를 포함한다. ``` GET /api/data HTTP/1.1 Host: server.example.com Origin: https://client.example.com ``` ⇒ `Origin: https://client.example.com` 2. **서버 → 브라우저 (응답)** 서버는 요청을 처리하고, 응답에 **CORS 관련 헤더**를 포함시킨다. ``` HTTP/1.1 200 OK Access-Control-Allow-Origin: https://client.example.com Content-Type: application/json {\"message\": \"success\"} ``` ⇒ `Access-Control-Allow-Origin: https://client.example.com` 1. **브라우저 검증** 브라우저는 서버 응답에 포함된 `Access-Control-Allow-Origin` 값을 확인한다. - 요청의 `Origin`과 `Access-Control-Allow-Origin`이 일치하면 리소스를 사용할 수 있다. - 일치하지 않으면 CORS 에러를 발생 **Preflight Request** - 복잡한 요청은 Preflight 단계를 거친다. - 요청의 흐름 ![](/Network/img/network_cors_3.png) 1. **브라우저 → 서버 (OPTIONS 요청)** 브라우저는 리소스를 요청하기 전에 **OPTIONS 메서드**를 사용하여 서버에 **Preflight** 확인 요청을 보낸다. ``` OPTIONS /api/data HTTP/1.1 Host: server.example.com Origin: https://client.example.com Access-Control-Request-Method: PUT Access-Control-Request-Headers: My-Custom-Header ``` 2. **서버 → 브라우저 (Preflight 응답)** 서버는 OPTIONS 요청에 대해 허용된 조건들을 응답 헤더에 포함하여 반환한다. ``` HTTP/1.1 204 No Content Access-Control-Allow-Origin: https://client.example.com Access-Control-Allow-Methods: PUT, POST, GET Access-Control-Allow-Headers: My-Custom-Header, Authorization Access-Control-Max-Age: 86400 ``` 1. **브라우저 → 서버 (실제 요청)** Preflight 요청을 통과하면, 브라우저는 이제 실제 HTTP 요청을 서버로 보낸다. ``` PUT /api/data HTTP/1.1 Host: server.example.com Origin: https://client.example.com My-Custom-Header: custom-value Content-Type: application/json {\"data\": \"new data\"} ``` 1. **서버 → 브라우저 (응답)** 서버는 요청을 처리하고 응답에 CORS 헤더를 포함시킨다. ``` HTTP/1.1 200 OK Access-Control-Allow-Origin: https://client.example.com Content-Type: application/json {\"message\": \"update success\"} ``` 1. **브라우저 검증** 브라우저는 응답의 `Access-Control-Allow-Origin` 값을 확인하고, 일치하면 리소스를 사용할 수 있다. | 구분 | 단순 요청(Simple) | 프리플라이트 요청(OPTIONS) | --- | --- | --- | HTTP 메서드 | `GET`, `POST`, `HEAD` | `OPTIONS` | 추가 헤더 사용 | X | O | 요청 흐름 | 직접 요청 | Preflight → 실제 요청 | 주요 사용 사례 | 일반적인 API 호출 | `PUT`, `DELETE`, 커스텀 헤더 사용 | ### **CORS 헤더** **요청** | Origin | 요청이 시작된 위치 | --- | --- | Access-Control-Request-Method | 프리플라이트 요청 시, 어떤 HTTP 메서드가 사용될 것인지 서버에 알림 | Access-Control-Request-Headers | 프리플라이트 요청 시, 사용될 HTTP 헤더를 서버에 알림 | **응답** | Access-Control-Allow-Origin | 응답이 허용될 출처 | --- | --- | Access-Control-Allow-Credentials | 자격 증명(쿠키, HTTP 인증 헤더, 클라이언트 SSL 인증서 등)을 요청에 포함할 수 있도록 허용하는 옵션 | Access-Control-Allow-Headers | 허용된 요청 헤더 | Access-Control-Allow-Methods | 허용된 HTTP 메서드 | Access-Control-Expose-Headers | 클라이언트가 접근할 수 있는 응답 헤더를 명시. | Access-Control-Max-Age | Preflight 요청 결과를 캐싱할 시간 | - `Access-Control-Allow-Origin: *` 는 보안상 위험이 있으므로 정확한 출처를 지정하는게 좋다. - `Access-Control-Allow-Credentials: true` 를 사용하면 `Access-Control-Allow-Origin: *` 는 함께 쓸 수 없다 ### CORS 에러 해결 - 서버에서 정확한 헤더 설정. - 프록시 서버 사용. - 개발 중 로컬 환경에서 브라우저 CORS 비활성화. 👉 [Spring에서 CORS 옵션 넣는 방법](https://spring.io/guides/gs/rest-service-cors) 🍎 참고 https://developer.mozilla.org/ko/docs/Glossary/Origin https://developer.mozilla.org/ko/docs/Web/Security/Same-origin_policy https://developer.mozilla.org/ko/docs/Web/HTTP/CORS https://docs.tosspayments.com/resources/glossary/cors [https://pallycon.com/ko/blog/cors의-이해와-올바른-구현을-위한-가이드/](https://pallycon.com/ko/blog/cors%EC%9D%98-%EC%9D%B4%ED%95%B4%EC%99%80-%EC%98%AC%EB%B0%94%EB%A5%B8-%EA%B5%AC%ED%98%84%EC%9D%84-%EC%9C%84%ED%95%9C-%EA%B0%80%EC%9D%B4%EB%93%9C/) [https://velog.io/@nayeon/CORS-개념과-간단한-XSS-CSRF-소개](https://velog.io/@nayeon/CORS-%EA%B0%9C%EB%85%90%EA%B3%BC-%EA%B0%84%EB%8B%A8%ED%95%9C-XSS-CSRF-%EC%86%8C%EA%B0%9C) ",
    "url": "/Network/network_cors.html",
    
    "relUrl": "/Network/network_cors.html"
  },"57": {
    "doc": "Network Device",
    "title": "Network Device",
    "content": "# Network Device - **네트워크 장치** 는 조직 내 장치들 간의 데이터 전송과 자원 공유를 중개하는 역할. - 컴퓨터 네트워킹에 속한 장치들이 서로 통신하고 상호 작용할 수 있도록 하는 물리적 장치(하드웨어). > _컴퓨터 네트워킹이란 서로 데이터를 교환하고 리소스를 공유할 수 있는 상호 연결된 컴퓨팅 장치 를 말하다._ # 기능 - 다양한 장치 간 데이터 송수신 지원 - 장치들이 효율적이고 안전하게 연결 되도록 해줌 - 네트워크에 대한 접근 제어와 위협 방지 - 네트워크의 범위 확장 및 신호 문제 해결 - 변화하는 비즈니스 요구에 적응할 수 있도록 도움 # 주요 네트워크 장치 및 용도 ## 액세스 포인트 (Access Point) - Wi-Fi 네트워크를 생성하여 스마트 폰 및 노트북과 같은 무선 장치가 유선 네트워크에 연결될 수 있도록 하는 장치. 다리, 송수신기 역할을 한다. - 무선 장치들을 물리적 케이블이 없이도 연결할 수 있기때문에, 유연성과 이동성이 향상됨. - 하나의 네트워크에 여러개의 액세스 포인트를 사용하면 더 큰 무선 인프라를 구축할 수 있다. (WLAN) ## 모뎀 (Modem) - 디지털 신호를 아날로그 신호로 변환하여 수신 위치의 모뎀으로 전송하는 데 사용되는 네트워크 장치. 반대로 수신된 아날로그 신호를 디지털 데이터로 변환하는 역할도 함. - 따라서, 변조기 및 복조기(modulator / demodulator)라고도 불리움. - 이 변환된 신호는 케이블 시스템, 전화선 및 기타 통신 매체를 통해 전송될 수 있다. 모뎀은 또한 아날로그 신호를 디지털 신호로 다시 변환하는 데 사용됨. - 모뎀은 일반적으로 인터넷 서비스 제공자(ISP)의 고객이 인터넷에 액세스하는 데 사용된다. ### 종류 - DSL 모뎀 : 일반 전화선을 사용하여 인터넷에 연결하지만 다른 유형보다 속도가 느림. - 케이블 모뎀 : TV 케이블을 통해 데이터를 전송하며 DSL보다 빠른 인터넷 속도를 제공. - 무선 모뎀 : Wi-Fi를 사용하여 인터넷에 연결하며 근처 Wi-Fi 신호를 기반으로 작동. - 셀룰러 모뎀 : Wi-Fi 또는 고정 케이블 없이 셀룰러 네트워크의 모바일 데이터를 사용하여 인터넷에 연결. ## 방화벽(Firewalls) - 컴퓨터나 네트워크와 인터넷 간의 데이터 흐름을 모니터링하고 제어하여,신뢰할 수 있는 내부 네트워크 와 신뢰할 수 없는 외부 네트워크 사이의 장벽 역할. - 신뢰할 수 없는 접근을 차단하는 동시에 신뢰할 수 있는 데이터만 통과시켜, 내부 네트워크를 해커, 바이러스 및 기타 위협으로부터 보호한다. - 특정 유형의 트래픽을 제외하고 모든 트래픽을 허용하는 블랙리스트(거부 목록)를 적용 가능. 보다 제한적인 보안을 위해, 명시된 트래픽 외에는 모두 차단하는 화이트리스트(허용 목록)를 구현 가능. ### 유형 - 패킷 필터링(Packet Filtering) : 네트워크 계층의 체크포인트 역할을 하며, 데이터 패킷을 IP 주소, 패킷 유형, 포트 번호 또는 네트워크 프로토콜에 따라 분석. - 상태 기반 검사(Stateful Inspection) : 네트워크 계층과 전송 계층에서 데이터를 분석하며, 출발지 IP, 목적지 IP, 출발지 포트, 목적지 포트를 검사하다. - 차세대 방화벽(Next-Generation Firewall, NGFW) : 기존 방화벽 기능을 넘어 다양한 보안 기능을 통합한 고급 네트워크 보안 장치. 예를 들어, 심층 패킷 검사, 침입 방지 시스템(IPS), 애플리케이션 가시성 및 제어, 고급 위협 탐지 기능이 포함됨. ## 리피터 (Repeater) - 네트워크에서 신호가 약해지거나 손상되기 전에 신호를 증폭(재생성) 하여 동일 네트워크에서 신호를 더 길게 전송할 수 있도록 한다. > _디지털 신호는 케이블을 따라 이동하면서 점차 약해지며, 이 점진적인 신호 약화를 감쇠율(Attenuation Rate)이라고 한다._ - 어떻게 재생성? 신호가 약해질 시, 비트를 하나씩 복사하여 원래 강도의 신호로 재생성. - 리피터는 오늘날 거의 사용되지 않음. 전원 공급 허브, 스위치, 라우터가 그 역할을 대신함. - 간혹 원격 무선 액세스 포인트의 범위를 확장하는 데 사용되기도 한다. ## 허브 - 여러 컴퓨터와 장치를 함께 연결하는 장치이며, 데이터 전송의 중심점 역할을 한다. - 데이터가 연결된 모든 장치로 전송되며, 모든 장치는 언제든 같은 데이터에 접근할 수 있다. 따라서, 최대 성능을 유지하려면 네트워크에 충분한 용량이 있는지 확인이 필요하다. - 한 장치에만 데이터가 필요한 경우에도 연결된 모든 장치에 데이터를 전송해야하는 점, 트래픽의 우선 순위를 정하는 기능이 없는 점, 데이터에 필터링 이 되지 않는 점 등 때문에 소규모 조직의 네트워크에 적합하다. 그러나 현재는 스위치로 대체되어 거의 사용되지 않는다. - 1계층인 물리계층 에서 작동. ![](/Network/img/network_devices_hub.png) 출처 : https://www.naukri.com/code360/library/hub-network ### 종류 - 액티브 허브 : 신호를 깨끗이 하고, 증폭 및 중계한다. 따라서 리피터의 역할(신호 증폭) 도 한다. 외부 전원이 필요하다. - 패시브 허브: 신호를 네트워크에 전달하지만 깨끗이 하거나 증폭 하는 기능이 없다. 자체 전원 공급 장치가 있어 전원을 필요로 하지 않는다. - 지능형 허브: 네트워크 관리, 모니터링, 진단 기능 이 있다. ## 브리지 (Bridge) - 허브가 여러 장치를 연결하는 역할을 한다면, 브리지는 두 개 이상의 네트워크 세그먼트를 연결하고 세그먼트 간 트래픽을 필터링한다. - 로컬 브리지 는 동일한 물리적 위치나 LAN 내의 네트워크 세그먼트를 연결, 원격 브리지 는 지리적으로 떨어진 네트워크 세그먼트를 연결한다. - 허브와 마찬가지로 현대 네트워크 환경에서는 거의 사용하지 않는다. - 2계층인 데이터 링크 계층 ![](/Network/img/network_devices_bridge.png) 출처 : https://myshubhsang.wordpress.com/2016/10/01/networking-devices-ccna-tutorial-11/ ### 네트워크 세분화 (Network Segmentation) - 네트워크 세분화는 네트워크를 더 작고 독립적인 단위인 여러 세그먼트로 분리하는 방법을 뜻한다. - 각 네트워크 세그먼트에 적합한 보안 제어와 서비스를 제공할 수도 있게된다. - 공격자가 네트워크에 침입하게 되도, 하나의 네트워크 세그먼트에 침입하게 된것이 되어, 공격을 최소화 할 수 있다. 또한 공격 후 복원하는 과정에서도, 보다 효율적으로 가능하다. - 따라서, 네트워크 세그먼트는 네트워크 세분화 의 과정에서 생성된 네트워크를 더 작고 독립적인 단위로 세분화 한 단위로써, 네트워크 세분화 라고 불리우는 접근 방식에서 파생된 용어라고 볼 수 있다. #### 종류 - 물리적 세분화 : 라우터, 스위치, 방화벽 등의 하드웨어 장비를 사용하여 분리하는 것을 뜻한다. 설정 및 유지 관리에 비용이 많이 든다. 더불어, 클라우드 컴퓨팅의 등장으로 사용자가 인터넷을 통해 데이터에 액세스할 수 있게 되면서 물리적 네트워크 경계는 거의 사라졌다. - 논리적 세분화 : 논리적 세분화는 가상 네트워크 세분화 라고 볼수 있다. 소프트웨어를 사용하여 네트워크를 나누기 때문이다. 이러한 세그먼트는 서브넷, 가상 근거리통신망(VLAN), 네트워크 주소 체계를 통해서도 생성할 수 있다. 물리적 세분화와 달리 장비에 구애받지 않기 때문에, 비교적 효율적인 방법이라고 알려져있다. ## 스위치 (Switch) - 네트워크 내의 장치를 연결하고 해당 장치와 데이터 패킷을 주고받는다. 라우터와 달리 스위치는 여러 장치의 네트워크가 아닌 의도된 단일 장치(다른 스위치, 라우터, 사용자 컴퓨터일 수 있음) 로만 데이터를 전송한다. - 데이터 전송 전 오류를 확인할 수 있어, 오류가 있는 패킷은 전달하지 않으며, 올바른 포트로만 선택적으로 전달한다. - 2계층인 데이터 링크 계층 혹은 3계층인 네트워크 계층에서 작동. 2계층에서는 대상 MAC 주소를 참조하고, 3계층에서는 IP 를 참조하는 방식으로 작동된다. ### 종류 - 비관리형 스위치 (Unmanaged Switches): 단순히 LAN 에 더 많은 포트를 생성하여 더 많은 로컬 장치가 인터넷에 액세스할 수 있도록 하는 방식을 사용한다. 장치 MAC 주소를 기반으로 데이터를 주고받는다. - > LAN 은 작은 물리적(지리적) 영역 내에 포함된 네트워크이며, 근거리 통신망 이라고도 불리운다. 대부분 LAN 은 라우터라는 중앙 지점에서 인터넷에 연결된다. 네트워크 장치를 연결하기 위해 거의 보통 이더넷, Wi-Fi 둘 중 하나 혹은 둘 다 사용한다. - 관리형 스위치 (Managed Switches): 훨씬 더 큰 네트워크에 대해 동일한 기능을 수행하며, 네트워크 관리자가 트래픽의 우선순위를 훨씬 더 세부적으로 제어할 수 있도록 한다. 또한 관리자는 가상 LAN(VLAN)을 설정하여 로컬 네트워크를 더 작은 청크로 세분화할 수 있다. - 스마트 스위치 (Smart Switches): 관리형 스위치와 유사한 기능을 제공하지만 설정 및 관리가 더 간단하다. 중소 규모의 네트워크에 적합하다. - 계층 2 스위치 (Layer 2 Switches): OSI 모델의 데이터 링크 계층에서 작동하며 동일 네트워크 세그먼트 내 장치 간 데이터를 전달하다. - PoE 스위치 (PoE Switches): Power over Ethernet 기능을 지원하여 네트워크 장치에 데이터를 전송하는 케이블을 통해 전력을 공급할 수 있다. - 기가비트 스위치 (Gigabit Switches): 기존 이더넷보다 빠른 속도의 기가비트 이더넷을 지원하다. - 랙 마운트 스위치 (Rack-Mounted Switches): 서버 랙에 장착하도록 설계되어 데이터 센터나 대규모 네트워크에서 사용된다. - 데스크톱 스위치 (Desktop Switches): 책상이나 소규모 사무실 환경에서 사용하도록 설계된 소형 스위치입니다. - 모듈형 스위치 (Modular Switches): 모듈식 디자인으로 쉽게 확장하거나 사용자 정의할 수 있다. 대규모 네트워크 및 데이터 센터에 적합하다. - 계층 3 스위치 (Layer 3 Switches): OSI 모델의 네트워크 계층에서 작동하며 서로 다른 네트워크 세그먼트 간 데이터를 라우팅할 수 있다. 더 큰 네트워크에서 사용된다. ## 라우터(Router) - 둘 이상의 패킷 스위칭 네트워크 또는 서브 네트워크 들을 연결하는 장치. > 패킷 스위칭은 데이터를 패킷 단위로 나누어 전송하는 컴퓨터 네트워크 기술이다. 따라서 패킷 스위칭 네트워크는 데이터를 패킷 단위로 나누어 전송하는 네트워크라고 할 수 있다. > 서브 네트워크(서브넷) 은 네트워크 내부의 네트워크를 뜻하며, 네트워크를 보다 효율적으로 만든다. - 데이터 패킷을 의도한 IP 주소로 전달하여 네트워크 간의 트래픽을 관리하고, 여러 장치가 동일한 인터넷 연결을 사용할 수 있도록 하는 등 의 두 가지 주요 기능을 제공한다. - 일반적으로 LAN 과 WAN 을 연결한다. - 스위치와 비슷해 보이지만, 스위치는 네트워크 내부의 장치간의 데이터 패킷을 전달하는 반면, 라우터는 다른 네트워크 간의 데이터를 전달한다. - 주로 3계층인 네트워크 계층, 4계층인 전송 계층 에서 작동한다. ### 라우터와 스위치 ![](/Network/img/network_devices_router_switch.png) 출처 : https://www.cloudflare.com/ko-kr/learning/network-layer/what-is-a-network-switch/ ## 게이트웨이(Gateway) - 서로 다른 네트워크를 연결하여 네트워크 간의 통신을 가능케하는 장치.네트워크 간의 통신을 가능하게 합니다. - 게이트웨이는 데이터를 하나의 프로토콜이나 형식에서 다른 프로토콜이나 형식으로 변환하는 번역기 역할을 한다. 이를 통해 다양한 네트워크 환경 간의 호환성을 보장할 수 있다. 게이트웨이는 서로 다른 네트워크 아키텍처를 넘나들며 통신이 이루어질 수 있도록 하는 데 필수적이다. - 일반적인 게이트웨이 장치의 예로는 로컬 영역 네트워크(LAN)를 광역 네트워크(WAN)나 인터넷에 연결하는 장치가 있다. 주로 5계층인 전송 계층 및 6계층인 세션 계층에서 작동된다. - 라우터와 그 역할이 비슷하지만, OSI 모델의 계층에서 차이가 있으며, 게이트웨이는 서로 다른 프로토콜을 사용하는 네트워크 간의 연결에서 더 유용하다는 의미가 있다. ![](/Network/img/network_devices_gateway.png) 출처 : https://whatismyipaddress.com/gateway ## 브라우터(Brouter) - 브라우터는 브리지 라우터(Bridge Router) 의 줄임말로, 브릿지 와 라우터의 기능을 결합한 장치이다. 브릿지처럼 MAC 주소를 기반으로 데이터를 전달하고, 라우터처럼 IP 주소를 기반으로 데이터 패킷을 전달한다. OSI 모델의 2계층인 데이터 링크 계층 과 3계층인 네트워크 계층 에서 작동한다. - 하지만 현재는 대부분의 네트워크에서 특화된 라우터와 스위치를 사용하기 때문에 브라우터는 더 이상 사용되지 않는다. ## 네트워크 인터페이스 카드(NIC) - 컴퓨터를 네트워크에 연결하는 데 필수적인 구성 요소로써, 컴퓨터와 라우터나 스위치와 같은 네트워크에 연결된 다른 장치 간에 데이터를 송수신할 수 있도록 해준다. NIC는 유선 또는 무선 기술을 사용하여 컴퓨터를 네트워크와 연결할 수 있다. - 메인보드에 통합된 형태로 제공된다. - 1계층인 물리 계층과, 2계층인 데이터 링크 계층 사이의 인터페이스 역할을 한다. 예를 들어 케이블이나 안테나로부터 들어오는 신호를 디지털 신호로 변환하여 이더넷 케이블, 광섬유, 또는 Wi-Fi 전파를 통해 데이터를 송신한다. # 출처 ## 전체 - [Network Devices (Hub, Repeater, Bridge, Switch, Router, Gateways and Brouter)](https://www.geeksforgeeks.org/network-devices-hub-repeater-bridge-switch-router-gateways/) - [Common Types of Network Devices and Their Functions](https://blog.netwrix.com/network-devices-explained) - [CloudFlare 학습 센터](https://www.cloudflare.com/ko-kr/learning/) ## 액세스 포인트 - [LENOVO](https://www.lenovo.com/kr/ko/glossary/what-is-access-point/?orgRef=https%253A%252F%252Fwww.google.com%252F&srsltid=AfmBOorlGURh_jA2phhnUcgCHLZQKfuxAFLSzVYiSqmkht2cAlgrdOtr) ## 컴퓨터 네트워킹 - [AWS ](https://aws.amazon.com/ko/what-is/computer-networking/#:~:text=%EC%BB%B4%ED%93%A8%ED%84%B0%20%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%82%B9%EC%9D%B4%EB%9E%80%20%EC%84%9C%EB%A1%9C%20%EB%8D%B0%EC%9D%B4%ED%84%B0,%ED%86%B5%ED%95%B4%20%EC%A0%95%EB%B3%B4%EB%A5%BC%20%EC%A0%84%EC%86%A1%ED%95%A9%EB%8B%88%EB%8B%A4.) ## 허브 - [LENOVO](https://www.lenovo.com/kr/ko/glossary/what-is-a-hub/?orgRef=https%253A%252F%252Fwww.google.com%252F&srsltid=AfmBOoqVRgofx0xIc_ZvahJpSquqc095_aH5T_FLDsp10oT2iOtIqSle) ## 네트워크 세분화 - [VMware](https://www.vmware.com/topics/network-segmentation) ",
    "url": "/Network/network_devices.html",
    
    "relUrl": "/Network/network_devices.html"
  },"58": {
    "doc": "Domain",
    "title": "Domain",
    "content": "# Domain ## 다양한 맥락에서의 Domain - 도메인은 다양한 맥락에서 다양한 의미로 해석될 수 있다. - 예를 들어, 네트워크 맥락에서 도메인은, 네트워크 리소스를 통해 다양한 유형의 데이터를 공유하는 어떠한 객체들의 집합을 일컫는다. 객체들이라하면, 컴퓨터, 사용자, 데이터베이스, 이메일 서버 등을 이 될 수 있다. - 프로그래밍 맥락에서의 도메인은, 해결하고자 하는 문제의 영역이라는 개념으로 사용된다. (이러한 관점으로 개발하는 방법론을 DDD(Domain-Driven Design)이라고 부른다.) ## Domain or Domain Name? - DNS 에서 사용되는 도메인 네임은 도메인과 직접적인 관련이 있는 용어, 예를 들면 도메인의 이름을 뜻하는 의미를 가진 용어는 아니다. **도메인 네임은 고유의 의미를 가지는 용어** 이다. 하지만 많은 경우, 위의 맥락들에서의 도메인이 아닌 도메인 네임과 같은 의미를 가진 줄임말로써 사용하곤한다. 따라서, DNS 의 맥락에서 도메인은 도메인 네임 과 은 의미를 가진 줄임말로써 사용하는 것이라고 보면 될 듯 하다. # Domain Name - 웹 사이트에 접근하는 데 사용되는 고유하고 기억하기 쉬운 주소. ## 왜 필요할까? - 웹 사이트의 **실제 주소는** **복잡한 숫자형 IP 주소**(e.g. 192.0.2.2) 로 되어있으며, 모든 인터넷 상의 컴퓨터는 이 IP 주소를 통해 서로를 찾고 통신한다. - 하지만, 도메인 네임은 **텍스트 문자열로 구성** 되어있으며 단순한 숫자의 나열이 아닌 웹 사이트를 나타내는 단어를 포함(일반적으로) 하고 있다. 이 도메인 네임은 DNS 라는 것으로 실제 IP 주소로 변환된다. 따라서, 도메인 네임이 있으므로 특정 웹 사이트에 접속하기 위해 복잡한 IP 주소를 알 필요 없이, 웹 사이트에 접속할 수 있게된다. - 예를 들어, 도메인 네임이 없다면 Google 에 접속하기 위해서 Google 의 IP 주소를 알고 있어야 하며, 이를 브라우저에게 알려주어야 한다. 하지만, 실제로 우리는 주소창에 'google.com' 이라는 도메인 네임을 입력하는 것 만으로 Google 에 접속할 수 있다. ## 누가 관리할까? - 도메인 네임 은 모두 도메인 레지스트리(Registry) 에서 관리한다. 도메인 레지스트리는 모든 도메인 네임을 유지 및 관리하는 기관이며, 데이터베이스의 역할을 한다. - 레지스트리에서는 도메인 네임 예약을 등록기관(Registrar)에 위임한다. 따라서 보통 웹 사이트를 만들고 도메인 네임을 등록하려는 사람은, 이러한 등록기관(가비아, AWS, CloudFlare 등) 을 선택하여 도메인 네임 을 등록한다. - 일반적으로 등록기관을 통해 등록이 가능하지만, 레지스트리에서 직접 등록해야하는 도메인 네임도 있다.cl(칠레), .ee(에스토니아), .is(아이슬란드), .tr(터키) (OECD 회원국 4개국)과 .tk(토켈라우) (비 OECD 회원국 1개국)이 있으며, 이 다섯 개의 도메인 네임에 대해서는 등록기관이 아닌, 레지스트리를 통해야만 등록이 가능하다. ## 계층 - 도메인 네임 은 일반적으로 각각 점(.)으로 구분된 2 - 3 부분의 식별자로 나뉜다. - 오른쪽에서 왼쪽으로 갈수록, 식별자는 가장 일반적인 것에서 가장 구체적인 것으로 바뀐다. - 도메인 네임 의 마지막 점, 즉 가장 오른쪽 부분은 최상위 도메인(Top Level Domain, TLD)이다. - TLD의 왼쪽에는 두 번째 레벨 도메인(2nd Level Domain, 2LD)이 있고 2LD의 왼쪽에 무언가가 있으면 세 번째 레벨 도메인(3LD)이라고 한다. - 이를 도식화하면 다음과 같다. ![](/Network/img/network_dns_domain_name_space.png) ### TLD (Top Level Domain) - 도메인 네임에서 마지막 점 뒤에 오는 모든 것을 뜻한다. - 예를 들어, google.com 에서 .com 은 TLD 에 해당한다. - TLD 는 도메인 네임의 목적을 분류하고 전달한다. - 몇 가지 예 : - '.com' 은 영리 사업체용입니다. - '.gov' 는 미국 정부 기관용입니다. - '.uk' 는 영국의 도메인용입니다. - 인터넷에서 사용되는 모든 TLD 는 국제 인터넷 주소 관리 기구(ICANN) 로 부터 관리된다. ### Google 의 예 - 'google.com' 의 경우 : - '.com' 은 TLD (가장 일반적). - 'google' 은 2LD (가장 구체적). - 'google.co.uk'의 경우 : - '.uk' 은 TLD(가장 일반적). - '.co' 은 2LD. - 'google' 은 3LD(가장 구체적). # DNS - 앞서 [Domain Name](#domain-name) 파트에서 얘기했 듯, 도메인 네임은 DNS 를 통해 IP 주소로 변환하는 기능을 가지며, 이러한 과정 및 시스템을 DNS 라 일컫는다. - 일종의 주소책자 라고 생각할 수 있다. 사람은 nytimes.com 또는 espn.com과 같은 도메인 네임 을 통해 온라인으로 정보에 액세스합니다. 웹 브라우저는 인터넷 프로토콜(IP) 주소를 통해 상호작용합니다. DNS는 브라우저가 인터넷 자원을 로드할 수 있도록 도메인 네임 을 IP 주소로 변환합니다. - 사람이 읽을 수 있는 도메인 네임 을 머신이 읽을 수 있는 IP 주소로 변환하는 기능이 있다. ## DNS 동작 방식 ![](/Network/img/network_dns_dns_summary.png) ## DNS 서버 (네임 서버) ![](/Network/img/network_dns_dns_summary_2.png) - DNS 는 다수의 DNS 서버로 구성되어있다. 각 DNS 서버는 상호작용을 통해 사용자가 요청하는 DNS 쿼리를 수신하여, 도메인 네임을 IP 로 변환하고, IP 에 해당하는 웹 사이트를 찾아 사용자가 해당 웹사이트에 접근할 수 있도록 한다. - 이러한 DNS 서버는 4가지로 분류할 수 있다. DNS 리졸버(재귀 확인자), Root 네임 서버, TLD 네임서버, 권한 있는 네임서버 이다. 따라서 DNS 리졸버를 제외한 각 서버는 네임서버라고도 부른다. ### DNS 리졸버(재귀 확인자) - DNS 쿼리의 첫 단계로써, 사용자와 DNS 서버 사이의 중개자 역할을 하며, 각 DNS 서버 사이에서 요청과 응답을 하는 역할을 한다. - DNS 쿼리를 받은 후, 캐시된 IP 주소가 있다면 그것으로 응답한다. 그렇지 않다면, 첫 번째 요청을 Root 네임서버로 보내고 또 다른 요청을 TLD 네임서버로 보낸 후 마지막 요청을 권한 있는 네임서버로 보낸다. 이 과정 중에서 DNS 서버에서 받은 정보를 캐시한다. - 마지막 요청인 권한 있는 네임서버로부터 응답을 받은 후 응답을 클라이언트에 보낸다. - 대부분의 인터넷 사용자는 ISP에서 제공하는 DNS 리졸버를 사용한다. ### Root 네임서버 - Root 네임 서버는 모든 DNS 리졸버에게 알려져 있다. 따라서 Root 네임 서버는 DNS 쿼리 요청을 처리하는 프로세스의 첫번째 단계가 된다. - Root 네임 서버는 DNS 리졸버 의 요청을 받아 도메인 네임의 TLD 에 대한 정보를 DNS 리졸버에 응답한다. ### TLD 네임서버 - 특정 TLD 를 가지고 있는 도메인 네임에 대한 정보를 가지고있다. 예를 들어 TLD 네임서버는 .com 으로 끝나는 모든 웹 사이트의 정보를 갖고 있다. - DNS 리졸버 로부터 (Root 네임 서버의 응답) 요청을 받아, 권한 있는 네임 서버에 대한 정보를 DNS 리졸버에게 응답한다. - 일반적으로 도메인 등록 기관이 관리하는 서버이다. ### 권한 있는 네임서버 - DNS 리졸버 로부터 (TLD 네임서버로부터 응답) 요청 을 받아, 해당 응답을 권한 있는 네임서버로 보낸다. 권한 있는 네임서버는 IP 주소를 확인하는 마지막 단계가 된다. - 권한 있는 네임서버는 도메인 네임에 대한 고유한 정보 를 포함하며 DNS A 레코드에서 찾은 도메인의 IP 주소를 DNS 리졸버에 제공하거나, 도메인에 CNAME 레코드(별칭)가 있는 경우 DNS 리졸버에 별칭 도메인을 제공한다. ## DNS 레코드 - 도메인 이름과 연계된 IP 주소 및 해당 도메인에 대한 요청의 처리 방법에 대한 정보를 제공한다. - 존 파일(Zone File) 이라는 형식으로 저장된다. - 모든 DNS 레코드에는 'TTL'이 있는데, 이는 time-to-live의 약어로 DNS 서버가 해당 레코드를 새로 고치는 빈도를 나타낸다. ### A 레코드 ``` ... example.com. A 192.0.2.23 ... ``` - 주소, 즉 도메인의 IP 주소를 갖고 있다. - 따라서, 한번의 요청으로 IP 주소를 알 수 있다. ### CNAME 레코드 ``` ... example.com. A 192.0.2.23 www.example.com. CNAME example.com ... ``` - 도메인 네임의 별칭을 만드는 데 사용된다. - 예를 들어 위 처럼 존 파일에 CNAME 을 추가했다면, 이제 example.com 은 www.example.com 으로도 접속할 수 있다. - IP 주소가 바뀌어도 유연하게 대응할 수 있다는 장점이 있다. ### NS 레코드 - NS는 네임서버를 의미한다. 이는 앞서 얘기했던 [DNS 서버](#dns-서버-네임-서버) 의 모든 네임서버를 의미하는 것이아닌, [권한 있는 네임서버](#권한-있는-네임서버) 를 위미한다. - NS 레코드로 도메인 네임 대한 네임서버의 권한을 누가 관리하고 있는지 알려주는 레코드이다. 예를들어, 내가 example.co.kr 이라는 도메인을 가비아에서 구입해서 사용하고 있다고 하면, example.co.kr 도메인 네임을 관리하는 네임 서버는 가비아 가 되게 된다. - 즉 NS 레코드는 어떤 도메인 네임에 대한 처리를 다른 권한 있는 네임서버 에게 위임하는 기능을 가진 레코드이다. # 출처 - [CloudFlare 학습센터](https://www.cloudflare.com/ko-kr/learning/dns/what-is-dns/) - [DNS란 무엇입니까?](https://aws.amazon.com/ko/route53/what-is-dns/) - [DNS란?](https://velog.io/@zinukk/9kpyzbdt) - [Techopedia - Domain](https://www.techopedia.com/definition/1326/domain-networking) - [도메인 (네트워크)이란 | 도메인 네임 (인터넷) | DNS 서버 설명](https://www.youtube.com/watch?v=Il9Y-b9Qv0g) - [🌐 DNS 레코드 종류 ★ 완벽 정리](https://inpa.tistory.com/entry/WEB-%F0%9F%8C%90-DNS-%EB%A0%88%EC%BD%94%EB%93%9C-%EC%A2%85%EB%A5%98-%E2%98%85-%EC%95%8C%EA%B8%B0-%EC%89%BD%EA%B2%8C-%EC%A0%95%EB%A6%AC#a_%EB%A0%88%EC%BD%94%EB%93%9C_vs_cname_%EC%9E%A5%EB%8B%A8%EC%A0%90) - [What is DNS? - Introduction to Domain Name System](https://www.youtube.com/watch?v=e2xLV7pCOLI) ",
    "url": "/Network/network_dns.html",
    
    "relUrl": "/Network/network_dns.html"
  },"59": {
    "doc": "HTTP (Hyper Text Transfer Protocol)",
    "title": "HTTP (Hyper Text Transfer Protocol)",
    "content": "# HTTP (Hyper Text Transfer Protocol) 서버/클라이언트 모델을 따라 데이터를 주고 받기 위한 프로토콜 인터넷에서 하이퍼텍스트를 교환하기 위한 통신 규약 **80번 포트 사용** ### 특징 - **무상태성**: 프로토콜에서 클라이언트의 상태를 기억하지 않음. 클라이언트 상태 보관을 위해 **쿠키**, **세션**, **JWT 토큰** 등을 이용하여 유지함. - **비연결성**: 처음 연결을 맺은 후 요청과 한 번의 응답 이후 연결 종료됨. 매 요청마다 다시 연결을 맺음. - **TCP 사용**: HTTP는 **TCP**를 transport 프로토콜로 사용. --- ## Request & Response ![](/Network/img/network_http_1.png) ### 1. **GET** - 서버에서 데이터를 요청하여 가져온다. - 요청한 데이터는 서버에서 읽기만 한다. - 캐싱 가능. --- ### 2. **POST** - 서버에 새로운 데이터를 생성하거나 데이터를 전송. - 요청 본문(Body)에 데이터를 포함, 일반적으로 데이터 생성 작업에 사용. - 캐싱 불가능. --- ### 3. **PUT** - 서버에 있는 데이터를 업데이트. - 기존 리소스를 완전히 대체하거나 생성. - 요청 본문(Body)에 업데이트 데이터를 포함. - **멱등성 보장**: 동일한 요청을 여러 번 보내도 결과 동일. --- ### 4. **PATCH** - 리소스의 일부만 수정. (PUT은 전체 리소스를 대체하지만, PATCH는 부분 수정에 적합.) - **멱등성은 보장하지 않을 수 있음**. - 요청 본문(Body)에 수정할 데이터를 포함. --- ### 5. **DELETE** - 서버에서 데이터를 삭제. - **멱등성 보장**. --- ### 6. **HEAD** - 서버의 리소스 상태를 확인하기 위해 사용. (GET과 동일하지만 응답 본문 없이 헤더만 반환.) - 리소스의 존재 여부, 크기, 변경 여부 등을 확인할 때 유용. --- ### 7. **OPTIONS** - 특정 리소스가 지원하는 HTTP 메서드를 확인. - 서버가 어떤 메서드와 기능을 지원하는지 클라이언트에게 제공. - 주로 **CORS (Cross-Origin Resource Sharing)** 요청에서 사용. --- ### 8. **TRACE** - 서버로부터 클라이언트 요청이 서버에 도달하는 경로를 확인. (요청이 중간 프록시를 거칠 경우 유용.) - 디버깅 목적으로 사용. - 요청을 그대로 반환하며, 이를 통해 경로를 추적. --- # HTTPS (Hyper Text Transfer Protocol Secure) HTTP에 **데이터 암호화**가 추가된 프로토콜 **443번 포트 사용** ### 특징 - 네트워크 상에서 중간에 제3자가 정보를 볼 수 없도록 암호화 지원. - **대칭키 암호화**와 **공개키 암호화**를 조합하여 작동. - **SSL**이나 **TLS** 프로토콜을 통해 세션 데이터를 암호화. ![](/Network/img/network_http_2.png) --- ## SSL 클라이언트와 서버 간의 통신을 공인된 제3자(CA) 업체가 보증해주는 전자화된 문서. ### SSL에서 사용하는 암호화의 종류 1. **암호**: 텍스트를 아무나 읽지 못하도록 인코딩하는 알고리즘. 2. **키**: 암호의 동작을 변경하는 매개변수. 키에 따라서 암호화 결과가 달라지기 때문에 키를 모르면 복호화가 불가능하다. --- ### 1. **대칭키 암호화 방식** - 인코딩과 디코딩에 **같은 키**를 사용하는 알고리즘. - **단점**: 발송자와 수신자가 서로 대화하려면 둘 다 공유키를 가져야 한다는 점. 대칭키를 전달하는 과정에서 키가 유출되면 암호의 내용을 복호화할 수 있어 위험. --- ### 2. **공개키 암호화 방식** - 인코딩과 디코딩에 **다른 키**를 사용하는 알고리즘. - 특징: - A 키로 암호화하면 B 키로 복호화 가능. - B 키로 암호화하면 A 키로 복호화 가능. - **Public Key** (공개키): 누구나 접근 가능하며, 보통 디지털 인증서에 포함. - **Secret Key** (비공개키): 호스트만이 알고 있는 개인 키. - 공개키와 비공개키의 분리를 통해 **메시지 인코딩은 누구나 가능**, **디코딩은 비밀키 소유자에게만 허용**. - **단점**: 공개키 암호화 방식의 알고리즘은 계산이 느려지는 경향이 있다. ![](/Network/img/network_http_3.png) ## 참고 자료 - [생활코딩 - 웹 브라우저와 웹 서버가 대화하는 방식](https://opentutorials.org/course/228/4894) - [MDN - HTTP 메시지](https://developer.mozilla.org/ko/docs/Web/HTTP/Messages) ",
    "url": "/Network/network_http_https.html",
    
    "relUrl": "/Network/network_http_https.html"
  },"60": {
    "doc": "HTTP 메시지",
    "title": "HTTP 메시지",
    "content": "# HTTP 메시지 ## 메시지의 흐름 * 인바운드, 아웃바운드, 업스트림, 다운스트림 ### 인바운드 & 아웃바운드 > \"메시지는 원 서버 방향을 인바운드로 하여 송신된다\" ![alt text](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FePdLDE%2FbtsJFJ1jJWI%2F1LeMVKXT328zWwkh6hHzS1%2Fimg.png) * HTTP는 인바운드와 아웃바운드라는 용어를 트랜잭션 방향으로 표현하기 위해 사용한다. * 인바운드로 이동한다 == 메시지가 원서버 방향으로 향한다. * 아웃바운드로 이동한다 == (모든 처리가 끝난 뒤) 메시지가 사용자 에이전트로 돌아오는 것 ### 다운스트림 & 업스트림 > \" 다운스트림으로 흐르는 메시지 \" ![alt text](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FY48KI%2FbtsJGwmMEF0%2FOv9774EUm9nAk9b8A6RLZ1%2Fimg.png) * 다운스트림과 업스트림이란 용어는 발송자와 수신자에 대한것이다. * HTTP는 강물과 같이 흐른다. 모든 메시지는 요청 또는 응답 메시지냐에 관계없이 다운스트림으로 흐른다. * 메시지의 발송자는 수신자의 업스트림이다. (요청에서는 프락시 1이 프락시 3의 업스트림이지만, 응답에서는 프락시 3이 프락시 1의 업스트림이 될 수도 있다.) ## 메시지의 각 부분 > HTTP 메시지는 단순한, 데이터의 구조화된 블록 각 메시지는 클라이언트로부터 요청이나 서버로부터의 응답 중 하나를 포함한다. ### 메시지의 구성 * 메시지는 시작줄, 헤더블록, 본문 3가지 파트로 구성된다. * 시작줄: 이것이 어떤 메시지인지 서술 * 헤더블록: 메시지의 속성을 담고 있음 ``` Content-type: text/plain # 본문이 무엇인지 말해줌 Content-length: 19 # 본문의 크기: 19byte ``` * 본문: 선택적인 데이터 덩어리 (optional 한 부분) 시작줄 & 헤더블록 → 줄 단위로 분리된 아스키 문자열 (각 줄은 캐리지리턴(ACSII 13) & 개행문자(ACSII 10)로 구성된 두 글자의 줄바꿈 문자열(CRLF)로 끝난다) 본문 → 시작줄, 헤더블록과 달리 본문은 텍스트와 이진데이터(ex) 이미지나 동영상)를 포함할 수 있고, 그냥 비어있을 수도 있음 ### 메시지 문법 모든 HTTP 메시지 * 요청: 웹 서버에 어떤 동작을 요구 * 응답: 요청의 수행 결과를 클라이언트에게 돌려줌 (상태정보와 결과 데이터 등) ⇒ 둘다 기본적 구조가 같음! ### 요청/응답 메시지 형식 * 요청 ``` ``` * 응답 ``` ``` - 메서드: 클라이언트 측에서 서버가 리소스에 대해 수행해주길 바라는 동작 - 요청 URL: 요청 대상이 되는 리소스를 지칭하는 완전한 URL 혹은 URL의 경로 구성요소다 - 버전: 메시지에서 사용 중인 HTTP의 버전이다. - 형식 - HTTP/, - 상태 코드: 요청 중에 무엇이 일어났는지 설명하는 3자리 숫자 - 사유 구절: 숫자로 된 상태 코드의 의미를 사람이 이해할 수 있게 설명해주는 짧은 문구 - 상태 코드 이후부터 줄바꿈 문자열까지가 사유 구절이다. 이는 오로지 사람에게 읽히기 위한 목적으로 존재한다. - 헤더: 이름, 콜론(:), 선택적인 공백, 값, CRLF가 순서대로 나타나는 0개 이상의 헤더들 - 엔터티 본문: 임의의 데이터 블록을 포함한다 ### 시작줄 모든 HTTP 메시지는 시작 줄로 시작한다. 메서드, 상태 코드, 사유 구절, 버전 번호 등이 포함된다. ### 헤더 HTTP 헤더 필드는 요청과 응답 메시지에 추가 정보를 더한다. 기본적으로 이름/값 쌍의 목록이다. ### 엔티티 본문 엔티티 본문은 이미지, 비디오, HTML 문서, 소프트웨어 애플리케이션, 신용카드 트랜잭션, 전자우편 등 여러 종류의 디지털 데이터를 실어 나를 수 있다. ## 메서드 1. GET * GET은 주로 서버에게 리소스를 달라고 요청하기 위해 쓰인다. 2. HEAD * HEAD 메서드는 정확히 GET 처럼 동작하지만, 서버는 응답으로 헤더만을 반환하며 엔티티 본문은 반환되지 않는다. * HEAD를 사용하는 이유 - 리소스를 가져오지 않고도 그에 대해 무엇인가를 알아낼 수 있다. - 응답의 상태코드를 통해 개체의 존재 여부를 확인할 수 있다. - 헤더를 확인하여 리소스가 변경되었는지 검사할 수 있다. 3. PUT * PUT 메서드는 서버가 요청의 본문을 가지고 요청 URL의 이름대로 새 문서를 만들거나 이미 URL이 존재한다면 본문을 사용해서 교체한다. * PUT은 콘텐츠 변경을 하도록 해주므로, 웹 서버가 PUT을 수행하기 전에 사용자 인증을 해야한다. 4. POST * POST 메서드는 서버에 입력 데이터를 전송하기 위해 설계되었다. 5. TRACE * 클라이언트가 어떤 요청을 할 때, 그 요청은 방화벽, 프락시, 게이트웨이 등의 애플리케이션을 통과할 수 있다. 이들한테는 원래의 HTTP 요청을 수정할 수 있는 기회가 있으며, TRACE 메서드는 클라이언트에게 자신의 요청이 서버한테 도달했을 때 어떻게 보이는지 알려준다. * TRACE 메서드는 주로 진단을 위해 사용된다. 요청이 의도한 요청/응답 연쇄를 거쳐가는지 검사할 수 있으며, 프락시나 다른 애플리케이션들이 요청에 어떤 영향을 미치는지 확인해보고자 할 때도 좋은 도구다. 6. OPTIONS * OPTIONS 메서드는 웹 서버에게 여러가지 종류의 지원범위에 대해 물어본다. * 서버에게 특정 리소스에 대해 어떤 메서드가 지원되는지 물어볼 수 있다. 7. DELETE * DELETE 메서드는 서버에게 요청 URL로 지정한 리소스를 삭제할 것을 요청한다. ",
    "url": "/Network/network_http_message.html",
    
    "relUrl": "/Network/network_http_message.html"
  },"61": {
    "doc": "IP의 정의와 역할",
    "title": "IP의 정의와 역할",
    "content": "## 1. IP의 정의와 역할 ### IP(Internet Protocol) - IP는 네트워크 계층에서 데이터를 라우팅하는 기본 프로토콜이다. - 인터넷에 연결되어 있는 모든 장치들을 식별할 수 있도록 각각의 장비에게 부여되는 고유 주소로 데이터 패킷이 출발지에서 목적지까지 올바르게 전달되도록 네트워크에서 호스트를 고유하게 식별한다. ### 역할 - 패킷 주소 지정 - 네트워크 간 데이터 전달 경로 결정 ### 특징 - 사용자가 변경 가능한 논리 주소이다. - 그룹을 의미하는 네트워크 주소와 호스트 주소로 나뉜다. - IP 주소는 32비트로 구성되며, 각 8비트 단위를 **옥텟**이라고 한다. ## 2. IP 주소 체계 | **IPv4** | **IPv6** | --- | --- | --- | **비트 수** | 32비트 | 128비트 | **주소 형식** | 4개의 십진수(0~255) | 8개의 16진수 블록 | **주소 공간** | 약 43억 개 | 3.4×10³⁸개 | **예시** | 192.168.0.1 | 2001:0db8:85a3:0000:0000:8a2e:0370:7334 | ## 3. IP 주소의 구성 ### IP =  네트워크 주소 + 호스트 주소 - **네트워크 주소** - **네트워크를 구분하는 주소**로, 같은 네트워크 안에 있는 장치들은 동일한 네트워크 주소를 가진다. - 네트워크 주소가 같으면 로컬 네트워크로 간주한다. - 주소(서울 서초구 내곡동) - **호스트 주소** - 네트워크 내 **개별 장치를 식별하는 주소**이다. - 하나의 네트워크 안에서 각 호스트를 고유하게 구분한다. - 상세주소 (1-749) ![](/Network/img/network_ip_1.png) **IP 주소: 192.168.64.112** - **네트워크 부분**: `192.168.0` (2진수: `11000000.10101000.0000000`) - **호스트 부분**: `112` (2진수: `01110000`) ### 나눠지는 이유 네트워크가 효율적으로 작동할 수 있도록 라우터는 정보 패킷이 대상으로 하는 호스트의 네트워크만 알고있다. 라우팅 테이블에 저장된 정보를 사용하여 **패킷을 대상 호스트의 네트워크로 전달한 후 호스트로 전달**된다. 이 프로세스가 작동하기 위해 IP는 네트워크가 호스트 두 부분으로 구성된다. ## 4. IP 주소 클래스 네트워크와 호스트 주소를 구분하는 부분은 고정되어 있지 않다. 필요한 호스트 IP 개수에 따라 네트워크의 크기를 다르게 할당할 수 있는 클래스 개념을 도입했다. ### 클래스 기반 주소 체계 (Classful Addressing) - 필요에 따라 네트워크를 크게 혹은 작게 나누어 IP를 할당한다. - 주소의 맨 앞 숫자를 보고 해당 주소가 어떤 클래스에 속했는지 알 수 있다. | 클래스 | 시작 주소 | 끝 주소 | 특성 | | --- | --- | --- | --- | --- | A | 1.0.0.0 | 126.255.255.255 | 대규모 네트워크 | 약 1,600만 개 | B | 128.0.0.0 | 191.255.255.255 | 중규모 네트워크 | 약 6만 5천 개 | C | 192.0.0.0 | 223.255.255.255 | 소규모 네트워크 | 약 250개 | ![](/Network/img/network_ip_2.png) 클래스풀에서는 한 개의 클래스 네트워크가 한 조직에 할당되면 비어 있는 주소라도 IP를 분할해 다른 기관이 사용할 수 없다. 상위 클래스를 할당받은 조직이 이 주소들을 제대로 사용하지 못하면 주소 낭비가 발생할 수 있다. 👉 **클래스리스 주소 체계 (CIDR, Classless Inter-Domain Routing)** 등장 ### 클래스리스 주소 체계 (CIDR, C**lassless Inter-Domain Routing**) - 현대 인터넷의 주소 체계 - 클래스가 존재하지 않는 도메인간 라우팅 기법 - 네트워크 주소와 호스트 주소를 1비트 단위로 세밀하게 구분해 필요한 만큼 할당할 수 있다. - **서브넷 마스크**를 네트워크와 호스트 주소를 나누는 구분자로 사용한다. | **구분** | **클래스풀(Classful)** | **클래스리스(CIDR)** | --- | --- | --- | **유연성** | 고정된 네트워크/호스트 비율 | 가변적인 네트워크 크기 | **주소 낭비 문제** | 발생 | 최소화 | **서브넷 지원** | 제한적 | 서브네팅 필수 요소 | ## 5. 서브넷 마스크 - **서브넷**을 구분하는 방법 중 하나 - 네트워크 주소와 호스트 주소를 구분하는 데 사용되는 32비트 숫자 - 1이 연속된 부분 = 네트워크 주소 - 0이 있는 자리 = 호스트 주소 - 주소에서 서브넷 마스크 값을 가지고 비트 and 연산을 해서 네트워크 아이디가 나와 일치 한다면 우리 네트워크로 유입되는 것으로 확인 ![](/Network/img/network_ip_3.png) ### 네트워크 주소 계산법 - IP 주소: `192.168.64.112` - 서브넷 마스크: `255.255.255.0` - **네트워크 주소**: `192.168.64.0` - **호스트 주소**: `0.0.0.112` ### 프리픽스(prefix) - 서브넷마스크를 표기하는 방법으로 네트워크 ID의 개수를 표기한다. - `192.168.64.112/24` - 서브넷 마스크: `255.255.255.0` - 프리픽스 표기법: `/24` - 처음 24비트가 네트워크 주소를 나타낸다. ## 6. 서브네팅 IP주소를 효율적으로 나누어 사용하기 위해 네트워크-호스트 구분 기준을 사용자가 정해 원래 클래스 단위보다 잘게 쪼개는 것을 서브네팅이라고 한다. **기본 네트워크**: `192.168.64.112/24` - 256개의 호스트 주소 지원. **서브네팅 후** (`/25`로 분할 시) ![](/Network/img/network_ip_4.png) - 총 서브넷 수: 2개 - 서브넷 마스크 = `255.255.255.128` - 서브넷 범위 | **서브넷 번호** | **네트워크 주소** | --- | --- | 서브넷 1 | `192.168.64.0` 192.168.64. **0** 0000000 ~ **0** 1111111 | `192.168.64.1 ~ 192.168.64.126` | 서브넷 2 | `192.168.64.128` 192.168.64. **1** 0000000 ~ **1** 1111111 | `192.168.64.129 ~ 192.168.64.254` | ## 7. IP 주소 할당 방식 ### 고정 IP - 사용자가 수동으로 설정한 변하지 않는 IP 주소 - 항상 동일한 주소를 사용하기 때문에 외부에서 접근이 필요한 경우 적합하다. - 예: 서버, 네트워크 장비(라우터, 프린터) ### 동적 IP - DHCP(Dynamic Host Configuration Protocol) 서버에 의해 자동 할당되는 IP 주소 - 일정 시간이 지나면 IP 주소가 변경될 수 있다. - 사용하지 않는 IP는 재활용하여 낭비를 방지할 수 있다. - 예: 일반 사용자 장치(PC, 스마트폰, 태블릿), 공공 네트워크 | **특징** | **고정 IP** | **동적 IP** | --- | --- | --- | **설정 방식** | 수동으로 설정 | DHCP 서버에 의해 자동 할당 | **변경 여부** | 변하지 않음 | 임대 기간 만료 시 변경 가능 | **유지 비용** | 비교적 높음 | 비용 절감 가능 | **주요 사용처** | 서버, 네트워크 장비 | 사용자 장치, 공공 네트워크 | **관리 용이성** | 관리가 복잡할 수 있음 | 자동화되어 간편 | - **DHCP 서버가 없는 경우의 문제점** - 모든 장치에 수동으로 고정 IP를 설정해야 한다. - 설정 오류 발생 가능성이 높고, 관리가 복잡해진다. 동적 IP의 장점은 **효율성**과 **관리 용이성**에 있으며, 고정 IP는 **안정성**과 **외부 접근성**이 좋다. ### 공인 IP - 전 세계에서 유일한 IP - 내/외부 상관없이 해당 IP에 접속할 수 있다. - CANN에서 국가별로 사용할 IP 대역을 관리한다. 우리나라는 한국인터넷진흥원(KISA)에서 국내 IP 주소들을 관리하고 있다. - 통신업체(ISP, Internet Service Provider)가 IP를 부여받고 사람들은 가입을 통해 통신업체로부터 IP제공받아 인터넷을 사용한다. 이렇게 발급받은 IP가 공인 IP 이다. ### 사설 IP - 하나의 네트워크 안에서 유일한 IP - 내부에서만 접근할 수 있다. - 내부 네트워크에서 사용되는 주소로, 인터넷에 직접 연결되지 않는다. - 공유기까지 → 공인 IP - 공유기에 연결되어 있는 기기 → 사설 IP 할당 | **구분** | **공인 IP** | **사설 IP** | --- | --- | --- | **범위** | 인터넷 전체에서 고유 | 로컬 네트워크 내에서 고유 | **접속 가능성** | 외부 네트워크에서 접근 가능 | 외부에서 직접 접근 불가 | --- 🍎 ### 참고 https://docs.tosspayments.com/resources/glossary/ip https://learn.microsoft.com/ko-kr/troubleshoot/windows-client/networking/tcpip-addressing-and-subnetting https://www.cloudflare.com/ko-kr/learning/network-layer/what-is-a-subnet/ https://www.youtube.com/watch?v=b7Wk-6w5vgg https://www.youtube.com/watch?v=-iMFsDdfoeI [**IT 엔지니어를 위한 네트워크 입문**](https://www.yes24.com/Product/Goods/93997435) ",
    "url": "/Network/network_ip.html",
    
    "relUrl": "/Network/network_ip.html"
  },"62": {
    "doc": "로드 밸런싱이란?",
    "title": "로드 밸런싱이란?",
    "content": "# 로드 밸런싱이란? 애플리케이션을 지원하는 리소스 풀 전체에 네트워크 트래픽을 균등하게 배포하는 방법이다. 최신 애플리케이션은 수백만 명의 사용자를 동시에 처리하고 정확한 텍스트, 비디오, 이미지 및 기타 데이터를 빠르고 안정적으로 반환해야 한다. 이를 위해 데이터가 중복되는 리소스 서버가 많고, **로드 밸런서**는 사용자와 서버 그룹 사이에서 **보이지 않는 촉진자** 역할을 한다. \"한 놈(한 서버)이 일을 다 처리하면 부담스러우니, 여러 놈(여러 서버)한테 일을 나누겠다!\" --- ![](/Network/img/network_load_balancing_1.png) ## 로드 밸런싱의 이점 로드 밸런싱은 애플리케이션 서버와 방문자 또는 클라이언트 간의 인터넷 트래픽을 지시하고 제어한다. 결과적으로 **애플리케이션의 가용성, 확장성, 보안 및 성능이 향상**됨. --- ### 애플리케이션 가용성 서버 장애 또는 유지 관리로 인해 애플리케이션 가동 중지 시간이 늘어 방문자가 애플리케이션을 사용할 수 없을 수 있음. 로드 밸런서는 **서버 문제를 자동으로 감지하고** 클라이언트 트래픽을 사용 가능한 서버로 리디렉션하여 시스템의 **내결함성을 높인다**. 로드 밸런싱을 사용하여 다음 태스크를 더 쉽게 수행할 수 있음: - 애플리케이션 **가동 중지 없이 유지 관리** 또는 업그레이드 실행 - 백업 사이트에 **자동 재해 복구** 제공 - **상태 확인**을 수행하고 가동 중지를 유발할 수 있는 문제 방지 --- ### 애플리케이션 확장성 로드 밸런서를 사용하여 여러 서버 간에 **네트워크 트래픽을 지능적으로 전달**할 수 있다. 로드 밸런싱이 다음을 수행하므로 애플리케이션에서 **수천 개의 클라이언트 요청을 처리**할 수 있다: - 한 서버에서 **트래픽 병목 현상** 방지 - 필요한 경우 **서버를 추가/제거**할 수 있도록 애플리케이션 트래픽을 예측 - 안심하고 조정할 수 있도록 시스템에 **중복성**을 추가 --- ### 애플리케이션 보안 로드 밸런서에는 인터넷 애플리케이션에 또 다른 **보안 계층**을 추가할 수 있는 보안 기능이 내장되어 있다. 이는 공격자가 서버 장애를 일으키는 **수백만 개의 동시 요청**으로 애플리케이션 서버를 가득 채우는 **DDoS 공격**을 처리하는 데 유용한 도구다. 로드 밸런서는 다음을 수행할 수도 있다: - **트래픽 모니터링** 및 악성 콘텐츠 차단 - 공격 트래픽을 여러 백엔드 서버로 **자동으로 리디렉션**하여 영향 최소화 - 추가 보안을 위해 **네트워크 방화벽 그룹**을 통해 트래픽 라우팅 --- ## 로드 밸런싱의 기본 기능 ### Health Check (상태 확인) - 서버들에 대한 주기적인 Health Check를 통해 서버들의 장애 여부를 판단하여, 정상 동작 중인 서버로만 트래픽을 보낸다. - **L3 체크**: *ICMP를 이용하여 서버의 IP 주소가 통신 가능한 상태인지를 확인한다. - **L4 체크**: TCP는 3 Way-Handshaking (전송 - 확인/전송 - 확인)을 기반으로 통신하는데, 이러한 TCP의 특성을 바탕으로 각 포트 상태를 체크하는 방식. - **L7 체크**: 어플리케이션 계층에서 체크를 수행. 실제 웹페이지에 통신을 시도하여 이상 유무를 파악. --- ### Tunneling (터널링) - 데이터 스트림을 인터넷 상에서 가상의 파이프를 통해 전달시키는 기술로, 패킷 내에 터널링할 대상을 캡슐화시켜 목적지까지 전송. - 연결된 상호 간에만 캡슐화된 패킷을 구별해 캡슐화를 해제하게 함. --- ### NAT (Network Address Translation) - 내부 네트워크에서 사용하는 사설 IP 주소와 로드밸런서 외부의 공인 IP 주소 간의 변환 역할. - 로드밸런싱 관점에서는 여러 개의 호스트가 하나의 공인 IP 주소(VLAN or VIP)를 통해 접속하는 것이 주 목적. - **SNAT (Source Network Address Translation)**: 내부에서 외부로 트래픽이 나가는 경우. 내부 사설 IP 주소 -> 외부 공인 IP 주소로 변환. - **DNAT (Destination Network Address Translation)**: 외부에서 내부로 트래픽이 들어오는 경우. 외부 공인 IP 주소 -> 내부 사설 IP 주소로 변환. --- ### DSR (Destination Network Address Translation) - 서버에서 클라이언트로 트래픽이 되돌아가는 경우, 목적지를 클라이언트로 설정한 다음, 네트워크 장비나 로드밸런서를 거치지 않고 바로 클라이언트를 찾아가는 방식. - 이 기능을 통해 로드밸런서의 부하를 줄여줄 수 있음. --- ## 로드 밸런싱 알고리즘 로드 밸런서가 서로 다른 클라이언트 요청 각각에 가장 적합한 서버를 결정하기 위해 따르는 규칙 세트이다. 크게 2가지 범주로 나뉨(정적,동적) ### 정적 로드 밸런싱 - 사전 정의된 규칙을 기반으로 트래픽을 분산, 로드밸런서가 시스템 시작 시점에서 서버 간의 부하를 미리 계산하거나 설정해 둔 기준에 따라 작업을 분배 1. **라운드 로빈**: 순서대로 요청 할당 2. **가중치 라운드 로빈**: 성능에 따라 더 많은 트래픽 할당 3. **IP 해시**: 클라이언트 IP를 해싱해 동일 서버로 연결 ### 동적 로드 밸런싱 - 실시간으로 서버 상태와 부하를 모니터링하고 이를 기반으로 작업을 분산, 각 서버의 현재 성능과 부하 상황에 따라 로드밸런서가 적절한 서버를 선택함 1. **최소 연결**: 활성 연결 수가 적은 서버로 분배 2. **최소 응답 시간**: 가장 빠른 서버에 요청 3. **가중치 최소 연결**: 성능 가중치와 연결 수를 고려 4. **자원 기반**: CPU, 메모리 사용률 등을 분석해 최적의 서버 선택 | 구분 | 정적 로드 밸런싱 | 동적 로드 밸런싱 |--------------------|------------------------|-----------------------------| **기준** | 사전 정의된 규칙 | 실시간 서버 상태와 부하 고려 | **복잡도** | 낮음 | 높음 | **유연성** | 낮음 | 높음 | **오버헤드** | 적음 | 많음 (실시간 모니터링 필요) | **사용 예시** | 단순한 트래픽 분산 | 대규모 시스템, 실시간 부하 변화 | --- ## 로드 밸런싱의 작동 방법 회사는 일반적으로 여러 서버에서 애플리케이션을 실행한다. 이러한 서버 배열을 서버 팜이라고 한다. 애플리케이션에 대한 사용자 요청은 먼저 로드 밸런서로 이동한다. 그런 다음 로드 밸런서는 요청을 처리하는데 가장 적합한 서버 팜의 단일 서버로 각 요청을 라우팅한다. 로드 밸런싱은 레스토랑에서 관리자가 수행하는 작업과 같다. 5명의 웨이터가 있는 식당을 생각해보면, 고객이 웨이처를 선택할 수 있는 경우 한,두명의 웨이터는 업무에 과부하가 걸리고 나머지는 유휴 상태일 수 있다. 이러한 경우가 발생하지 않도록 레스토랑 관리자는 고객에게 가장 적합한 특정 웨이터에게 고객을 할당한다. --- ![](/Network/img/network_load_balancing_2.png) ## L4 로드 밸런서 : 4 계층 - 네트워크 계층(IP, IPX)이나 3 계층 - 전송 계층(TCP, UDP) 의 정보를 바탕으로 로드를 분산. 즉, IP 주소, 포트번호, MAC 주소, 전송 프로토콜 등에 따라 트래픽을 분산하는 것이 가능. ![](/Network/img/network_load_balancing_3.png) ## L7 로드 밸런서 : 7 계층 - 어플리케이션 계층(HTTP, FTP, SMTP 등)에서 로드를 분산하기 때문에, HTTP 헤더, 쿠키 등과 같은 사용자 요청을 기준으로 특정 서버에 트래픽을 분산하는 것이 가능. ![](/Network/img/network_load_balancing_4.png) ![](/Network/img/network_load_balancing_5.png) ",
    "url": "/Network/network_load_balancing.html",
    
    "relUrl": "/Network/network_load_balancing.html"
  },"63": {
    "doc": "OSI 7계층 &amp; TCP/IP 4계층",
    "title": "OSI 7계층 &amp; TCP/IP 4계층",
    "content": "# OSI 7계층 & TCP/IP 4계층 ## 1️⃣ OSI 7계층 ### 개념 ![](/Network/img/network_osi_tcpip_1.png) - **네트워크 통신**이 일어나는 과정을 7단계로 나눔. - ISO(국제 표준화 기구)에서 정의한 네트워크 표준 모델 - 통신이 일어나는 과정을 단계별로 알 수 있고, 7단계 중 특정한 곳에 이상이 생기면 다른 단계와 독립적으로 그 단계만 수정할 수 있음 ⇒ **개발 및 유지보수 용이** ### 1️⃣ 계층 - 물리 계층 (Physical Layer) - 장치 간 전기적 신호를 전달하는 계층. - 데이터 프레임 내부의 각 bit를 한 노드에서 다음 노드로 이동시킴. - 컴퓨터의 `전기적인 신호`를 곡선 형태의 `아날로그 신호`로 변경하는 과정이 필요 - 인코딩, 디코딩 - 데이터 단위 : bit (1과 0) - 프로토콜 : DSL, ISDN 등 - 장비 : 통신 케이블, 허브, 리피터 ![](/Network/img/network_osi_tcpip_2.png) ### 2️⃣ 계층 - 데이터 링크 계층(DataLink Layer) - 데이터를 `frame` 단위로, 한 네트워크 요소에서 이웃 네트워크 요소로 전송하는 계층 - 네트워크 계층에 데이터를 전달하고, 물리 계층에서 발생하는 오류를 탐지하고 수정 - `MAC 주소`라는 물리적 주소를 사용하여 각 기기를 구분 - 양쪽의 데이터 속도를 조절하기 위해, 데이터의 양을 조정하는 `흐름 제어` 기능 제공 - 손상되거나 손실된 프레임을 감지하고 재전송하는 `오류 제어` 기능 제공 - 데이터 단위 : frame - 데이터를 전송할 때 `데이터의 시작과 끝`을 알리기 위해, 프레임의 시작과 끝에 **특수 비트 패턴**을 첨부하여 수행 - 프로토콜 : PPP, Ethernet, Token ring, IEE 802.11(Wifi) 등 - 장비 : 스위치, 브릿지 ![](/Network/img/network_osi_tcpip_3.png) ### 3️⃣ 계층 - 네트워크 계층 (Network Layer) - `IP`로 **도착지**를 찾고, `라우팅`을 통해 도착지까지 **최적의 경로** 탐색하는 계층 - `패킷`을 목적지까지 전달하는 기능을 수행하며, 이 과정에서 `라우팅 알고리즘` 사용 - 라우팅 알고리즘 : 데이터를 전송할 최적의 경로를 찾음 - 전송 계층에게 전달 받은 목적지 주소를 이용해서 패킷을 만들고, 그 목적지의 전송 계층으로 패킷 전달 - 데이터 단위 : datagram, packet - 프로토콜 : **IP**, ICMP, ARP, RIP, BGP 등 ![](/Network/img/network_osi_tcpip_4.png) ### 4️⃣ 계층 - 전송 계층 (Transport Layer) - 상위 계층의 메시지를 하위 계층으로 전송하는 계층 - `포트 번호`를 관리하여 수신된 데이터가 어느 응용프로그램에 전송될지 판독 - 데이터 전송 - 메시지가 클 경우 **나눠서**(Segmentation) 네트워크 계층으로 전달. - 받은 패킷을 **재조립해서** 상위 계층으로 전달 - 전송사용 프로토콜 결정 -TCP or UDP - `TCP` : 3-way handshake로 연결을 설정하고, 연결 종료 시 4-way handshake를 수행 ⇒ **신뢰성** 있는 데이터 전송 보장 - `UDP` : 데이터 전송 시, 패킷의 순서와 신뢰성 고려X ⇒ **빠른** 데이터 전송 - 메시지의 오류를 제어 - 데이터 단위 : segment - 프로토콜 : TCP, UDP, ARP, SCTP 등 - 장비 : GateWay ![](/Network/img/network_osi_tcpip_5.png) ### 5️⃣ 계층 - 세션 계층 (Session Layer) - 통신을 위해, 두 컴퓨터 사이에 `연결`을 형성/유지/종료 - 논리적인 연결을 설정하고 유지하는 기능을 수행 - 송신시 : 데이터 복구를 위한 동기점 생성 - 수신시 : 동기점 확인 - 데이터를 상대방이 보내고 있을 때, 전이중/반이중 통신 결정 - 전이중 : 동시에 보냄 - ex) 전화기 - 반이중 : 동시에 보내지 X - ex) 무전기 - 데이터 단위 : message - 프로토콜 : NetBIOS, TLS 등 ![](/Network/img/network_osi_tcpip_6.png) ### 6️⃣ 계층 - 표현 계층 (Presentation Layer) - 응용 계층으로부터 받은 데이터를 수신측에 **알맞는 코드 및 형식**으로 변환하거나, 그 반대의 과정을 수행. 필요시에 **암호화/복호화** 수행 - 응용 프로그램 ⇔ 네트워크 간 정해진 형식대로 데이터를 변환 - 데이터 단위 : message - 프로토콜 : ASCII, MPEG 등 ![](/Network/img/network_osi_tcpip_7.png) ### 7️⃣ 계층 - 응용 계층 (Application Layer) - 사용자에게 가장 가까운 계층이며 `응용 프로그램`을 통해 사용자와 직접적으로 상호작용 - 응용 서비스를 수행하고 사용자 인터페이스를 제공 - 데이터 단위 : message - 프로토콜 : HTTP, SMTP, FTP, SIP 등 ![](/Network/img/network_osi_tcpip_8.png) ### OSI 7 계층 정리 ![](/Network/img/network_osi_tcpip_10.png) ## 2️⃣ TCP/IP 4계층 ### 개념 - 대부분의 컴퓨터가 기본으로 제공하는 인터넷 표준 프로토콜 - TCP/IP는 데이터 전송 과정을 4계층으로 나누며, OSI 모델과 다르게 각 계층이 서로 **종속적** - ex) 네트워크 계층(IP)에서 잘못된 패킷을 전송하면, 상위 계층(TCP/UDP)에서 이를 바로잡아야 하거나 에러가 전파됨 - ARPANET이 개발된 이후 현재의 인터넷으로 발전해나가는 과정에서 대부분의 데이터 통신이 **TCP와 IP 기반**으로 이루어졌기 때문에, 인터넷 프로토콜 그 자체를 표현하는 용어 ![](/Network/img/network_osi_tcpip_9.png) ### 1️⃣ 계층 - 네트워크 인터페이스(Network Interface) 계층 - OSI 7계층의 물리 계층과 데이터 링크 계층에 해당 - HW 요소와 관련된 모든 것을 지원하는 계층 - 물리적인 주소로 `MAC`을 사용 - 프로토콜 : Ethernet, Token Ring, PPP 등 ### 2️⃣ 계층 - 인터넷 계층(Internet Layer) - OSI 7계층의 네트워크 계층에 해당 - 통신 노드 간의 `IP 패킷을 전송`하는 기능과 `라우팅` 기능을 담당 - 상위 전송 계층에서 받은 데이터에 IP 패킷 헤더를 붙여, IP패킷을 만들어 전송 - 프로토콜 : IP, ICMP, ARP, RARP, OSPF, BGP 등 ### 3️⃣ 계층 - 전송 계층(Transport Layer) - OSI 7계층의 전송 계층에 해당 - 통신 노드 간의 `연결을 제어`하고, 신뢰성 있는 `데이터 전송` - 프로토콜 : TCP, UDP 등 ### 4️⃣ 계층 - 응용 계층(Application Layer) - OSI 7계층의 세션 계층, 표현 계층, 응용 계층에 해당 - TCP/UDP 기반의 `응용 프로그램`을 구현할 때 사용 - 응용프로그램들이 네트워크서비스, 메일서비스, 웹서비스 등을 할 수 있도록 표준적인 `인터페이스`를 제공 - 프로토콜 : SMTP, FTP, HTTP, SSH, DNS 등 ### TCP/IP 4계층 정리 ![](/Network/img/network_osi_tcpip_11.png) ",
    "url": "/Network/network_osi_tcpip.html",
    
    "relUrl": "/Network/network_osi_tcpip.html"
  },"64": {
    "doc": "TCP",
    "title": "TCP",
    "content": "# TCP ### TCP란? TCP(Transmission Control Protocol)는 신뢰성 있는 데이터 전송을 보장하는 **전송 계층**(Transport Layer) 프로토콜입니다. TCP는 인터넷에서 데이터가 정확하게 전달되도록 도와주는 핵심 프로토콜 중 하나입니다. ## TCP의 주요 특징 1. **연결 지향적(Connection-Oriented)** - 데이터를 전송하기 전, 통신을 위한 **3-way Handshake** 과정을 통해 연결을 설정합니다. - 연결이 설정되면 양쪽이 데이터를 주고받을 수 있습니다. 2. **신뢰성 있는 전송** - **데이터 순서 보장**: 데이터 패킷이 올바른 순서대로 도착하도록 관리합니다. - **데이터 손실 복구**: 손실된 패킷이 있으면 재전송합니다. - **중복 방지**: 중복된 패킷은 버립니다. 3. **흐름 제어(Flow Control)** - 수신자가 처리할 수 있는 만큼만 데이터를 전송하도록 조절합니다. 4. **혼잡 제어(Congestion Control)** - 네트워크 혼잡 상태를 감지하고 전송 속도를 조절하여 네트워크 과부하를 방지합니다. ## TCP의 주요 기능과 동작 원리 ### 연결 설정: 3-Way Handshake TCP는 통신을 시작하기 위해 **3단계 연결 설정 절차**를 사용합니다. 1. **SYN**: 클라이언트 → 서버에 연결 요청 (SYN 전송). 2. **SYN-ACK**: 서버 → 클라이언트에게 요청 수락 응답 (SYN과 ACK 전송). 3. **ACK**: 클라이언트 → 서버에 응답 확인 (ACK 전송). > **결과**: 양쪽이 서로 데이터를 주고받을 준비가 완료됩니다. ![](/Network/img/network_tcp_1.png) ### 데이터 전송 - **데이터 패킷 전송**: TCP는 데이터를 **세그먼트(segment)** 단위로 나누어 전송합니다. - **순서 번호(Sequence Number)**: 각 세그먼트에는 **순서 번호**가 부여되어 데이터의 순서를 보장합니다. - **확인 응답(ACK)**: 수신자는 데이터 수신 후, 다음에 기대하는 순서 번호를 ACK로 응답합니다. - **타이머와 재전송**: 송신자는 특정 시간 안에 ACK를 받지 못하면, 해당 세그먼트를 **재전송**합니다. ### 연결 종료: 4-Way Handshake 연결 종료를 위해 TCP는 **4단계 종료 절차**를 사용합니다. 1. **FIN**: 클라이언트 → 서버에 연결 종료 요청 (FIN 전송). 2. **ACK**: 서버 → 클라이언트에게 종료 요청 수락 (ACK 전송). 3. **FIN**: 서버 → 클라이언트에게 종료 요청 (FIN 전송). 4. **ACK**: 클라이언트 → 서버에게 종료 수락 (ACK 전송). > **결과**: 양쪽 모두 데이터 전송이 종료되고 연결이 닫힙니다. ![](/Network/img/network_tcp_2.png) ## TCP의 주요 기능 심화 ### 흐름 제어 (Flow Control) - **수신 윈도우(Window Size)**: 수신자가 처리 가능한 버퍼의 크기를 **수신 윈도우**로 알려줍니다. - **슬라이딩 윈도우(Sliding Window)**: 송신자는 수신 윈도우 크기만큼 데이터를 전송합니다. ### 혼잡 제어 (Congestion Control) 네트워크 혼잡을 방지하기 위해 TCP는 다음과 같은 알고리즘을 사용합니다: 1. **Slow Start**: - 전송 속도를 낮게 시작하고 점진적으로 증가시킵니다. 2. **Congestion Avoidance**: - 혼잡이 감지되면, 전송 속도를 천천히 증가시킵니다. 3. **Fast Retransmit & Fast Recovery**: - 패킷 손실이 감지되면, 손실된 패킷을 재전송하고 혼잡 상태를 빠르게 회복합니다. ## TCP와 UDP의 비교 | **구분** | **TCP** | **UDP** |---------------------|------------------------------------|----------------------------------| **연결 방식** | 연결 지향(Connection-Oriented) | 비연결(Connectionless) | **신뢰성** | 신뢰성 보장 | 신뢰성 없음 | **데이터 순서 보장** | 보장 | 보장하지 않음 | **속도** | 상대적으로 느림 | 빠름 | **사용 사례** | 파일 전송(FTP), 웹 통신(HTTP) 등 | 실시간 스트리밍, VoIP, DNS 등 | ## 6. TCP의 장단점 ### 장점 - 신뢰성 있는 데이터 전송. - 데이터의 순서 보장 및 재전송 기능 제공. - 흐름 제어 및 혼잡 제어를 통한 네트워크 안정성 확보. ### 단점 - 연결 설정 및 종료로 인한 **오버헤드** 발생. - 데이터 전송 속도가 상대적으로 느림. - 실시간 전송에는 부적합. ## TCP의 활용 TCP는 데이터의 신뢰성과 순서를 보장하는 중요한 프로토콜입니다. 이를 통해 인터넷과 같은 불안정한 네트워크에서도 정확하고 안정적으로 데이터를 전송할 수 있습니다. 다만 오버헤드가 크기 때문에 실시간성이 필요한 경우에는 UDP와 같은 다른 프로토콜이 사용됩니다. ## 참고 자료 1. [RFC 793 - TCP 프로토콜 명세](https://tools.ietf.org/html/rfc793) 2. 컴퓨터 네트워킹: 톱다운 접근법, James Kurose & Keith Ross. 3. TCP/IP Illustrated, W. Richard Stevens. ",
    "url": "/Network/network_tcp.html",
    
    "relUrl": "/Network/network_tcp.html"
  },"65": {
    "doc": "UDP (User Datagram Protocol)",
    "title": "UDP (User Datagram Protocol)",
    "content": "# UDP (User Datagram Protocol) ## 1️⃣ 전송 계층 - 송수신자를 연결하는 통신 서비스를 제공하는 계층. - 데이터의 전달을 담당 - 프로토콜 : TCP, UDP ![](/Network/img/network_udp_1.png) ## 2️⃣ UDP란? - 데이터를 `데이터그램` 단위로 처리 - 데이터그램 : UDP 헤더 + 실제 UDP 데이터 - `비연결형` 프로토콜 - 각각의 패킷은 다른 경로로 전송되고, 각 패킷은 독립적인 관계를 가짐 - 송신자는 수신자가 준비되었는지 확인X - **낮은 신뢰성** - 데이터 손실이나 오류가 발생하면 애플리케이션이 처리 - **순서 보장X** - 패킷이 순서대로 도착하지 않을 수 있음 - TCP보다 **빠른 속도** - 연결할 필요X - **패킷 크기 제한** - 한 패킷당 최대 65,535byte의 데이터 전송 가능 - 정리 - 장점 : 속도, 간단한 구현 - 단점 : 낮은 신뢰성, 순서 보장X | **TCP** | **UDP** | --- | --- | --- | **연결 방식** | 연결형 | 비연결형 | **데이터 수신 여부** | O | X | **전송 순서 보장** | O | X | **신뢰성** | 높음 | 낮음 | **속도** | 비교적 느림 | 비교적 빠름 | **패킷 교환 방식** | 가상 회선 | 데이터그램 | **헤더 길이** | 20 byte | 8 byte | **통신 방식** | 1:1 | 1:1, 1:N, N:M | ![](/Network/img/network_udp_2.png) ## 3️⃣ UDP 패킷 - UDP 패킷 : 헤더 + 페이로드(실제 데이터 내용) - UDP 헤더 - 길이 : 8바이트 - 구성 1. 출발지 포트 - 출발지 포트번호 2. 목적지 포트 - 목적지 포트번호 3. 길이 - 응용 계층에서 생성한 UDP `페이로드`와 전송 계층에서 생성한 UDP `헤더`가 더해진 **`데이터그램` 길이** 4. 오류 검사(CheckSum) - 패킷의 무결성을 검사 - 최소한의 오류만을 검출 - 일반적으로 비활성 상태 - IPv6에서는 체크섬이 필수 - 계산 방법 1. UDP 헤더와 페이로드를 연결하여 하나의 데이터를 만든다. 2. 데이터를 16비트 단위로 나눈다. 3. 각 16비트 단위의 값을 모두 더한다. 4. 이렇게 계산된 값의 하위 16비트를 구한다. 5. 최종적으로 Checksum은 하위 16비트 값의 보수(ones' complement)를 취하여 얻는다. ![](/Network/img/network_udp_3.png) ## 4️⃣ UDP 서버 - TCP와 달리 핸드셰이크 과정이 없음 - 연결 자체가 없기 때문에(connect 함수 존재x), 서버/클라이언트 소켓의 구분x - 소켓을 활용해 IP와 PORT 기반으로 데이터 전송 - 서버와 클라이언트는 1:1, 1:N, N:M으로 연결 가능 ⇒ 브로드캐스트, 멀티캐스트 - 데이터그램(메시지) 단위로 전송되며, 그 크기는 65535 byte. 크기가 초과되면 잘라서 전송 - 흐름 제어X ⇒ 패킷의 전송/오류 여부를 확인 X - 참고사항 - 흐름제어 : 데이터의 송수신 데이터 처리 속도를 조절하여, 수신자의 버퍼 오버플로우를 조절 - 혼잡제어 : 네트워크 내의 패킷 수가 넘치지 않도록 방지 ## 5️⃣ UDP 용도 - 실시간 데이터 전송 - 음성 통화와 스트리밍에서는 빠른 전송이 중요하고, 약간의 데이터 손실 허용 - 여러 상대에게 같은 내용의 데이터 전송 - 신뢰성이 필요하지 않은 소량의 데이터 전송 ",
    "url": "/Network/network_udp.html",
    
    "relUrl": "/Network/network_udp.html"
  },"66": {
    "doc": "웹 서버",
    "title": "웹 서버",
    "content": "# 웹 서버 > 웹 서버 라는 용어는 웹 서버 소프트웨어 와 웹페이지 제공에 특화된 장비 양쪽 모두를 가리킨다. 1.웹 서버 구현 웹 서버는 HTTP 및 그와 관련된 TCP 처리를 구현한 것. 웹 서버는 HTTP 프로토콜을 구현하고 웹 리소스를 관리하고 웹 서버 관리 기능을 제공. 웹 서버는 TCP 커넥션 관리에 대한 책임을 운영체제와 나눠 갖는다. 운영체제는 컴퓨터 시스템의 하드웨어를 관리, TCP/IP 네트워크 지원, 웹 리소스 유지를 위한 파일 시스템 현재 연산 활동을 제어하기 위한 프로세스 관리를 제공 ## 웹서버가 하는 일 1. 커넥션을 맺는다. 2. 요청을 받는다. 3. 요청을 처리한다. 4. 리소스에 접근한다. 5. 응답을 만든다. 6. 응답을 보낸다. 7. 트랜잭션을 로그로 남긴다. ![alt text](https://velog.velcdn.com/images/bahar-j/post/6cbdd139-aa0b-4459-951a-af811bfd5686/image.png) ## 1. 클라이언트 커넥션 수락 ### 새 커넥션 다루기 웹 서버는 어떤 커넥션이든 마음대로 거절하거나 즉시 닫을 수 있다. ### 클라이언트 호스트 명 식별 대부분의 쉡 서버는 역방향 DNS를 사용해서 클라이언트의 IP 주소 -> 클라이언트의 호스트명 으로 변환하도록 설정되어 있음. 클라이언트 호스트 명을 구체적인 접근제어와 로깅을 위해 사용할 수 있음 호스트명 룩업은 시간이 많이 걸릴 수 있어 웹 트랜잭션을 느리게 할수 있음 대용량 웹 서버는 호스트 명 분석(hostname resolution)을 꺼두거나 특정 콘텐츠에 대해서면 킨다. ### ident를 통해 클라이언트 사용자 알아내기 Ident 프로토콜은 특정 TCP 연결이 어떤 사용자나 프로세스에 의해 시작되었는지를 파악하기 위해 사용됩니다. 이는 보안 감사, 로깅, 또는 액세스 제어를 강화하기 위한 용도로 사용됩니다. Ident는 과거에 IRC(Internet Relay Chat) 서버와 같은 시스템에서 유용하게 사용되었습니다. IRC 서버는 연결 요청을 보낸 사용자가 누구인지 확인하기 위해 Ident 요청을 보내고, 결과에 따라 접속 허용 여부를 결정했습니다. 현재는 주로 레거시 시스템이나 특정 환경에서 제한적으로 사용됩니다. 많은 네트워크와 애플리케이션은 이를 더 이상 활성화하지 않거나 더 안전한 대안을 사용합니다. ## 2. 요청 메시지 수신 - 웹 서버는 요청줄을 파싱하여 요청 메서드, 지정된 리소스의 식별자(URI), 버전 번호를 찾는다. 각 값은 스페이스 한 개로 분리 되어 있으며, 요청줄은 캐리지 리턴 줄바꿈(CRLF) 문자열로 끝난다. - 메시지 헤더들을 읽는다. 각 메시지 헤더는 CRLF로 끝난다. - 헤더의 끝을 의미하는 CRLF로 끝나는 빈 줄을 찾아낸다. - 요청 본문이 있다면, 읽어들인다.(길이는 Content-Length 헤더로 정의된다) 네트워크 커넥션은 언제라도 무효화될 수 있기 때문에 웹 서버는 파싱해서 이해하는 것이 가능한 수준의 분량읗확보할 때까지 데이터를 네트워크로부터 읽어서 메시지 일부분을 메모리에 임시로 저장해 둘 필요가 있다. ### 메시지의 내부 표현 몇몇 웹 서버는 요청 메시지를 쉽게 다룰 수 있도록 내부의 자료 구조에 저장한다. ### 커넥션 입/출력 처리 아키텍처 고성능 웹 서버는 수천 개의 커넥션을 동시에 열 수 있도록 지원한다. 웹 서버들은 항상 새 요청을 주시한다. 웹 서버 아키텍처의 차이에 따라 요청을 처리하는 방식도 달라진다. (a) 단일 스레드 웹 서버 (b) 멀티프로세스와 멀티스레드 웹서버 (c) 다중 I/O 서버 대량의 커넥션을 지원하기 위해 모든 커넥션은 동시에 그 활동을 감시당한다. 스레드와 프로세스는 유휴 상태의 커넥션에 매여 기다리느라 리소스를 낭비하지 않는다. (d) 다중 멀티스레드 웹 서버 몇몇 시스템은 자신의 컴퓨터 플랫폼에 올라와 있는 CPU 여러 개의 이점을 살리기 위해 멀티스레딩 다중화를 결합한다. 여러개의 스레드는 각각 열려있는 커넥션을 감시하고 각 커넥션에 대해 조금씩 작업을 수행한다. ## 3. 요청처리 웹 서버가 요청을 받으면, 서버는 요청으로부터 메서드, 리소스, 헤더, 본문을 얻어 처리한다. POST를 비롯한 몇몇 메서드는 요청 메시지에 엔티티 본문이 있을 것을 요구한다. 그 외 OPTIONS를 비롯한 다수의 메서드는 요청에 본문이 있는 것을 허용하되 요구하지는 않는다. 많지는 않으나 GET 같이 요청 메시지에 엔티티 본문이 있는 것을 금지하는 메서드도 있다. ## 4. 리소스의 매핑과 접근 웹 서버는 리소스 서버다. HTML, JPEG 이미지 같은 미리 만들어진 콘텐츠를 제공하며, 서버 위에서 동작하는 리소스 생성 애플리케이션을 통해 만들어진 동적 콘텐츠도 제공한다. 웹 서버가 클라이언트에게 알맞은 콘텐츠를 전달하려면 그전에 요청메시지의 URI에 대응하는 콘텐츠 또는 콘텐츠 생성기를 웹 서버에서 찾아서 그 콘텐츠의 원천을 식별해야 한다. ### Docroot 웹 서버는 여러 종류의 리소스 매핑을 지원하지만, 가장 단순한 방법은 요청 URI를 웹 서버의 파일 시스템 안에 있는 파일 이름으로 사용하는 것이다. 일반적으로 웹 서버 파일 시스템의 특별한 폴더를 웹 콘텐츠를 위해 예약해 둔다. 이 폴더는 루트 혹은 docroot로 불린다. 웹 서버는 요청 메시지에서 URI를 가져와 문서 루트 뒤에 붙인다. httpd.conf 와 같은 내부 설정파일을 이용하여 웹 서버의 문서 루트를 설정할 수 있다. 서버는 docroot 이외의 다른부분이 노출되지 않도록 주의해야 한다. ex) 아파치 httpd.conf 파일을 보면 DocumentRoot가 정의되있는 부분을 보실 수 있을 겁니다. ### 가상 호스팅된 docroot 가상 호스팅 웹 서버는 각 사이트에 그들만의 분리된 문서 루트를 주는 방법으로 한 웹 서버에 여러 개의 웹 사이트를 호스팅 한다. 가상 호스팅 웹 서버는 URI나 Host 헤더에서 얻은 IP 주소나 호스트 명을 이용해 올바른 문서 루트를 식별한다. 하나의 웹 서버 웨어서 두 개의 사이트가 완전 분리된 콘텐츠를 갖고 호스팅 되도록 할 수 있다. 가상으로 호스팅 되는 docroot 설정은 아파치 웹 서버 같은 경우 VirtualHost 블록에서 DocumentRoot 지시자를 포함하도록 설정한다. https://httpd.apache.org/docs/2.4/ko/vhosts/examples.html ### 사용자 홈 디렉터리 docroots docroot의 또 다른 대표적인 활용은 사용자들이 한 대의 웹 서버에서 각자 개인의 웹 사이트를 만들 수 있도록 해주는 것이다. 빗금과 물결표 다음에 사용자 이름이 오는 것으로 시작하는 URI는 사용자 개인 문서 루트를 가리킨다. ### 디렉터리 목록 웹 서버는 경로가 파일이 아닌 디렉터리를 가리키는, 디렉터리 URL에 대한 요청을 받을 수 있다. 클라이언트가 디렉터리 URL을 요청했을 때 몇 가지 다른 행동을 취하도록 설정할 수 있다. 에러를 반환 디렉터리 대신 특별한 색인 파일을 반환 디렉터리를 탐색해서 그 내용을 담은 HTML 페이지를 반환 ### 동적 콘텐츠 리소스 매핑 웹 서버와 벡엔드 애플리케이션과 연결하여 동적으로 리소스를 식별하여 매핑한다. EX) 자바 서블릿 ### 서버사이드 인클루드(Server-Side Includes, SSI) 서버는 콘텐츠에 변수 이름이나 내장된 스크립트가 될 수 있는 특별한 패턴이 있는지 검사 특별한 패턴은 변수 값이나 실행 가능한 스크립트의 출력 값으로 치환 동적 콘텐츠를 만드는 쉬운 방법 ### 접근 제어 웹 서버는 클라이언트 IP에 근거하여 리소스에 접근하기 위한 비밀번호를 물어 볼수도 있음 ## 5. 응답 만들기 응답 메시지는 응답 상태 코드, 응답 헤더, 응답 본문을 포함한다. ### 응답 엔티티 본문이 있다면 응답 메시지는 다음을 포함한다. 응답 본문의 MIME 타입을 서술하는 Content-Type 헤더 응답 본문 길이를 서술하는 Content-Length 헤더 실제 응답 본문의 내용 ### MIME 타입 결정하기 웹 서버에게는 응답 본문의 MIME 타입을 결정해야 하는 책임이 있다. 다음은 MIME 타입과 리소스를 연결하는 여러가지 방법이다. - mime.types > 웹 서버는 MIME 타입을 나타내기 위해 파일 이름의 확장자를 사용할 수 있다. 이런 확장자 기반 타입 연계가 가장 흔한 방법이다. - 매직 타이핑 > 각 파일의 MIME 타입을 알아내기 위해 파일의 내용을 검사해서 알려진 패턴에 대한 테이블에 해당하는 패턴이 있는지 찾는다. > 느리긴 하지만 파일이 표준 확장자 없이 이름이 지어진 경우는 특히 편리하다. - 유형 명시 > 파일의 확장자 내용에 상관없이 어떤 MIME 타입을 갖도록 웹 서버를 설정할 수 있다. - 유형 협상 > 한 리소스가 여러 종류의 문서 형식에 속하도록 설정할 수 있다. 특정 파일이 특정 MIME 타입을 갖게 끔 설정할 수도 있다. ### 리다이렉션 웹 서버는 요청을 수행하기 위해 브라우저가 다른 곳으로 가도록 리다이렉트 할 수 있다. Location 응답 헤더는 콘텐츠의 새로운 혹은 선호하는 위치에 대한 URI를 포함한다. 리다이렉트는 다음의 경우에 유용하다. - 영구히 리소스가 옮겨진 경우 - 임시로 리소스가 옮겨진 경우 - URL 증강 > 서버는 종종 문맥 정보를 포함시키기 위해 재 작성된 URL로 리다이렉트를 한다. 트랜잭션간 상태를 유지하는 유용한 방법이다 - 부하 균형 > 과부화된 서버가 요청을 받으면, 서버는 클라이언트를 좀 덜 부하가 걸린 서버로 리다이텍트할 수 있다. - 친밀한 다른 서버가 있을때 - 디렉터리 이름 정규화 > 클라이언트가 디렉터리 이름에 대한 URI를 요청하는데 빗금을 빠트렸다면, 대부분의 웹 서버는 상대경로가 정상적으로 동작할 수 있도록 클라이언트를 슬래시를 추가한 URI로 리다이렉트한다. ​ ## 6. 응답 보내기 서버는 받을때와 마찬가지로 커넥션 너머로 데이터를 보낼 때도 비슷한 이슈에 직면한다. 서버는 커넥션 상태를 추적해야 하며, 지속커넥션인 경우 특별히 주의해야 한다. 비지속 커넥션이면 모든 메시지를 전송후 자신쪽의 커넥션을 닫을 것이다. 지속커넥션 이라면, Content-Length 헤더를 바르게 계산하기 위해 특별한 주의를 필요로 하는 경우, 클라이언트가 응답이 언제 끝나는지 알 수 없는 경우 커넥션은 열린 상태를 유지할 것이다. ",
    "url": "/Network/network_web_server.html",
    
    "relUrl": "/Network/network_web_server.html"
  },"67": {
    "doc": "네트워크",
    "title": "네트워크",
    "content": "# 네트워크 - 네트워크 기초 - OSI 7계층 & TCP/IP 4계층 - 네트워크 기기 - 스위치, 브리지, NIC, 리피터 등 - IP - HTTP & HTTPS - HTTP - 1, 1.1, 2, 3 - HTTPS - SSL/TLS - TCP & UDP - TCP 3 way handshake & 4 way handshake - DNS - 도메인 주소를 브라우저에 입력하면 발생하는 일 - Load Balancing - CDN ",
    "url": "/Network/readme_NW.html",
    
    "relUrl": "/Network/readme_NW.html"
  },"68": {
    "doc": "Synchronous?",
    "title": "Synchronous?",
    "content": "## 1. Synchronous? - 작업이 ‘순차적으로’ 진행되어야 하는 방법. - 작업이 독집적이지 못한다. 특정 작업에 영향을 받는다. 작업 진행을 호출한 쪽(스레드, 프로세스)이 담당한다. - 작업은 blocking이 된다. - 외부 요인에 의해 작업을 영향 받아서 기다린다. - 커널에 요청한 작업 때문에 wait queue에 들어갈 수도 있다. - 예시 - A 작업이 끝나야 B 작업이 실행이 된다. - API를 호출하고 결과가 오기 전까지 대기한다. - API 호출 결과를 알기 위해서 지속적으로 확인해야 한다. (처리 결과를 직접 확인해야 함) ## 2. Asynchronous? - 작업이 ‘독립적으로’ 진행할 수 있는 방법 - 즉시 리턴이 된다. 시스템 콜의 완료 여부를 기다리지 않는다. - 작업이 독립적으로 실행되기 위해서는 어떻게 해야할까? - **요청한 작업을 호출한 쪽이 신경쓰지 않는다. (non-blocking)** - 특정 신호를 통해서 결과 여부를 확인할 수 있다. (**signal**) - 신호는 운영체제가 알려준다. (사용자가 관리하지 않음) - epoll, iocp 등 - 호출 처리 담당을 만들어, 나중에 결과를 알려준다. (**asynchrous procedure call)** - callback - **작업을 여러 개로 쪼개서 독립적으로 실행한다. (concurrent)** - 작업을 A,B,C,D로 나눠 각 스레드가 독립적으로 처리한다. - Thread-1 : A,B 처리 담당 - Thread-2 : C,D 처리 담당 - 결과를 알기 위해서는 따로 확인을 해야한다. ## 3. Blocking & Non-Blocking - blocking과 non-blocking은 작업 진행이 멈추는가 안 멈추는가 (나 자신의 제어가 아닌 외부에 의해서) - Blocking - 운영체제 관점에서는 스레드가 작업을 요청 후 wait queue에 들어가서 대기함. 요청이 완료되면 요청을 받고 context switch가 되어 작업을 진행한다. - Non-blocking - wait queue에서 대기하지 않고 응답을 받고 돌아간다. (응답 코드, 에러 코드 등) - 예 - blocking I/O, non-blocking I/O - multi-threading ## 4. Blocking I/O, Non-Blocking I/O ![figure1.gif](https://developer.ibm.com/developer/default/articles/l-async/images/figure1.gif) - Boost application performance using asynchronous I/O - ibm에서 설명하는POSIX IO 설명 - 4분면은 IO를 설명하기 위해서 사용함. ### 4.1 Sync-blocking I/O ![sync-blocking.png](https://developer.ibm.com/developer/default/articles/l-async/images/figure2.gif) - 단순한 IO 모델 - 유저 스레드가 커널 스레드에게 요청을 보내면 유저 스레드는 대기한다. ### 4.2 Syn-non blocking I/O ![sync-non-blocking.png](https://developer.ibm.com/developer/default/articles/l-async/images/figure3.gif) - IO 작업이 요청이 blocking을 하지 않고 현재 작업에 대한 에러 코드를 전달한다. - 커널 스레드에서 유저 스레드로 권환이 돌아오기 때문에 유저 스레드는 자신의 작업을 계속 진행할 수 있다. - 하지만 유저 스레드는 작업의 완료 여부를 지속적으로 확인해야 한다. ### 4.3 Async -blocking (애매한 표현) ![figure4.gif](https://developer.ibm.com/developer/default/articles/l-async/images/figure4.gif) - 위 모델은 notify 기반으로 동작하는 모델 - IO mulitplexing을 통해서 하나의 소켓이 여러 file descirptor를 가지고 있다. - file descriptor에 데이터가 준비가 되면 스레드에게 통지하는 모델 - select(), epoll()은 non blocking라고 설명이 되어 있는데, ibm에서는 blocking으로 분류 - 만약 통지가 오기 전까지 유저 스레드가 작업을 멈추면, 그럴 수도 있다. - 다른 작업을 하다가 통지를 받으면 그렇지 않을 수도 있다. ### 4.4 Aysnc-non blocking ![figure5.gif](https://developer.ibm.com/developer/default/articles/l-async/images/figure5.gif) - aio, select, epoll, kqueue이 동작하는 방식이 위 사진처럼 동작함. - 작업은 callback, signal을 통해서 유저 스레드에게 통지가 된다. ## 5. 자바에서는 IO를 어떻게 사용할까? - io 패키지에 있는 input stream, output stream이 위에 있는 blocking io 방식 - 소켓이 열리면 데이터가 올 때까지 대기한다. - nio는 selector 라는 객체가 채널을 관리하면서 데이터 전달을 한다. - 이 selector는 sun에서 구현한 poll 방식의 시스템 콜을 사용한다. 통지 방식으로 구현됨. ``` Selector selector = Selector.open(); ServerSocketChannel serverSocket = ServerSocketChannel.open(); serverSocket.bind(new InetSocketAddress(\"localhost\", 5454)); serverSocket.configureBlocking(false); serverSocket.register(selector, SelectionKey.OP_ACCEPT); while (true) { selector.select(); // select() 호출과 동일한 블로킹 방식 Set selectedKeys = selector.selectedKeys(); Iterator iter = selectedKeys.iterator(); while (iter.hasNext()) { SelectionKey key = iter.next(); if (key.isAcceptable()) { // 새로운 연결 수락 SocketChannel client = serverSocket.accept(); client.configureBlocking(false); client.register(selector, SelectionKey.OP_READ); } if (key.isReadable()) { // 데이터 읽기 SocketChannel client = (SocketChannel) key.channel(); ByteBuffer buffer = ByteBuffer.allocate(1024); client.read(buffer); } iter.remove(); } } ``` ### 5.1 Servlet 3.0 - non-blocking io를 지원하기 시작한 서블릿 버전 - 기존 서블릿은 io 패키지에 있는 input, out stream을 사용 - servlet 3.0 부터 AsyncEvent, AysncListener을 통해서 서블릿 기능을 확장 - 어뎁터 패턴으로 기능을 확장함. - 정확히 어떠한 원리로 동작하는지는 모르겠음. - 내부에 atomicBoolean과 onEvent, onError가 구현되는 것을 보아 데이터가 준비되면 시그널, 콜백으로 전달하고 아닐 경우 에러를 처리하는 방식? - 동시성 때문에 시그널은 atomicBoolean으로 관리 ### 5.2 Future - 비동기적 연산을 지원함 - 여기서 비동기 연산은 non-blocking io를 활용하는 것이 아닌 multi-thread를 활용하는 방식 - 이유 : future는 excutor에 의해 실행이 된다. runnable을 파라미터로 받음. - 여기서 비동기 연산을 넣어 실행하면 정상일 때, 비정상일 때 처리 로직, 고계함수로 엮으면 복잡한 코드가 완성됨. - future로 작업을 얻기 위해서 get을 호출하는데 이 때, blocking이 발생. - 좀 더 우아한? 처리를 위한 것이 CompletableFuture ## 참고 - https://developer.ibm.com/articles/l-async/ - https://interconnection.tistory.com/141 - https://joooing.tistory.com/entry/동기비동기-블로킹논블로킹 ",
    "url": "/OS/os_Blocking_Non-Blocking_Synchronous_Asynchronous.html",
    
    "relUrl": "/OS/os_Blocking_Non-Blocking_Synchronous_Asynchronous.html"
  },"69": {
    "doc": "Computer 구조",
    "title": "Computer 구조",
    "content": "# Computer 구조 ### Computer란? CPU, DMA 컨트롤러, 메모리, 타이머, 디바이스 컨트롤러 등으로 이루어져 있습니다. ![](/OS/img/os_computer_1.png) ## CPU - `CPU(Central Processing Unit)`란 산술논리연산장치(ALU), 제어장치, 레지스터로 구성되어 있는 컴퓨터 장치이고, 인터럽트에 의해 단순히 메모리에 존재하는 명령어를 해석해서 실행하는 역할을 맡습니다. - 컴퓨터의 사용자는 운영체제의 커널을 통해 프로그램을 메모리에 올려 프로세스로 만들고, 이를 CPU가 연산 작업을 통해 처리합니다. ### 제어장치(CU, Control Unit) - 프로세스 조작을 지시하는 CPU의 한 부품입니다. - 입출력장치 간 통신을 제어하고, 명령어들을 읽고 해석하며 데이터 처리를 위한 순서를 결정합니다. ### 레지스터(Register) - CPU 안에 있는 매우 빠른 임시기억장치입니다. - CPU와 직접 연결되어 있어 연산 속도가 메모리보다 수십에서 수백 배 빠릅니다. - CPU는 자체적으로 데이터를 저장할 방법이 없기 때문에 레지스터를 거쳐 데이터를 전달합니다. ### 산술논리연산장치(ALU, Arthmetic Logic Unit) - 덧셈, 뺄셈 같은 두 숫자의 산술 연산과 배타적 논리합, 논리곱 같은 논리 연산을 계산하는 디지털 회로입니다. ### CPU의 연산 처리 과정 ![](/OS/img/os_computer_2.png) 1. 제어장치가 메모리에 계산할 값을 로드합니다. 또한, 레지스터에도 로드합니다. 2. 제어장치가 레지스터에 있는 값을 계산하라고 산술논리연산장치에 명령합니다. 3. 제어장치가 계산된 결과 값을 다시 '레지스터에서 메모리로' 계산한 값을 저장합니다. ### 인터럽트 - 어떤 신호가 들어왔을 때, CPU를 잠깐 정지시키는 것을 말합니다. - 키보드, 마우스, 등 IO 디바이스로 인한 인터럽트/0으로 숫자를 나누는 산술 연산에서의 인터럽트/프로세스 오류 등으로 발생합니다. - 인터럽트가 발생하면 인터럽트 핸들러 함수가 모여 있는 인터럽트 벡터로 가서 *인터럽트 핸들러 함수가 실행됩니다. 인터럽트 간에는 우선순위가 있고 우선순위에 따라 실행되며 인터럽트는 하드웨어 인터럽트, 소프트웨어 인터럽트 두 가지로 나뉩니다. *인터럽트 핸들러 함수: 인터럽트가 발생했을 때, 핸들링하기 위한 함수. 커널 내부의 IRQ를 통해 호출되며 request_irq()를 통해 인터럽트 핸들러 함수를 등록할 수 있다. _하드웨어 인터럽트_ - 키보드나 마우스를 연결하는 등의 IO 디바이스에서 발생하는 인터럽트를 의미합니다. - 이때 인터럽트 라인이 설계된 이후, 순차적으로 처리 중이던 인터럽트 실행을 잠시 중단하고, 운영체제에 시스템콜을 요청해서 원하는 디바이스의 작은 로컬 버퍼에 접근한 뒤 필요한 작업을 수행합니다. _소프트웨어 인터럽트_ - 트랩(trap)이라고도 하며, 프로세스 오류 등으로 프로세스가 시스템콜을 호출할 때 발동합니다. ## DMA 컨트롤러 - IO 디바이스가 메모리에 직접 접근할 수 있도록 하는 하드웨어 장치 - CPU에만 많은 인터럽트 요청이 들어오기 때문에 CPU 부하를 막고, CPU의 일을 보조하는 역할을 맡고 있습니다. - 하나의 작업을 CPU와 DMA 컨트롤러가 동시에 수행하는 것을 방지합니다. ## 메모리 - 전자회로에서 데이터나 상태, 명령어 등을 기록하는 장치를 말하며 보통 RAM(Random Access Memory)을 메모리라고 합니다. - CPU는 계산을 담당하고, 메모리는 기억을 담당합니다. - 메모리가 클 수록 많은 작업을 동시에 처리할 수 있어 작업 속도가 빨라집니다. ## 타이머 - 몇 초 내에 작업이 끝나야 한다는 것을 정하고 특정 프로그램에 시간 제한을 두는 역할을 합니다. - 시간이 많이 걸리는 프로그램이 작동하면 제한을 걸기 위해 존재합니다. ## 디바이스 컨트롤러 - 컴퓨터와 연결되어 있는 IO 디바이스들의 작은 CPU를 말하고, 옆에 붙어 있는 로컬 버퍼는 각 디바이스에서 데이터를 임시로 저장하기 위한 작은 메모리를 뜻합니다. # 운영체제(OS, Operating System) ### 운영체제란? 컴퓨터 하드웨어와 사용자(또는 응용 프로그램) 사이를 중재하는 소프트웨어 계층으로, 프로세스/메모리/파일/장치 관리 등을 담당합니다. ## 운영체제의 역할 1. CPU 스케줄링과 프로세스 관리: CPU 소유권을 어떤 프로세스에 할당할지, 프로세스의 생성과 삭제, 자원 할당 및 반환을 관리합니다. 2. 메모리 관리: 한정된 메모리를 어떤 프로세스에 얼만큼 할당해야 할지 관리합니다. 3. 디스크 파일 관리: 디스크 파일을 어떠한 방법으로 보관할지 관리합니다. 4. IO 디바이스 관리: IO 디바이스인 마우스, 키보드와 컴퓨터 간에 데이터를 주고받는 것을 관리합니다. ## 운영체제의 구조 ![](/OS/img/os_computer_3.png) *그림에서 GUI 부분이 없는 `Linux` 운영체제도 있습니다. ### 시스템콜 - 운영체제가 커널에 접근하기 위한 인터페이스 - 유저 프로그램이 운영체제의 서비스를 받기 위해 커널 함수를 호출할 때 사용합니다. - 유저 프로그램이 IO 요청으로 트랩(trap, SW 인터럽트)을 발동하면 올바른 IO 요청인지 확인 후 유저 모드가 시스템콜을 통해 커널 모드로 변환되어 실행됩니다. - ex. IO 요청으로 rs.readFile()이라는 파일 시스템의 파일을 읽는 함수가 발동한 경우 - 유저 모드에서 파일을 읽지 않고 커널 모드로 들어가 파일을 읽고 다시 유저모드로 돌아가 그 뒤에 있는 유저 프로그램의 로직을 수행합니다. - 이 과정을 통해 컴퓨터 자원에 대한 `직접 접근을 차단`할 수 있고 `프로그램을 다른 프로그램으로부터 보호`할 수 있습니다. ![](/OS/img/os_computer_4.png) - 시스템콜과 커널, 운영체제 ![](/OS/img/os_computer_5.png) - 위 그림처럼 프로세스나 스레드에서 운영체제로 요청을 할 때, 시스템콜이라는 인터페이스와 커널을 거쳐 운영체제에 전달됩니다. - 시스템콜은 하나의 `추상화 계층`입니다. 그래서 이를 통해 네트워크 통신이나 데이터베이스와 같은 낮은 단계의 영역 처리에 대한 부분을 많이 신경쓰지 않고 프로그램을 구현할 수 있는 장점이 있습니다. _modebit_ - 시스템콜이 작동될 때, modebit을 참고하여 유저 모드와 커널 모드를 구분합니다. - modebit은 0 또는 1을 가지는 플래그 변수입니다. - 카메라, 키보드 등 IO 디바이스는 운영체제를 통해서만 작동해야 합니다. 그 이유는 유저 모드를 기반으로 IO 디바이스의 제어가 가능해진다면 공격의 의도를 가진 해커가 사용자의 의도와 관계 없이 카메라를 제어할 수 있어 피해가 생길 수 있기 때문입니다. - 커널 모드를 거쳐 운영체제를 통해 작동한다고 해도 100% 막을 수는 없지만 운영체제를 통해 작동하게 해야 막기 쉬워집니다. 이를 위한 장치가 modebit입니다. ![](/OS/img/os_computer_6.png) - modebit의 0은 커널 모드, 1은 유저 모드 1. 유저 프로그램이 카메라를 이용하려고 할 때, 시스템콜을 호출하고 modebit을 1에서 0으로 바꾸며 커널 모드로 변경한 후 카메라 자원을 이용한 로직을 수행합니다. 2. 이후 modebit을 0에서 1로 바꿔서 유저 모드로 변경하고 이후 로직을 수행합니다. # 참고 자료 1. 면접을 위한 CS 전공지식 노트, 주홍철 2. Operating System Concepts, Abraham Silberschartz ",
    "url": "/OS/os_com_and_operating_system.html",
    
    "relUrl": "/OS/os_com_and_operating_system.html"
  },"70": {
    "doc": "CPU Scheduling",
    "title": "CPU Scheduling",
    "content": "# CPU Scheduling ## CPU 스케줄링 **정의**: 여러 프로세스가 CPU를 공유하는 환경에서, 효율적으로 CPU를 배분하여 시스템 성능을 최적화하고 처리 효율을 극대화하는 메커니즘. **목적**: 시스템 성능 최적화 및 처리 효율 극대화.  → CPU 이용률 최대화. 컴퓨터 시스템에서는 여러 프로세스가 동시에 실행되므로 CPU 자원을 효율적으로 관리하는 것이 중요하다.운영체제는 프로세스가 상황/중요도에 맞게 CPU를 이용할 수 있도록 **프로세스 우선순위(priority)** 를 부여한다. ### **스케줄링 큐** - 프로세스들이 서는 줄 - 스케줄링에서의 큐는 반드시 선입선출 방식일 필요는 없다. - 같은 큐 내에서도 우선순위 별로 처리가 된다. - 준비 큐 : CPU를 이용하고 싶어하는 프로세스들이 서는 줄 - 대기 큐 : 입출력장치들을 이용하고 싶어하는 프로세스들이 서는 줄 ![](/OS/img/os_cpu_scheduling_1.png) ## 주요 용어 - **도착 시간:** 프로세스가 준비 큐에 도착하는 시간. - **완료 시간:** 프로세스가 실행을 완료하는 시간. - **버스트 시간(Burst Time)**: 프로세스가 CPU를 사용하는 시간. - **대기 시간(Waiting Time)**: 프로세스가 CPU 할당을 기다린 시간. - **턴어라운드 시간(Turnaround Time)**: 프로세스 제출부터 완료까지의 시간. ## **CPU 스케줄링 알고리즘** ![](/OS/img/os_cpu_scheduling_2.png) | 분류 | 설명 | 장점 | 단점 | --- | --- | --- | --- | 선점형 | CPU를 강제로 뺏을 수 있는 방식. 프로세스가 중단될 수 있음. | 자원 독점 방지, 모든 프로세스에 골고루 자원을 배분 | 문맥 교환에 오버헤드 발생, 비효율적인 자원 분배 가능 | 비선점형 | CPU를 할당받은 프로세스가 종료될 때까지 다른 프로세스가 개입할 수 없음. | 문맥 교환 오버헤드 적음 | 자원 독점 가능, 긴 프로세스가 시스템을 지배할 수 있음 | ## 비선점형(Non-preemptive) ### **FCFS (First-Come, First-Served)** - 선입 선처리 스케줄링 - 단순히 준비큐에 **삽입된 순서대로 처리**하는 비선점 스케줄링 - 먼저 CPU를 요청한 프로세스부터 CPU 할당 - 단점 : 프로세스들이 기다리는 시간이 매우 길어질 수 있다.(Convoy Effect, 호위 효과) **예제** 다음과 같은 작업들이 있을 때: 1. P1 (실행 시간: 6ms) 2. P2 (실행 시간: 8ms) 3. P3 (실행 시간: 2ms) | 프로세스 | 실행 시간(Burst Time) | 대기 시간(Waiting Time) | 완료 시간(Turnaround Time) | --- | --- | --- | --- | P1 | 6ms | 0ms | 6ms | P2 | 8ms | 6ms | 14ms | P3 | 2ms | 14ms | 16ms | 도착 순서: P1 → P2 → P3 실행 순서: P1 → P2 → P3 평균 대기 시간 = (0 + 6 + 14) / 3 = 6.67ms 평균 완료 시간 = (6 + 14 + 16) / 3 = 12ms **FCFS**에서는 P1 → P2 → P3 순서로 실행되므로, B와 C는 A가 끝날 때까지 대기해야 한다. 짧은 작업이 먼저 끝날 수 있지만, 긴 작업이 CPU를 점유하여 시스템 효율성이 떨어진다. 해결 방법으로 **SJF**, **RR**, **Priority Scheduling**과 같은 스케줄링 기법이 있다. ### SJF (Shortest Job First) - CPU 사용 시간이 가장 짧은 프로세스부터 처리 - 장점 - 평균 대기 시간 최소화. - 호위 효과 방지. - 단점: 긴 작업은 무한정 대기할 가능성이 있다. (Starvation, 기아 상태) **예제** 다음과 같은 작업들이 있을 때: 1. P1 (실행 시간: 6ms) 2. P2 (실행 시간: 8ms) 3. P3 (실행 시간: 2ms) | 프로세스 | 실행 시간(Burst Time) | 대기 시간(Waiting Time) | 완료 시간(Turnaround Time) | --- | --- | --- | --- | P1 | 6ms | 2ms | 8ms | P2 | 8ms | 8ms | 16ms | P3 | 2ms | 0ms | 2ms | 도착 순서: P1 → P2 → P3 실행 순서: P3 → P1 → P2 평균 대기 시간 = (0 + 2 + 8) / 3 = 3.33ms 평균 완료 시간 = (2 + 8 + 16) / 3 = 8.67ms ## 선점형(Preemptive) ### RR (Round Robin) - 일정 시간(Time Quantum) 동안 프로세스를 실행한 후 대기열의 끝으로 이동한다. - 선입 선처리 스케줄링 + 시간 퀸텀(Time Quantum) - 시간 퀸텀 : 각 프로세스가 CPU를 사용할 수 있는 정해진 시간 - 장점: 응답 시간이 일정. - 단점: 프로세스 실행 시간(Time Quantum) 설정이 성능에 영향을 준다. - 프로세스 실행 시간이 극단적으로 커지면 FCFS과 같이 호위 효과가 발생할 수 있다. - 프로세스 실행 시간이 지나치게 작으면 문맥교환에 발생하는 오버헤드가 발생한다. **예제** ![](/OS/img/os_cpu_scheduling_3.png) Time Quantum = 5ms | 프로세스 | 실행 시간(Burst Time) | 대기 시간(Waiting Time) | 완료 시간(Turnaround Time) | --- | --- | --- | --- | P1 | 20ms | 15ms | 35ms | P2 | 3ms | 5ms | 8ms | P3 | 7ms | 18ms | 25ms | P4 | 5ms | 13ms | 18ms | 1. 0ms: P1 실행 2. 5ms: P2 실행, P1 대기 (남은 시간 15ms) 3. 8ms: P2 완료, P3 실행 4. 13ms: P4 실행, P3 대기(남은 시간 2ms) 5. 18ms: P4 완료, P1 실행 6. 23ms: P3 실행 P1 대기 (남은 시간 10ms) 7. 25ms: P3 완료, P1 실행 8. 35ms: P1 완료 **결과** 평균 대기 시간 = (15+5+18+13)/4=12.75ms 평균 완료 시간 = (35+8+25+18)/4=21.5ms ### SRTF (Shortest Remaining Time First) - 남은 실행 시간이 가장 짧은 프로세스를 우선 실행한다. - 정해진 시간만큼 CPU를 이용하고, 다음으로 CPU를 사용할 프로세스는 남은 작업 시간이 가장 적은 프로세스로 선택한다. - 최단 작업 우선 스케줄링 + 라운드 로빈 스케줄링 - 장점: 짧은 작업 우선 처리로 평균 대기 시간 감소. - 단점: 긴 작업은 계속 대기할 가능성 있음. **예제** ![](/OS/img/os_cpu_scheduling_4.png) Time Quantum = 5ms | 프로세스 | 실행 시간(Burst Time) | 대기 시간(Waiting Time) | 완료 시간(Turnaround Time) | --- | --- | --- | --- | P1 | 20ms | 15ms | 35ms | P2 | 3ms | 0ms | 3ms | P3 | 7ms | 7ms | 20ms | P4 | 5ms | 3ms | 8ms | 1. 0ms: P2 실행 2. 3ms: P2 완료, P4 실행 3. 8ms: P4 완료, P3 실행 4. 13ms: P3 대기(남은 시간 2ms), P1 실행 5. 18ms: P1 대기, P3 실행 6. 20ms: P3 완료, P1 실행 7. 35ms: P1 완료 **결과** 평균 대기 시간 = (15+0+7+3)/4=6.25ms 평균 완료 시간 = (35+3+20+8)/4=16.5ms ### Priority Scheduling - 프로세스들에 우선순위를 부여하고, 우선순위 높은 프로세스부터 실행한다. - 동일한 우선순위를 가진 프로세스가 여러 개 있을 경우, 일반적으로 FCFS (First Come First Serve) 방식으로 실행된다. - 장점: 중요 작업 우선 처리 가능. - 단점: 낮은 우선순위 작업의 기아 현상(Starvation). **Aging 기법**(시간이 지남에 따라 우선순위 증가). 오랫동안 대기한 프로세스의 우선순위를 점차 높이는 방식으로 대기 중인 프로세스의 우선순위를 점진적으로 증가시킨다. 우선순위가 낮아도 언젠가는 우선순위가 높아진다. **장점** - 기아 현상을 방지. - 우선순위가 낮은 프로세스도 결국 CPU를 사용할 수 있도록 보장. **단점** - 오버헤드: 우선순위를 조정하는 데 추가적인 계산이 필요 - 우선순위 상승으로 인해 예기치 않은 실행 순서가 발생할 수 있음. ### 다단계 큐 스케줄링 (Multilevel queue) ![](/OS/img/os_cpu_scheduling_5.png) - 우선순위 스케줄링의 발전된 형태로 우선순위별로 준비 큐를 여러 개 사용한다. - 우선 순위가 가장 높은 큐에 있는 프로세스를 먼저 처리한다. - 장점 - 프로세스 유형별로 우선순위를 구분하기 쉽다. - 상황에 맞는 스케줄링 알고리즘을 적용할 수 있다. - 단점: 우선순위 간 이동이 불가능 하기 때문에 우선순위가 낮은 프로세스는 계속해서 대기하는 기아 현상이 발생할 수 있다. ### 다단계 피드백 큐 스케줄링 (Multilevel feedback queue) - 다단계 큐 스케줄링의 단점을 보완한 알고리즘으로 큐 간 이동을 허용한다. - CPU 스케줄링 방식의 가장 일반적인 형태 - 동작 원리 1. 높은 우선순위 큐에서 프로세스를 먼저 처리. 2. 일정 시간 동안 실행 후 시간 초과하면 하위 큐로 이동. 3. 하위 큐에서 대기 시간이 길어지면 다시 상위 큐로 이동 [https://imbf.github.io/computer-science(cs)/2020/10/18/CPU-Scheduling.html](https://imbf.github.io/computer-science(cs)/2020/10/18/CPU-Scheduling.html) https://www.geeksforgeeks.org/cpu-scheduling-in-operating-systems/ https://www.robotstory.co.kr/raspberry/?vid=148 https://www.youtube.com/watch?v=CdrozYcVccE https://www.youtube.com/watch?v=w1z6WCyMdhQ **추가** ## **CFS (Completely Fair Scheduler )** - 모든 프로세스가 CPU 자원을 공평하게 사용할 수 있도록 보장하는 스케줄러 - 가상 런타임(Virtual Runtime) - 각 프로세스가 CPU를 사용한 시간을 기록한 값 - CPU를 가장 적게 사용한 프로세스가 가장 먼저 실행된다. - CPU 사용 시간이 많을수록 가상 런타임 값이 더 빨리 증가한다. - 레드-블랙 트리(Red-Black Tree) - 레드-블랙 트리라는 자료구조를 사용해 프로세스를 관리하며, 프로세스가 CPU를 사용한 시간에 따라 정렬한다. ### **특징** 1. **공정성 보장** - CPU 사용량이 적은 프로세스가 더 자주 실행된다. - 우선순위가 높은 프로세스는 가상 런타임 증가 속도가 느려져 더 많은 CPU 시간을 할당받는다. 1. **레드-블랙 트리 사용** - 모든 실행 가능한 프로세스를 가상 런타임을 기준으로 정렬하여 관리한다. - 가장 가상 런타임이 작은 프로세스가 트리의 왼쪽 끝에 위치하고 먼저 실행된다. ![](/OS/img/os_cpu_scheduling_6.png) ### **CFS의 동작 방식** 1. **프로세스 삽입** - 새 프로세스가 실행 준비 상태(Ready)에 들어오면, 레드-블랙 트리에 삽입된다. 2. **최소 가상 런타임 선택** - 레드-블랙 트리에서 가장 **가상 런타임 값이 작은 프로세스**를 선택하여 실행한다. 3. **실행 및 가상 런타임 업데이트** - 프로세스가 실행되면 해당 프로세스의 가상 런타임 값이 증가한다. - 실행이 끝난 후, 프로세스는 다시 레드-블랙 트리에 삽입된다. ### 장점 1. **공정성:** 모든 프로세스가 CPU를 공평하게 사용할 수 있다. 2. **효율성**: 레드-블랙 트리를 사용해 스케줄링 작업을 효율적으로 수행한다. O(log N) 3. **우선순위 조정 가능:** Nice 값을 통해 우선순위를 조정하여 특정 프로세스에 더 많은 CPU 시간을 할당할 수 있다. - Nice 값: 프로세스의 우선순위(priority)를 조정하는 값 4. **다양한 환경 지원** ### **리눅스에서 CFS를 사용하는 이유** **공정성, 성능, 확장성, 다양한 워크로드 처리** 등을 모두 만족시키기 위함. **기존 스케줄러의 문제점** 1. 과거 리눅스는 우선순위 기반의 타임 슬라이스 방식을 사용했는데, 특정 프로세스가 불공정하게 자원을 독점하는 문제가 있었다. - 👉 Nice 값으로 우선순위 조정 2. GUI 프로그램(인터랙티브 프로그램)이나 I/O 중심의 프로세스는 응답 시간이 매우 중요하지만, 기존 스케줄러는 CPU 중심 프로세스에 우선순위를 주어 지연(latency)이 발생했다. 3. 특정 환경에 최적화된 스케줄러는 다른 환경에서는 비효율적일 수 있다. - 예를 들어, I/O 중심 프로세스와 CPU 중심 프로세스가 섞인 경우 효율적으로 처리하지 못한다. 4. 프로세스 수가 많아지면 성능이 급격히 저하되거나 관리 오버헤드가 증가 했다. - 👉 레드-블랙 트리(Red-Black Tree) 구조로 성능 보장 ",
    "url": "/OS/os_cpu_scheduling.html",
    
    "relUrl": "/OS/os_cpu_scheduling.html"
  },"71": {
    "doc": "Deadlock이란?",
    "title": "Deadlock이란?",
    "content": "# Deadlock이란? 운영체제에서의 교착상태(Deadlock)는, 두 개 이상의 작업이 서로 상대방이 점유하고 있는 자원을 기다릴 때 **무한 대기에 빠지는 상황**을 의미한다. 즉, 멀티프로그래밍 환경에서 한정된 자원을 얻기 위해 서로 경쟁하는 상황이다. 프로세스가 자원을 얻지 못해 다음 처리를 하지 못하는 상태로, 시스템적으로 **한정된 자원**(CPU,메모리,파일,프린터 등)을 여러 곳에서 **동시에 사용**하려고 할 때 발생한다. ![](/OS/img/os_deadlock_1.png) # 발생 조건 데드락이 발생하기 위한 조건은 크게 4가지가 있다. 1. **`상호 배제`** (Mutual Exclusion) - 자원은 한 번에 한 프로세스만 사용할 수 있다. 사용 중인 자원을 다른 프로세스가 사용하려면 요청한 자원이 해제될 때까지 기다려야 한다. 2. **`점유 대기`** (Hold and Wait) - 자원을 최소한 하나 보유하고, 다른 프로세스에 할당된 자원을 점유하기 위해 대기하는 프로세스가 존재해야 한다. 3. **`비선점`**  (Non-Preemptive) - 다른 프로세스에게 할당된 자원은 사용이 끝날 때까지 강제로 빼앗을 수 없다. 4. **`순환 대기`** (Circular wait) - 자원 할당 그래프에서 사이클이 존재해야 하며, 이는 각 프로세스가 순차적으로 다음 프로세스가 요구하는 자원을 보유하고 있어 서로가 서로를 기다리는 상태를 의미한다. ![](/OS/img/os_deadlock_2.png) # 해결법 ## 1️⃣ 예방 데드락 4가지 발생 조건 중 최소 1가지를 절대 만족시키지 않도록 한다. ### 1. 상호 배제 부정 - 여러 프로세스가 자원을 공유하도록 한다. - 자원이 독점적으로 사용될 필요가 없을 때 사용된다. - ex) 읽기 전용 파일 - 현실적으로 불가능하다. (CPU나 프린터 동시 사용 불가능) ### 2. 점유 대기 부정 1. 필요한 자원을 모두 할당받은 후 시작하도록 한다. 2. 자원을 전혀 갖고 있지 않을 때만 자원을 한 번에 요청하도록 한다. ⇒ 지금 필요하지 않은 자원도 소유할 뿐더러, 필요한 자원을 계속해서 파악하기 위한 비용이 든다. ⇒ 할당된 모든 자원이 바로 사용되지 않기에 **낮은 자원 효율성** ⇒ 최소한의 자원이 항상 다른 프로세스에게 할당되어 있기 때문에 **기아 발생 가능** cf) `기아(Starvation)` : 특정 프로세스의 우선 순위가 낮아서 원하는 자원을 계속 할당받지 못하는 상태 ### 3. 비선점 부정 - 사용 중인 자원에 대해 다른 프로세스가 요청할 경우, 자원을 점유하고 있던 프로세스가 그 자원을 해제하고 나중에 다시 요청할 수 있도록 하는 방법 ### 4. 순환 대기 부정 - 모든 자원에 고유 번호를 할당하고, 프로세스가 번호가 낮은 순서대로만 자원을 요청할 수 있도록 한다. ⇒ 자원을 순차적으로만 요청할 수 있다. - ex) 프로세스는 순서의 증가 방향으로만 자원 요청 가능 R1, R2, R3, R4 P1 (R1, 2, 4 모두 필요) P2 (R1, 3 모두 필요) P1이 먼저 R1을 사용하면, P2는 R1을 못 쓰기 때문에 P2가 실행 불가. 따라서, 자원 3는 아무도 사용하지 않는다. => 자원 사용의 효율성이 떨어지고 비용이 많이 든다. ## 2️⃣ 회피 데드락이 발생할 가능성이 있을 땐 아예 자원을 할당하지 않는 방법이다. `안정 상태(safe state)`란 모든 프로세스가 최대 자원 요구량만큼 자원이 필요할 때도, 시스템이 주어진 순서대로 자원을 할당하여 모든 프로세스가 완료될 수 있는 상태이다. 안정 상태에서는 어떠한 프로세스도 데드락에 빠지지 않는다. `안전 순서(Safe Sequence)`란 프로세스에 특정 순서로 자원을 할당할 때 모든 프로세스가 성공적으로 완료될 수 있는 순서다. 이 순서대로 자원을 할당하면 시스템은 항상 안전 상태를 유지할 수 있다.  ### 은행가 알고리즘(Banker’s Algorithm) 회피 방법의 대표적인 예시로는 `은행가 알고리즘(Banker's Algorithm)`이 있다. 은행에서 모든 고객의 요구가 충족되도록 현금을 할당하는 데에서 유래한 기법이다. 다중 프로세스 시스템에서 안전한 순서로 자원을 할당하는 방법을 제공한다. 은행이 모든 고객에게 현금을 대출해주는데서 유래됐다. 은행(os)은 최소한 고객(프로세스)에게 대출할 정도의 돈(자원)이 있어야 한다. 그렇지 않으면 은행은 불안정 상태(데드락이 발생 가능한 상태)다. 은행가 알고리즘에는 3가지 전제조건이 있다. 아래 조건들이 충족되면, 시스템은 현재의 자원 할당 상태와 남은 자원량을 계속해서 감시하며, 각 요청이 안정 상태를 유지하는지 확인한다. 1. 각 프로세스가 평생 요구할 최대 자원량을 예측할 수 있어야 한다. 2. 각 프로세스는 다른 프로세스의 자원 요구에 독립적이어야 한다. 3. 자원의 수가 고정되어 있고, 추가/제거가 불가능해야 한다. 각 프로세스의 요구에 따라 자원을 한꺼번에 몰아주지 않는다. 프로세스가 요구하는 자원의 상태를 safe state와 unsafe state로 나누어, **safe state일 때만** 자원을 할당하는 방법이다. 프로세스에 자원이 할당된 후에 safe state로 남아있는지 **사전에 검사**하여 교착 상태를 피한다. 즉, `safe state`면 **자원을 할당**하고 `unsafe state`면 다른 프로세스가 **자원을 해지할 때까지 대기**하게 한다. 시스템은 모든 프로세스가 자신의 최대 요구량만큼 자원을 안전하게 할당받을 수 있는 순서, 즉 `안전 순서(Safe Seqeuence)`를 찾아낸다. 만약 실험적으로 특정 순서에 따라 모든 프로세스에 자원을 할당했을 때 최종 상태가 안전 상태라면 승인된다. 이 방식으로 시스템은 언제나 안전 상태를 유지하며 각 프로세스의 자원 요구를 최대한 만족시킨다. ## 3️⃣ 탐지 데드락 발생 가능성을 인정하고, 데드락을 빠르게 발견하고 문제를 해결하는 방법이다. `자원 할당 그래프`(Resource Allocation Graph, RAG)를 통해 교착 상태를 탐지할 수 있다. 이 그래프에서 사이클이 존재하면 데드락이 발생했다고 판단할 수 있다. 하지만 자원을 요청할 때마다 탐지 알고리즘을 실행하면, 오버헤드가 발생하게 된다. ![](/OS/img/os_deadlock_3.png) ## 4️⃣ 회복 교착 상태를 일으킨 프로세스를 종료하거나 할당된 자원을 해제하면서 회복하는 방법이다. 1. 프로세스 종료 - 교착 상태에서 나올 때까지 한 프로세스씩 중지한다. - 이때 순서는 무작위로 또는 특정 기준(우선순위 등)에 따라 결정된다. 2. 자원 선점 - 데드락을 일으킨 프로세스로부터 자원을 회수하여 다른 프로세스에 재할당하여 문제를 해결한다. # 출처 https://velog.io/@shinyejin0212/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9COS-7.-Deadlocks https://persi0815.tistory.com/6 https://www.boardinfinity.com/blog/deadlock-in-operating-system/ ",
    "url": "/OS/os_deadlock.html",
    
    "relUrl": "/OS/os_deadlock.html"
  },"72": {
    "doc": "Memory",
    "title": "Memory",
    "content": "# Memory # CPU 와 메모리 **CPU** 는 컴퓨터의 명령 해석, 데이터 처리를 **실행** 하는 장치 이다. **메모리** 는 이러한 CPU 가 처리할 데이터, 혹은 프로세서가 빠르게 접근할 수 있도록 명령어를 **저장** 하는 장치 이다. CPU 는 메모리에 직접 접근할 수 있다. 따라서 CPU 에서 메모리에 접근하여 데이터를 읽고 쓰는 속도가 프로그램 실행 속도, 즉 컴퓨터의 성능에 큰 영향을 미친다. ![](/OS/img/os_memory_cpu_and_memory.png) 출처 : [Understanding your Computer Memory and CPU](https://scottc130.medium.com/understanding-your-computer-memory-and-cpu-3a992aa60577) # 종류 메모리는 크게 RAM(Random Access Memory)과 ROM(Read Only Memory)으로 나뉘며, 이 둘은 주 메모리(Main Memory) 라고도 불린다. ### RAM - 현재 실행중인 프로그램, 데이터와 명령어를 저장하는 휘발성(일시적) 메모리. 모든 실행되는 프로그램이 존재하기 때문에 속도가 빨라야한다. - 1차 메모리라고도 불리운다. - 프로세스가 적재되는 메모리 는 RAM 을 의미한다. - 일반적으로 \"메모리\" 는 보통 RAM 을 의미한다고 볼 수 있다. ### ROM - 비휘발성 메모리로, 전원이 꺼져도 데이터가 유지. RAM 에 비해 속도가 느리다. - 부팅 과정에서 필요한 필수 명령어를 저장하는 데 사용. ### HDD (Hard Disk Drive) - 속도가 느리다. 2차 저장장치 혹은 보조 기억 장치 라고도 불리운다. - ROM 과 마찬가지로 비휘발성 메모리이다. # 주소 메모리(물리 메모리) 는 1바이트 의 크기를 가지는 주소 라는 것으로 이루어진다. ## 물리 / 논리 주소 - 물리 주소는 RAM 사용하는 주소 를 의미한다. - 논리 주소는 CPU와 실행중인 프로그램(프로세스)가 참조하는 주소이다. 즉, RAM 을 구성하고 있는 주소는 물리 주소, 프로세스를 구성하고 있는 주소는 논리 주소 임을 알 수 있다. ## 논리 주소 -> 물리 주소 CPU 는 논리 주소를 참조한다. RAM 에 접근하려면 논리 주소를 물리 주소로 변환하는 과정이 필요하다. 이를 실행하는 유닛이 MMU(Memory Management Unit, 메모리 관리 장치) 이다. ![](/OS/img/os_memory_cpu_memory_process.png) 출처 : [[10분 테코톡] 채채의 가상 메모리](https://www.youtube.com/watch?v=_SyFgWccEs8) 이미지에는 페이지 테이블 이라고 적혀있는데 # 메모리 관리 메모리 관리 작업은 크게 가져오기(Fetch), 배치(Placement), 재배치(Replacement)로 구분된다. - 메모리 가져오기 : 실행할 프로세스와 데이터를 메모리로 가져오는 작업 - 메모리 배치 : 가져온 프로세스와 데이터를 메모리의 어떤 부분에 올려놓을지 결정하는 작업. 그리고 메모리를 어떤 크기로 나누는 지 결정하는 작업. 페이징, 세그먼테이션이 메모리 배치 방법에 해당한다. - 메모리 재배치 : 꽉 찬 메모리에 새로운 프로세스를 가져오기 위해 오래된 프로세스를 내보내는 작업 ## 메모리 배치 전략 - 가변 분할 방식 (세그멘테이션) : 프로세스의 크기에 따라 프로세스 별로, 메모리를 나누는 방식. 세그먼트 라는 단위로 나뉘게 된다. - 고정 분할 방식 (페이징) : 페이지라고 불리우는 영역으로 모든 메모리를 0부터 시작하여 고정적인 값으로 번호를 매겨 관리. 페이지 라는 단위로 나뉘게 된다. ![](/OS/img/os_memory_segmentation_paging.png) # 물리 메모리 (Physical Memory) - RAM (혹은 때때로 RAM 에 존재하는 데이터)을 의미한다. 물리 메모리는 이러한 가상 메모리를 설명할 때, 가상 메모리와 구분하기 위한 의미로 사용되는 용어 라고 볼 수 있다. - 독자적인 의미를 띄기도 하지만, 가상 메모리 라는 개념을 설명하는 것에서 비롯되어 가상 메모리와 구분하기 위한 의미로 사용되는 용어라고 볼 수 있다. ## 주소 - 하나의 프로세스에 해당하는 주소 공간이 연속적으로 이어진 구조이다. 따라서, 보통 세그먼테이션 방식으로 분할되어 세그먼트 단위로 나뉘게 된다. - 물리 메모리를 구성하는, 혹은 물리 메모리를 관리할 수 있는 최소 단위는 1바이트 이다. 이 1바이트 마다 주소 라는 것이 할당된다. - 주소가 저장할 수 있는 크기는 CPU, OS 에 의존한다. 예를 들어 주소가 32비트 를 저장할 수 있다면, 해당 CPU 의 최대 메모리크기는 4GB 가 된다. (32비트가 표현할 수 있는 정보의 가지수는 4,294,967,296, 이를 바이트로 환산하면 4GB 이다.) # 가상 메모리 (Virtual Memory) - 제한된 메모리(물리 메모리) 로 더 많은 프로그램을 실행시키기 위한 기술 혹은 개념 > 물리 메모리는 RAM (혹은 때때로 RAM 에 존재하는 데이터) 를 의미한다. 물리 메모리는 이러한 가상 메모리를 설명할 때, 가상 메모리와 구분하기 위한 의미로 사용되는 용어 라고 볼 수 있다. - 사용 가능한 메모리의 범위를 RAM 에서, Swap 영역(HDD) 를 포함하는 것으로 확장시키는 추상화의 개념이라고 볼 수 있다. > Swap 영역은 주 메모리 의 용량이 부족할 때, 문제가 생기는 것을 방지하고자 2차 기억장치(보조 기억 장치)인 HDD 의 공간을 활용하여 메모리 역할을 할 수 있도록 도와주는 영역을 의미한다. ![](/OS/img/os_memory_swap_1.png) ![](/OS/img/os_memory_swap_2.png) 출처 : [[10분 테코톡] 채채의 가상 메모리](https://www.youtube.com/watch?v=_SyFgWccEs8) - 가상(Virtual) === 논리(Logical) 라고 볼 수 있다. ## 주소 - 어느 위치에 있던, 항상 0부터 시작한다. - 이론적으로는 가상 메모리의 크기는 무한대이지만, 실제로 가상 메모리의 최대 크기는 컴퓨터 시스템이 가진 물리 메모리의 최대 크기로 한정된다. 즉, CPU 비트에 따라 결정된다. - 주로 세그멘테이션 과 페이징 을 혼용한 기법을 많이 사용한다. ## 페이징 기법 에서의 가상 주소를 물리 주소로 변환하는 방법 ### 필요한 이유 앞서 얘기했 듯, 가상 메모리는 고정 분할 방식으로 나누어져 주소는 위치에 상관 없이 항상 0부터 시작한다. 하지만 물리 메모리의 주소는 가변 분할 방식으로 나누어지며 연속적이다. _예를 들어 프로세스 1, 2, 3 이 적재된 가상 메모리가 3개 있다. 각 가상 메모리에서는 같은 주소, 100번의 주소에 데이터를 가지고 있다. 하지만 이를 물리 메모리에서 생각하면, 각 데이터는 100번의 주소에 있다고 생각할 수없을 것이다. 앞서 얘기했듯, 메모리를 나누는 방식이 다르기 때문이다._ 따라서 가상 메모리의 페이지를, 물리 메모리의 세그먼트와 맵핑하여 변환하는 기능이 필요하다. ### 작동 원리 > 페이지 테이블이란 페이지를 실제 물리 주소 정보와 매핑한 표를 담고 있는 테이블 이다. 프로세스 마다 하나씩 가지고 있다. ![](/OS/img/os_memeory_page_table.png) ## 요구 페이징 필요한 프로그래만만 메모리에 올려 실행하고 나머지 프로그램은 사용자가 특정 기능을 요구할 때와 같이 필요하다고 판단될 때 메모리로 불러온다. 이렇게 사용자가 요구할 때 해당 페이지를 메모리로 가져오는 것을 요구 페이징이라고 한다. 페이징은 메모리 배치 전략의 일종이었다면, 이러한 요구 페이징은 메모리를 가져올 때 고려하는 메모리 가져오기 전략의 일종이다. ### 운영체제에서 중요한 이유 - 물리 메모리에 대한 의존성 제거 - 컴퓨터 마다 물리 메모리의 크기는 다르다. 만약 소프트웨어가 이러한 물리 메모리에 의존한다면, 크기가 다른 컴퓨터마다 다른 버젼의 소프트웨어를 사용해야할 것이다. 첫번째로 가상메모리는 이러한 소프트웨어의 물리메모리에 대한 의존성을 없애준다. - 메모리를 관리하는 측면에서 의의가 있다. MMU 역시 운영체제에서 중요한 역할을 한다고 볼 수 있다. 현대 메모리는 프로그램을 실행하는 공간이기에, 메모리 를 관리하는 것은 여러 프로그램을 실행하는 멀티프로그래밍 환경에서 아주 중요한 부분이다. 가상 메모리는 물리 메모리의 크기와 프로세스가 올라갈 메모리의 위치를 신경 쓰지 않고 프로그래밍하도록 지원한다는 것이다. --- 더 깊게 살펴보고싶다면 아래 링크를 추천합니다! [가상 메모리 개요](https://www.youtube.com/watch?v=-jlzaslp-w4),[[운영체제] 물리 메모리 관리](https://rob-coding.tistory.com/32), [[운영체제] 가상 메모리 ](https://rob-coding.tistory.com/33) # 출처 - [What is computer memory?](https://www.lenovo.com/us/en/glossary/computer-memory/?orgRef=https%253A%252F%252Fwww.google.com%252F&srsltid=AfmBOooZPjiaAitoO96hpjhnxvr0nqkB0-dNTguCss0s2Tti6xtILrIw) - [컴퓨터 구조의 이해: CPU와 메모리](https://f-lab.kr/insight/understanding-cpu-and-memory) - [What is the difference between physical memory, main memory, secondary memory, virtual memory, and hard disk? I’m studying operating system and I am very confused between these terms. ](https://www.quora.com/What-is-the-difference-between-physical-memory-main-memory-secondary-memory-virtual-memory-and-hard-disk-I-m-studying-operating-system-and-I-am-very-confused-between-these-terms) - [가상 메모리 개요](https://www.youtube.com/watch?v=-jlzaslp-w4) - [운영 체제의 가상 메모리](https://www.geeksforgeeks.org/virtual-memory-in-operating-system/) - [[운영체제] 물리 메모리 관리](https://rob-coding.tistory.com/32) - [[운영체제] 가상 메모리 ](https://rob-coding.tistory.com/33) - [[10분 테코톡] 채채의 가상 메모리](https://www.youtube.com/watch?v=_SyFgWccEs8) ",
    "url": "/OS/os_memory.html",
    
    "relUrl": "/OS/os_memory.html"
  },"73": {
    "doc": "Multi Process (멀티 프로세스)",
    "title": "Multi Process (멀티 프로세스)",
    "content": "# Multi Process (멀티 프로세스) # 프로그램 / 프로세스 - 프로그램 : 컴퓨터에서 실행할 수 있는 파일. 실행하기 전엔, 정적인 코드 덩어리. - 프로세서 : 프로그램을 실행하는 **하드웨어 유닛**. CPU 혹은 Microprocessor를 일컫는다. - 프로세스 : 프로그램이 메모리에 적재된 후, 프로그램이 실행 중이거나 실행 대기 중에 있는 상태. 동적인 작업의 단위. 즉, 메모리에 적재되어 프로세서에 의해 실행중인 프로그램. # 멀티 프로세싱 - 하나의 컴퓨터에서 2개 이상의 CPU(프로세서) 를 사용하여 프로그램을 병렬적으로 처리하는 방식. ## 동작 방식 ![](/OS/img/os_multi_processing_work.png) - 각 CPU는 주 메모리에 연결되어있다. - 수행해야 할 작업은 모든 프로세서에 분배. - 각 프로세서의 모든 작업이 완료되면 이를 함께 컴파일하여 단일 출력을 생성. ## 장/단점 - 여러 작업을 병렬적으로 처리하기 때문에, 더 빠른 속도로 작업을 처리할 수 있다. - 하지만, 여러 작업을 병렬적으로 처리하기 때문에, 동시성 문제를 해결해야할 필요가 있다. # 멀티 프로세스 - 하나의 프로그램에 대해 동시에 여러 개의 프로세스를 실행할 수 있게 하는 기술. ## 멀티 프로세스 / 멀티 프로세싱? - 프로세서는 프로그램이 실행할 수 있게하는 하드웨어이다. 따라서 멀티 프로세스와 멀티 프로세서는 같은 의미가 아닐까 생각할 수 있지만 엄밀히 따지자면 별개의 개념이다. - 멀티 프로세싱은 다중의 CPU 로 작업을 병렬적으로 처리하는 방식, 멀티 프로세스는 하나의 프로그램에 대해 다중의 프로세스가 생성된 상태를 뜻한다. --- - 멀티 프로세싱은 여러 작업을 더 빠르게 처리하기 위한 것에 초점을, 멀티 프로세스는 프로세스를 세분화 하여 더욱 안정성있고, 각 프로세스간의 유연한 소통이 가능한 것에 초점을 맞춘 것이라고 생각하면 될 듯 하다. _많은 블로그 및 자료에서 멀티 프로세스와 멀티 프로세싱 용어를 혼용하여 사용하는 듯합니다. 그래서 멀티 프로세스 와 멀티 프로세싱의 연관성과 면확한 차이점에 대해 찾아보려했지만 마땅한 자료가 없었습니다. 추후 자료를 찾으면 보충해보도록 하겠습니다._ ## 구조 - 멀티 프로세스는 하나의 부모 프로세스가 여러 개의 자식 프로세스를 생성하는 방식으로 구성된다. - 부모 프로세스와 자식 프로세스는 기본적으로 서로 독립적이다. ![](/OS/img/os_multi_processing_structure.png) ## 자식 프로세스 생성 방식 - 부모 프로세스는 실행되는 도중, 프로세스 생성 시스템 콜 중 하나인 fork() 메서드를 통해 자식 프로세스들을 생성한다. 즉, 부모 프로세스는 fork() 시스템 콜을 통해 자식 프로세스를 생성하는 프로세스이다. > 시스템 콜은 프로그램과 운영 체제 사이에서 상호작용하는 인터페이스를 의미한다. 프로그램이 운영 체제 커널에 서비스를 요청하는 프로그래밍 방식을 의미한다. - fork() : 새로운 프로세스 공간을 별도로 만들고, fork() 시스템 콜을 호출한 부모 프로세스 공간의 데이터을 모두 복사한다. ## 프로세스 간 통신 (IPC) - 멀티 프로세스 에서는 서로 다른 프로세스간의 데이터 공유 및 상호작용을 할 수있다. 이는 **프로세스 간 통신(Inter-Process Communication, IPC)** 를 통해 가능하다. ### 독자 / 협력 적인 프로세스 - 기본적으로 프로세스는 독자적이며, 다른 프로세스의 실행으로 부터 영향을 받지 않는다. 하지만 다른 프로세스와 상호작용을 할 경우(IPC 를 통해), 다른 프로세스의 실행에 영향을 받을 수 있는 협력 프로세스가 된다. ### 동기화 - 프로세스간 데이터를 공유하기 때문에, 공유 자원에 동시에 접근하는 문제가 발생할 수 있으므로 동기화에 유의해야한다. - IPC 의 방식중 공유 메모리 방식은 동기화를 직접 구현해야하지만, 메세지 전달 방식은 동기적인 통신을 지원한다. ### 장/단점 - 시스템 복잡도가 증가하고, 동기화에 유의하지 않으면 데이터 일관성이 해쳐질 수 있다는 단점도 존재하지만, - 프로세스간의 유연하고 효율적인 통신을 지원하고, 분산 시스템을 개발 가능하게 해준다는 점에서 현대 운영체제에서는 필수적인 요소이다. ### 공유 메모리 방식 (Sharing Memory) - 프로세스가 공통 메모리 공간을 사용하여 데이터를 교환한다. - 생성자가 데이터를 생성하고, 소비자가 소비한다. 이 둘은 buffer 라는 공유 메모리를 사용한다. - 생산자가 데이터를 생성해 buffer 에 추가하고, buffer 가 꽉 차면 대기한다. - 소비자는 buffer 에서 데이터를 가져와 소비하고, buffer 가 비어있으면 대기한다. - 효율적인 방법이지만, 동기화를 신경써야한다. ### 메시지 전달 방식 (Message Passing) - 메시지 교환만을 통해 통신하며, 동기적인 통신이 가능하다. - 직/간접 - 직접 통신 : 프로세스가 수신자나 발신자를 명시적으로 지정한다. - 간접 통신 : 메일박스(mailbox)라는 중간 매개체를 통해 메시지를 전달한다. - 동기/비동기 - 동기 통신 : 송신자는 수신 확인 전까지 대기한다. - 비동기 통신 : 송신자는 확인 없이 다른 작업을 계속 진행한다. ## 장/단점 - 하나의 프로그램을 독립적인 메모리 공간을 가지는 프로세스로 나누어 처리하는 부분에서 이점이 발생한다. ### 안정성 - 각 프로세스가 독립적인 메모리 공간을 가지므로, 한 프로세스가 비정상적으로 종료되어도 다른 프로세스에 영향을 주지않는다. 따라서 프로그램 전체의 안정성을 확보할 수 있다. ### 확장성 - 각 프로세스가 독립적이므로, 새로운 기능이나 모듈을 추가하거나 수정할때 다른 프로세스에 영향을 주지 않는다. 그래서 시스템의 규모를 쉽게 확장할 수 있다. - 이를 네트워크 서버에 적용하면, 로드 밸런서를 얘기할 수 있다. 로드밸런서는 요청을 여러 서버에 분산시키는 기능을 한다. 이때 여러 서버는 여러 컴퓨터가 될수도 있지만, 멀티 프로세스를 적용하면 하나의 성능 좋은 컴퓨터에 여러개의 서버 프로세스를 두는 것이 될 수도 있다. - 서버 클러스터도 하나의 컴퓨터에 여러개의 서버 프로세스를 띄움으로써 요청을 분산시키는 방법으로 이에 해당된다고 할 수 있다. Node.js 진영에선 대표적으로 PM2 가 있다. ## 단점 ### Context Switching Overhead > 컨텍스트 스위칭(Context Switching) 은 기존 프로세스가 실행되고 있는 상태에서 **interrupt** 가 발생하여 다른 프로세스가 실행되어야 할 때, 프로세스의 컨텍스트를 교체하는 과정을 뜻한다. 이 과정에는 기존 프로세스의 컨텍스트(상태) 를 나중에 복원할 수 있도록 저장하고, 다른 프로세스의 컨텍스트 를 실행하기 위해 로드하는 작업을 포함한다. interrupt 가 발생하는 상황에는 입출력 요청이 발생했을 때, CPU 사용시간 만료되었을 때, 자식 프로세스를 생성했을 때 등이 있다. - 멀티 프로세스 환경에서는 자식 프로세스를 생성하기에, interrupt 가 발생하여 컨텍스트 스위칭도 불가피하게 된다. 컨텍스트 스위칭이 발생할때마다, CPU 는 다음 프로세스의 정보를 로드하고, 기존 프로세스의 컨텍스트를 저장해야하기 때문에, 빈번하게 컨텍스트 스위칭이 일어난다면 비용 오버헤드가 발생할 수 있게 된다. # 출처 [👩‍💻 멀티 프로세스 vs 멀티 스레드 비교 💯 완전 총정리](https://inpa.tistory.com/entry/%F0%9F%91%A9%E2%80%8D%F0%9F%92%BB-multi-process-multi-thread) [👩‍💻 ‍완전히 정복하는 프로세스 vs 스레드 개념](https://inpa.tistory.com/entry/%F0%9F%91%A9%E2%80%8D%F0%9F%92%BB-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4-%E2%9A%94%EF%B8%8F-%EC%93%B0%EB%A0%88%EB%93%9C-%EC%B0%A8%EC%9D%B4) [프로세스 생성 시스템 콜 - fork(), exec() - 1](https://probe29.tistory.com/39) [Process VS Processor](https://woochan-autobiography.tistory.com/249) [OS - Context Switch(컨텍스트 스위치)가 무엇인가?](https://jeong-pro.tistory.com/93) [[CS] 멀티 프로세스/스레드와 context switching](https://velog.io/@bagt/%EB%A9%80%ED%8B%B0-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4%EC%8A%A4%EB%A0%88%EB%93%9C%EC%99%80-context-switching#-%EC%BB%A8%ED%85%8D%EC%8A%A4%ED%8A%B8-%EC%8A%A4%EC%9C%84%EC%B9%AD-context-switching) [Inter Process Communication (IPC)](https://www.geeksforgeeks.org/inter-process-communication-ipc/) [👩‍💻 멀티 태스킹 & 멀티 프로세싱 개념 한방 정리](https://inpa.tistory.com/entry/%F0%9F%91%A9%E2%80%8D%F0%9F%92%BB-multi-programming-tasking-processing) [멀티 프로세싱 운영 체제](https://www.geeksforgeeks.org/multi-processing-operating-system/) ",
    "url": "/OS/os_multi_processing.html",
    
    "relUrl": "/OS/os_multi_processing.html"
  },"74": {
    "doc": "공유 자원 &amp; 임계 영역(Semaphore &amp; Mutex)",
    "title": "공유 자원 &amp; 임계 영역(Semaphore &amp; Mutex)",
    "content": "# 공유 자원 & 임계 영역(Semaphore & Mutex) ## 동기화(Synchronization) - 여러 프로세스/스레드를 동시에 실행해도 공유 데이터의 일관성을 유지하는 것 - **실행 순서 제어** : 프로세스를 올바른 순서대로 실행 - **상호 배제** : 동시에 접근해서는 안 되는 자원에 하나의 프로세스만 접근 ## 공유 자원과 임계 구역 ### 공유 자원(Share Section) - 공유 자원은 여러 프로세스나 스레드가 동시에 접근하거나 사용할 수 있는 자원 - 전역 변수, 파일, 입출력장치, 보조기억장치, 네트워크 소켓 - 특징 - 자원을 공유할 경우, 잘못된 동기화로 인해 데이터의 일관성이 깨질 수 있다. - 예: 한 스레드가 공유 자원을 읽는 동안 다른 스레드가 해당 자원을 수정하면 데이터가 손상될 수 있다. 👉 **경쟁 상태(Race Condition)** > **경쟁 상태(Race Condition)** 두 개 이상의 스레드가 동시에 공유 자원에 접근하면서 올바른 실행 순서가 보장되지 않아 데이터 불일치 또는 손상이 발생하는 것 (예: 은행 계좌 입금 처리 중 두 명이 동시에 입금하면 최종 금액이 올바르지 않을 수 있음) > ### 임계 구역(Critical Section) - 공유 자원에 접근하고 수정하는 코드 영역 - 자원의 일관성을 위해 한 번에 하나의 스레드만 실행할 수 있어야 한다. → 상호 배제 - 임계 구역을 보호하기 위한 대표적인 도구로 뮤텍스(Mutex)와 세마포(Semaphore)가 있다. ![](/OS/img/os_mutex_semaphore_1.png) ## **Mutex** ![](/OS/img/os_mutex_semaphore_2.png) - **한 번에 하나의 스레드**만 공유 자원(임계 영역)에 접근할 수 있도록 보장하는 동기화 도구 - 특징 - 스레드가 락을 획득하면 다른 스레드는 대기. - 사용 후 반드시 **Unlock**해야 함. - 주로 단일 자원의 보호에 사용. ### **동작 원리** 1. **Lock** - 스레드는 임계 영역에 접근하기 전에 뮤텍스에 락을 요청한다. - 락이 획득되면 스레드는 자원에 접근한다. 2. **임계 영역 실행** - 스레드는 공유 자원을 사용하거나 처리한다. 3. **Unlock** - 스레드가 자원 사용을 마치면 락을 해제하여 다른 스레드가 자원을 사용할 수 있도록 한다. 4. **대기(WAIT)** - 만약 자원이 이미 다른 스레드에 의해 락이 걸려 있다면, 새로운 스레드는 해제될 때까지 대기 한다. ```java acquire(); { 임계 구역 } release(); ``` ```java acquire() { while(lock == true) {} lock = true; // 임계 구역에 진입 } release() { lock == false; // 임계 구역 해제 } ``` **acquire()** - 락 요청. 자원 사용 가능 시 진입. **release()** - 락 해제. 다른 스레드가 접근 가능하도록 허용. ## **Semaphore** ![](/OS/img/os_mutex_semaphore_3.png) - 하나 이상의 스레드가 자원에 접근할 수 있도록 제한하는 동기화 도구 - 공유 자원이 여러 개 있는 경우에도 적용 가능 - 특징 - **카운터 기반**: 특정 개수의 허용 가능한 자원 개수를 관리한다. - 프로세스의 순서를 정할 수 있다. ### 동작 원리 ```java int value = 3; // 사용 가능한 공유 자원의 개수 wait(); { 임계 구역 } signal(); ``` ```java wait() { while(value <= 0) {} value--; // 자원 사용 } signal() { value++; } ``` **wait()** - 자원이 없으면 대기 상태로 진입. - 자원이 있으면 카운터 감소 후 접근 허용. **signal()** - 자원을 반환하고 카운터 증가. | 항목 | Mutex | Semaphore | --- | --- | --- | **자원 개수** | 1개 (Binary, 락/언락) | 여러 개 (카운트 기반) | **사용 목적** | 단일 공유 자원 보호 | 제한된 자원 관리 | **소유권** | 소유권 있음 (락을 획득한 스레드만 해제) | 소유권 없음 (누구나 해제 가능) | 상호 배제만 필요하다면 뮤텍스를, 작업 간의 실행 순서 동기화가 필요하다면 세마포를 권장한다. --- ## 사용 사례 - **Mutex** - 파일 시스템 접근 - 하나의 프로세스가 파일을 읽거나 수정할 때 다른 프로세스 접근 차단. - 프린터 공유 - 출력 장치 접근을 순차적으로 관리. - **Semaphore** - 서버 연결 풀 관리 - DB 연결을 제한된 개수로 유지하여 과부하 방지. - 리소스 대기열 관리 - 제한된 자원(예: API 호출)에 대한 접근 동시 처리. --- 참고 https://hapen385.tistory.com/55 https://www.youtube.com/watch?v=0YDjblJn30k https://www.youtube.com/watch?v=gTkvX2Awj6g https://www.youtube.com/watch?v=4u13f9Umq7Y&t=58s https://mierminusone.tistory.com/4 https://one-armed-boy.tistory.com/entry/Mutex-Semaphore https://www.javatpoint.com/mutex-vs-semaphore ",
    "url": "/OS/os_mutex_semaphore.html",
    
    "relUrl": "/OS/os_mutex_semaphore.html"
  },"75": {
    "doc": "PCB와 Context Switching",
    "title": "PCB와 Context Switching",
    "content": "# PCB와 Context Switching ## PCB란? 운영체제는 컴퓨터 시스템에서 여러 프로세스를 관리해야 한다. 프로세스 제어 블록(PCB)는 운영체제가 각 프로세스에 대해 유지하는 데이터 구조로, 각 프로세스는 고유한 PCB를 가지며 현재 상태와 관련된 모든 정보를 저장한다. PCB는 커널 영역에 생성되며, 프로세스가 생성될 때 할당되고, 프로세스가 종료될 때까지 유지된다. ![pcb_image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbRj8NW%2FbtsI9XtaVmg%2FXGHIy6sWX8H0jGQKDOtwqk%2Fimg.png) ### PCB에 저장되는 정보 1. **프로세스 상태 (Process State)**: 프로세스의 현재 상태. ex) 준비(Ready), 실행(Running), 대기(Waiting) 상태 등 2. **프로세스 우선순위 (Scheduling Information)**: 프로세스의 우선순위, 스케줄링 큐 포인터 등 스케줄링과 관련된 정보 3. **프로그램 카운터 (Program Counter, PC)**: 다음에 실행될 명령어의 주소 4. **CPU 레지스터 (CPU Registers)**: 현재 프로세스가 사용하는 모든 CPU 레지스터의 값을 저장. 범용 레지스터, 데이터 레지스터, 세그먼트 레지스터 등이 포함됨 5. **소유자 정보 (Owner Information)**: 프로세스 소유자의 계정 정보와 CPU 사용 시간 등의 정보를 포함 6. **메모리 관리 정보 (Memory Management Information)**: 프로세스의 메모리 사용 정보를 포함. 페이지 테이블, 세그먼트 테이블, 메모리 경계 레지스터 등이 포함됨 7. **입출력 상태 정보 (I/O Status Information)**: 프로세스에 할당된 입출력 장치, 열린 파일 목록, 입출력 요청 등의 정보를 포함 ### PCB의 사용 흐름 1. **프로세스 생성**: 새로운 프로세스가 생성될 때, 운영체제는 PCB를 생성하고, 프로세스에 대한 초기 정보를 저장한다. 2. **프로세스 실행**: 프로세스가 실행될 때, PCB는 현재 프로세스의 상태를 추적하고 필요한 정보를 제공한다. 3. **프로세스 일시 중지**: 프로세스가 일시중지되면, PCB는 프로세스의 현재 상태와 레지스터 값을 저장한다. 4. **프로세스의 재개**: 프로세스가 재개되면, PCB에 저장된 상태와 레지스터 값이 복원되어 프로세스가 계속 실행된다. 5. **프로세스 종료**: 프로세스가 종료되면, PCB는 운영체제에 의해 해제되고, 해당 자원은 다른 프로세스에게 할당된다. ## PCB와 연관 ### 1. 인터럽트 (Interrupt) 인터럽트는 하드웨어나 소프트웨어에서 발생하는 이벤트로, CPU가 현재 작업을 일시 중지하고 즉각적인 처리가 필요한 작업을 수행하도록 한다. 인터럽트가 발생하면 현재 실행 중인 프로세스의 상태가 PCB에 저장되며, 인터럽트 서비스 루틴이 실행된다. 인터럽트 처리가 완료되면 PCB에서 상태를 복원해 프로세스가 계속 실행된다. > 인터럽트 발생 시, 현재 프로세스의 상태(레지스터, 프로그램 카운터 등)가 PCB에 저장되고, 인터럽트 처리가 완료되면 PCB에서 상태가 복원된다. (컨텍스트 스위칭의 일환이다.) ### 2. 시스템 콜 (System Call) 사용자 프로그램이 운영체제의 커널 기능을 요청하는 것이다. 시스템 콜은 프로세스의 상태를 변경하거나, 자원 할당 등의 작업을 수행할 때 사용된다. 시스템 콜이 수행되면, PCB의 정보가 업데이트 되고, 필요 시 컨텍스트 스위칭이 발생할 수 있다. > PCB와 시스템 콜: 시스템 콜 수행 중, 프로세스의 상태가 PCB에 저장되며, 커널 모드에서 필요한 작업이 수행된다. 작업 완료 후, PCB를 통해 프로세스 상태가 복원된다. ### 3. 스케줄링 CPU 시간을 여러 프로세스에게 효율적으로 분배하는 스케줄링은 어떤 프로세스가 언제 실행될지 결정한다. - **PCB 큐**: 각 프로세스는 자신의 PCB를 가지고 있으며, 연결 리스트나 배열 형태로 저장하여, 프로세스의 상태와 스케줄링을 관리하는 데 사용한다. - **컨텍스트 스위칭**: 스케줄러가 프로세스를 전환할 때, 현재 프로세스의 PCB를 저장하고, 새로운 프로세스의 PCB를 로드하여 실행한다. ## 컨텍스트 스위칭 (Context Switching) 컨텍스트 스위칭은 운영체제가 현재 실행 중인 프로세스의 상태를 저장하고, 새로운 프로세스의 상태를 복원하는 과정이다. 이를 통해 여러 프로세스가 CPU 시간을 공유하며 실행될 수 있다. ![Context Switching](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FLG6V0%2FbtsJ2caaMmf%2FZgYGB3SxWqTLpSIclj3Uk0%2Fimg.png) ### 컨텍스트 스위칭 과정 1. **현재 프로세스의 상태 저장**: CPU는 현재 실행 중인 프로세스의 상태(레지스터, 프로그램 카운터 등)를 PCB에 저장한다. 2. **새로운 프로세스의 PCB 로드**: 스케줄러는 다음 실행할 프로세스를 선택하고, 해당 프로세스의 PCB를 로드한다. 3. **새로운 프로세스의 상태 복원**: CPU는 새로운 프로세스의 상태를 PCB에서 복원한다. 4. **프로세스 실행 재개**: CPU는 프로그램 카운터가 가리키는 주소에서 새로운 프로세스의 명령어 실행을 시작한다. ### 컨텍스트 스위칭의 원인 1. **타임 슬라이스 종료**: 프로세스가 할당된 CPU 시간을 모두 사용한 경우 2. **I/O 요청**: 프로세스가 입출력 작업을 요청할 때 3. **시스템 콜**: 프로세스가 시스템 호출을 수행할 때 4. **인터럽트**: 하드웨어 인터럽트가 발생할 때 ### 컨텍스트 스위칭의 문제점 1. **시간 오버헤드**: 프로세스 상태를 저장하고 복원하는 데 시간이 소요 2. **캐시 오버헤드**: CPU 캐시가 무효화되고 다시 로드되면서 성능 저하가 발생할 수 있음 (프로세스 컨텍스트 스위칭) 3. **복잡성 증가**: 잦은 컨텍스트 스위칭은 시스템의 복잡성을 증가시키고 관리하기 어려울 수 있음 ## 컨텍스트 스위칭의 종류 ### 프로세스 컨텍스트 스위칭 (Process Context Switching) 프로세스 컨텍스트 스위칭은 CPU가 현재 실행 중인 프로세스에서 다른 프로세스로 전환할 때 발생한다. 각 프로세스는 독립적인 메모리 주소 공간을 가지므로, 전환 시 많은 상태 정보를 저장하고 복원해야 한다. #### 특징 1. **독립된 메모리 공간**: 각 프로세스는 자신의 독립된 주소 공간을 가지므로, 전환 시 주소 공간을 완전히 교체해야 한다. 2. **큰 오버헤드**: 메모리 매핑 정보, 페이지 테이블, 파일 디스크립터 등 많은 정보를 저장하고 복원해야 하므로 오버헤드가 크다. 3. **프로세스 독립성**: 프로세스는 서로 독립적이므로, 하나의 프로세스가 다른 프로세스의 메모리에 접근할 수 없다. #### 과정 1. **현재 프로세스의 상태 저장**: 현재 프로세스의 레지스터, 프로그램 카운터, 메모리 매핑 정보 등을 PCB에 저장한다. 2. **새로운 프로세스의 PCB 로드**: 다음 실행할 프로세스의 PCB를 로드한다. 3. **새로운 프로세스의 상태 복원**: 새로운 프로세스의 레지스터, 프로그램 카운터, 메모리 매핑 정보 등을 복원한다. 4. **프로세스 실행 재개**: 프로그램 카운터가 가리키는 주소에서 새로운 프로세스의 실행을 시작한다. #### 특징 1. **시간 오버헤드**: 프로세스 상태를 저장하고 복원하는 데 시간이 소요된다. 2. **캐시 오버헤드**: 프로세스 간 전환 시 CPU 캐시가 무효화되고, 새로운 프로세스의 데이터와 코드가 캐시에 로드되어야 하므로 성능 저하가 발생할 수 있다. 3. **복잡성 증가**: 잦은 프로세스 전환은 시스템의 복잡성을 증가시키고, 관리하기 어려울 수 있다. ### 스레드 컨텍스트 스위칭 (Thread Context Switching) 스레드 컨텍스트 스위칭은 동일한 프로세스 내에서 다른 스레드로 전환할 때 발생한다. 스레드는 프로세스 내에서 실행 흐름의 단위로, 동일한 주소 공간을 공유한다. #### 특징 1. **공유된 메모리 공간**: 스레드는 같은 프로세스의 주소 공간을 공유하므로, 메모리 매핑 정보를 변경할 필요가 없다. 2. **작은 오버헤드**: 레지스터, 프로그램 카운터, 스택 포인터 등의 정보만 저장하고 복원하면 되므로 오버헤드가 작다. 3. **스레드 독립성**: 동일한 프로세스 내에서 스레드 간의 독립성을 보장하면서도 메모리 공간을 공유한다. #### 과정 1. **현재 스레드의 상태 저장**: 현재 스레드의 레지스터, 프로그램 카운터 등을 스레드 컨트롤 블록(TCB)에 저장한다. 2. **새로운 스레드의 TCB 로드**: 다음 실행할 스레드의 TCB를 로드한다. 3. **새로운 스레드의 상태 복원**: 새로운 스레드의 레지스터, 프로그램 카운터 등을 복원한다. 4. **스레드 실행 재개**: 프로그램 카운터가 가리키는 주소에서 새로운 프로세스의 실행을 시작한다. #### 특징 1. **동기화 문제**: 동일한 주소 공간을 공유하기 때문에 스레드 간의 데이터 접근 동기화가 필요하다. 2. **데이터 경쟁**: 적절한 동기화 메커니즘이 없으면 데이터 경쟁이 발생할 수 있다. 3. **캐시 오버헤드**: 상대적으로 적지만, 스레드 간의 데이터 접근 패턴 차이로 인해 일부 캐시 오버헤드가 발생할 수 있다. ## 컨텍스트 스위칭 비교 - **프로세스 컨텍스트 스위칭**은 큰 오버헤드와 캐시 무효화로 인한 성능 저하가 발생하지만, 프로세스 간의 독립성을 보장한다. - **스레드 컨텍스트 스위칭**은 상대적으로 작은 오버헤드로 인해 효율적이지만, 동기화와 데이터 경쟁 문제가 발생할 수도 있다. ## 결론 PCB는 프로세스의 상태를 저장하고 관리하는 데이터 구조이며, 컨텍스트 스위칭은 이러한 PCB를 이용해 프로세스 간 전환을 수행하는 구체적인 과정이다. ",
    "url": "/OS/os_pcb_and_context_switch.html",
    
    "relUrl": "/OS/os_pcb_and_context_switch.html"
  },"76": {
    "doc": "프로세스(Process)란?",
    "title": "프로세스(Process)란?",
    "content": "# 프로세스(Process)란? ## 프로그램 vs 프로세스 `프로그램` 자체로는 아무 일도 할 수 없다. 프로그램은 그저 **하드디스크에 저장되어 있는 하나의 파일**이다. 프로그램이 사용자에게 기능을 제공하기 위해서는, 메모리에 로드되어 프로그램 카운터(PC) 및 관련 자원의 집합을 가진 능동적인 존재로서 동작해야 한다. `프로세스`는 **실행 중인 프로그램**을 의미한다. 프로세스는 **OS에 의해 관리**되며, 독립적으로 실행되고 자원을 할당 받을 수 있는 단위이다. OS는 프로세스들에게 적절히 자원을 분배하여 여러가지 작업을 수행할 수 있게 한다. 프로그램이 프로세스가 되는 과정 1. 사용자가 프로그램을 시작하라는 요청(아이콘을 더블클릭 하는 등)을 보냄 2. OS는 하드 디스크에서 해당 프로그램을 메인 메모리로 로드하면서 필요한 자원을 할당한다. ## 프로세스 구조 메모리 상에 존재하는 프로세스는 아래와 같은 구조를 가진다. `Code와 Data` 영역의 **크기는 고정**되어 있지만, `Heap과 Stack`의 영역은 **런타임에 수시로 변경**된다. | 정의 / 특징 | 저장되는 요소 | --- | --- | --- | **Code** | 실행 가능한 코드 집합. 코드는 컴파일 되어 0과 1로 변환된 기계어가 저장됨 | | **Data** | 프로그램 시작시 초기화. 프로세스가 종료될 때까지 유지됨 | 전역 변수, 정적 변수, 상수 등 | **Heap** | 런타임에 동적으로 메모리에 할당되는 데이터 | 실행 중에 생성되는 인스턴스에 대한 정보 | **Stack** | 함수가 호출되면 stack 공간이 생성. 함수가 종료되면 제거됨 | 지역 변수, 매개 변수, return 주소 등 | ![](/OS/img/os_process_1.png) ## 프로세스 상태 프로세스의 상태에는 5가지가 있다. | **상태** | **설명** |--------------------|-----------------------------------------------------------------------------------------------------------------------------------------------| **생성 (new)** | 프로세스가 생성된 상태. OS의 커널에 PCB 등 생성. 아직 실행되기 위한 자원을 할당 받지 못한 상태 | **준비 (ready)** | 프로세스가 실행을 기다리는 상태. 프로세스가 필요한 자원은 모두 할당 받았지만, CPU를 할당 받지 못한 상태. CPU의 서비스를 받기 위해 Ready Queue에서 대기하고 있는 상태 | **실행 (running)** | 프로세스가 CPU를 할당 받아 실제로 코드를 실행하는 상태 | **대기 (waiting, blocked)** | I/O나 다른 event를 기다리며 프로세스가 멈춰있는 상태. 특정 자원을 사용할 수 있을 때까지 실행을 멈추고, 다시 Ready Queue로 들어감 | **종료 (terminated)** | 프로세스의 실행이 완료되어 종료된 상태. 할당된 자원이 해제되고, 프로세스의 메모리 공간은 OS에 반환됨 | 프로세스 전이도 ![](/OS/img/os_process_2.png) ## **PCB(Process Control Block)** PCB란 **OS가 프로세스를 관리하기 위해 사용하는 데이터 구조**다. 각 프로세스는 하나의 PCB를 가지며, PCB에는 해당 프로세스에 대한 모든 정보가 있다. 프로세스가 생성되면 운영체제는 PCB를 할당하고, 프로세스가 종료되면 해당 PCB를 해제한다. #### PCB에 저장되는 정보 1. 프로세스 식별자(PID) - 프로세스를 구별하는 유일한 식별자 2. 프로세스 상태 - 프로세스의 현재 상태 - 실행, 준비, 대기 등 3. 프로세스 카운터(PC) - 프로세스가 다음에 실행할 명령어(코드)의 주소를 가리키는 포인터 4. 레지스터 - 프로세스가 현재 실행되는 동안 사용되는 레지스터 값들을 저장 - 프로세스가 일시 중단되고 다시 실행 될 때 레지스터 값들을 복원하는 데 사용 5. 스케줄링 정보 - 프로세스의 우선순위, 할당 된 CPU 시간, 스케줄링 알고리즘과 관련된 정보 등 스케줄링에 필요한 정보 6. 메모리 관리 정보 - 프로세스가 사용하는 메모리 공간의 주소 범위, 페이지 테이블, 메모리 할당 정보 등과 같이 메모리 관리에 필요한 정보를 저장 7. 입출력 상태 - 프로세스가 현재 사용 중인 입출력 장치와 관련된 정보 ## 프로세스 레지스터 컴퓨터에서는 프로세스를 처리하기 위한 두 개의 레지스터가 있다. PC(Program Counter)와 SP(Stack Pointer)이며, 프로세스의 실행 및 메모리 관리와 관련된 역할을 한다. ### PC **(Program Counter)** **실행할 명령어의 주소를 가리키는 레지스터**다. 코드를 실행하면 코드가 한 줄씩 내려가며 실행된다. 프로세스는 한 줄을 처리한 뒤 다음에 실행할 코드가 어디인지 알려줘야 실행할 수 있다. 이때, 다음 실행할 코드의 주소를 저장하는 레지스터인 PC가 필요하다. 프로세스는 명령어를 순차적으로 실행하면서 PC 값을 증가시켜 다음에 실행할 명령어를 가리킨다. 따라서 PC는 **프로그램의 흐름을 제어**하는 역할을 한다. 프로세스가 명령어를 실행하다가 분기나 점프 명령어를 만나면, PC의 값을 분기된 주소로 변경하여 해당 명령어를 실행한다. PC는 프로세스가 중단되거나 인터럽트(예외 상황)가 발생했을 때, 현재 실행 중이던 명령어의 주소를 저장하고, 이후 다시 프로세스가 실행되었을 때 주소를 찾아가 **재실행** 시킬 수 있는 역할을 한다. ### SP **(Stack Pointer)** SP는 **현재 실행 중인 프로세스의 스택(Stack)의 최상단을 가리키는 레지스터**다. 즉, SP는 스택 프레임(Stack Frame)의 시작 주소를 가리키며, 스택에 데이터를 저장하거나 불러올 때 사용된다. 함수 호출 시에는 SP가 감소하여 스택에 새로운 스택 프레임(스택 공간)을 생성하고, 함수가 반환되면 SP가 증가하여 이전 스택 프레임으로 돌아간다. SP는 **프로세스의 스택 영역을 관리**하고, Stack Overflow와 같은 문제를 방지하기 위해 **제한된 메모리 영역을 사용**하는 등의 역할을 수행한다. 예를 들어, 재귀함수의 경우, 가장 최근에 호출한 함수 순서대로 Stack에 쌓인다. **가장 최근에 호출된 함수**(최상단 함수)의 위치를 알고 있으면, 어디까지 함수가 호출되어 있는지 프로세스가 알 수 있다. # 출처 [https://medium.com/ioxio/study-os-2-process-update-중-c6fe324329be](https://medium.com/ioxio/study-os-2-process-update-%EC%A4%91-c6fe324329be) https://itwiki.kr/w/%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4_%EC%83%81%ED%83%9C#google_vignette ",
    "url": "/OS/os_process.html",
    
    "relUrl": "/OS/os_process.html"
  },"77": {
    "doc": "Thread",
    "title": "Thread",
    "content": "# Thread ### 스레드란? 스레드는 프로세스의 실행 가능한 가장 작은 작업 단위입니다. 하나의 프로세스는 여러 개의 스레드를 가질 수 있고, 각 스레드는 독립적인 실행 흐름을 가집니다. 스레드는 코드, 데이터, 힙을 스레드끼리 공유합니다. 그 외의 영역은 각각 생성됩니다. ## 스레드의 주요 특징 - 독립적인 실행 흐름: 스레드는 독립적으로 실행됩니다. - 자원 공유: 같은 프로세스 내의 스레드들은 메모리 공간(Code, Static data, Heap)을 공유합니다. - 경량 프로세스: 스레드는 프로세스보다 생성 및 관리 비용이 적습니다. - *컨텍스트 스위칭(Context Switching): CPU가 여러 스레드 간에 작업을 전환할 수 있습니다. ```plain text *컨텍스트 스위칭(Context Swtiching) - CPU가 현재 실행 중인 작업(프로세스 혹은 스레드)의 상태(레지스터, 프로그램 카운터 등)를 저장하고, 새로운 작업의 상태를 로드하여 실행 흐름을 전환하는 과정을 의미합니다. 스레드와 컨텍스트 스위칭의 관계 - 스케줄러가 한 스레드를 멈추고 다른 스레드를 실행시킬 때, 이전 스레드의 상태(레지스터, 프로그램 카운터 등)를 저장하고, 새 스레드의 상태를 복원하는 Context Switching이 일어납니다. - 스레드끼리는 주소 공간을 공유하기에 프로세스 간 전환보다 Context Switching 비용이 작을 수 있지만, 여전히 레지스터나 스택 포인터 등을 저장·복원해야 하므로 오버헤드가 전혀 없지는 않습니다. ``` ### 스레드의 구성 요소 - 스레드 ID - 프로그램 카운터 (PC) - 레지스터 집합: CPU가 사용 중인 레지스터 상태(PC, Stack Pointer, 일반 register 등)는 스레드마다 달라집니다. - 스택: 스레드는 각각 고유한 스택을 가집니다. 지역변수, 함수 호출 기록(call stack) 등이 저장됩니다. ![](/OS/img/os_thread_1.png) # Multithreading ### 멀티스레딩이란? 하나의 프로세스 내에서 여러 개의 스레드를 동시에 실행하는 기술입니다. CPU의 사용률을 극대화하고 프로그램의 효율성을 높이기 위해 사용됩니다. ## 멀티스레딩의 주요 특징 - 동시성 - 두 개 이상의 스레드가 \"거의 동시에\" 실행되는 느낌을 줍니다. - 실제 싱글 코어 환경에서는 빠른 스위칭, 멀티코어 환경에서는 물리적 병렬 처리로 인해 출력이 뒤섞여 나옵니다. - 비결정적 출력 순서 - 실행할 때마다 콘솔에 찍히는 순서가 달라질 수 있습니다. 이는 스케줄러가 각 스레드에 CPU를 할당하는 시점이 매번 다르기 때문입니다. - 스레드 간 독립적 실행 흐름 - 각 스레드는 자신만의 for 루프를 진행하면서, 독립적으로 index를 증가시킵니다. - 이 때, 공유 자원을 건드리지 않으므로 동기화 이슈가 발생하지 않지만 만약 공유 자원을 쓰게 된다면 동기화가 필요해집니다. - 메인 스레드 - main() 메서드를 실행하는 것이 '메인 스레드'인데, t1.join()과 t2.join()을 통해 나머지 스레드가 종료될 때까지 기다렸다가 \"Main thread finished\"를 출력합니다. - 만약 join()을 사용하지 않으면, 메인 스레드가 먼저 종료된 뒤에도 다른 스레드가 뒤이어 계속 동작할 수도 있습니다. ### 멀티스레딩의 자바 코드 - 코드 ```java class MyThread extends Thread { private final String threadName; public MyThread(String name) { this.threadName = name; } @Override public void run() { // 스레드가 실제로 동작하고 있음을 확인하기 위해 숫자를 반복 출력 for (int i = 0; i 자원 활용도 개선 - 멀티스레딩은 Context Switching을 통해 병렬 실행을 구현합니다. ## 스레드 동기화 - Race Condition(경합 상태) - 여러 스레드가 동시 접근하여 값을 읽고 쓸 때, 실행 순서에 따라 결과가 달라지는 문제 - ex. 하나의 변수 `count`를 동시에 업데이트할 때, 덮어쓰기 문제 발생 가능 - 임계 영역(Critical Section) - 공유 자원에 접근하는 부분 - 동시 접근 시 동기화가 적절하게 되어 있지 않으면 Race Condition 발생 - 동기화 기법 - 뮤텍스(Mutex): 한 번에 하나의 스레드만 임계 영역 진입 가능 - 세마포어(Semaphore): 카운터를 통해 동시에 진입할 수 있는 스레드 수를 제한 - 모니터(Monitor): 객체 단위로 lock을 거는 고수준 구조(ex. 자바의 synchronized) - 데드락(Deadlock) - 스레드들이 서로 자원을 기다리면 영원히 대기 상태에 빠지는 현상 - `상호 배제` + `점유 대기` + `비선점` + `순환 대기` 조건이 동시에 만족할 때 발생 ## 참고 자료 1. 면접을 위한 CS 전공지식 노트, 주홍철 2. Operating System Concepts, Abraham Silberschartz ",
    "url": "/OS/os_thread.html",
    
    "relUrl": "/OS/os_thread.html"
  },"78": {
    "doc": "운영체제",
    "title": "운영체제",
    "content": "# 운영체제 - 컴퓨터 구조 & 운영체제 - 메모리 - 물리 메모리 & 가상 메모리 & 페이징 - 프로세스 & 스레드 - 프로세스 - PCB & Context Switching - 멀티프로세싱 - 스레드 & 멀티스레딩 - 공유 자원 & 임계 영역(Semaphore & Mutex) - 교착상태(Deadlock) - CPU Scheduling - 선점 & 비선점 - Blocking, Non-Blocking & Synchronous & Asynchronous ",
    "url": "/OS/readme_OS.html",
    
    "relUrl": "/OS/readme_OS.html"
  },"79": {
    "doc": "GraphQL",
    "title": "GraphQL",
    "content": "# GraphQL - 새로운 API 표준입니다. - 특정한 데이터베이스나 특정한 스토리지 엔진과 관계되어 있지 않습니다. - 페이스북에서 개발 및 오픈소스화 되었습니다. ## REST vs GraphQL ### REST 여러 개의 엔드포인트가 있고, 각 엔드포인트에 접근해 데이터를 수집합니다. 필요한 데이터를 가져오기 위해 n번의 요청을 보내야하고, 불필요한 추가 정보를 반환하기 때문에 과도한 페칭이 발생합니다. ![REST API](/Web/img/web_graphql_rest.png) _REST 흐름, 출처: [GraphQL 문서](https://www.howtographql.com/basics/1-graphql-is-the-better-rest/)_ 1. `/users/`: 초기 사용자 데이터를 가져오는 엔드포인트 2. `/users//posts`: 사용자의 모든 게시물을 반환하는 엔드포인트 3. `/users//followers`: 사용자별 팔로워 목록을 반환하는 엔드포인트 ### GraphQL 구체적인 데이터 요구 사항을 포함하는 단일 쿼리를 GraphQL 서버로 전송하고, 서버는 요구사항에 맞는 JSON 객체를 응답합니다. ![GraphQL](/Web/img/web_graphql_rest.png) _GraphQL 흐름, 출처: [GraphQL 문서](https://www.howtographql.com/basics/1-graphql-is-the-better-rest/)_ ### 비교 ![비교](/Web/img/web_graphql_rest_graphql.png) _REST와 GraphQL 비교, 출처: [카카오 기술 블로그 - GraphQL 개념잡기](https://tech.kakao.com/posts/364)_ - 오버페칭(Overfetching)해결 - REST에서는 특정 엔드포인트에서 일부 데이터만 필요해도 전부 다 받아야한다. - graphQL은 필요한 필드만 명시해 요청이 가능하다. - 언더페칭(Underfetching)과 N+1 해결 - REST에서는 각 사용자에 대한 상세 데이터 요청시 사용자 목록 조회 1번과 사용자 상세 데이터에 대한 요청 N번인 N+1번만큼 요청한다. - graphQL은 한번으로 조회 가능하다. ## GraphQL의 핵심 개념 ### 처리 흐름 ![처리 흐름](/Web/img/web_graphql_flow.png) _다이어그램, 출처:[카카오 기술 블로그 - GraphQL 개념잡기](https://tech.kakao.com/posts/364)_ 1. GraphQL Query: 클라이언트가 GraphQL 쿼리를 서버에 전송합니다. 이 쿼리는 필요한 데이터의 구조와 필드를 정확히 명시합니다. 2. Query Language Processor: 쿼리 언어 프로세서는 받은 쿼리를 파싱하고 유효성을 검사합니다. 이 단계에서 쿼리의 문법적 오류나 스키마와의 불일치를 확인합니다. 3. GraphQL Resolver: 개발자가 구현해야 하는 부분으로, 실제 데이터를 가져오는 로직이 포함됩니다. 리졸버는 다양한 데이터 소스(오른쪽에 표시된)와 연결하여 요청된 데이터를 검색합니다: - RDB (관계형 데이터베이스) - NoSQL 데이터베이스 - In-memory DB (메모리 내 데이터베이스) - REST/SOAP API 등 다른 웹 서비스 4. Output (JSON): 최종적으로 처리된 데이터는 JSON 형식으로 클라이언트에 반환됩니다. ### 쿼리 & 뮤테이션 gql에서는 굳이 쿼리와 뮤테이션을 나누는데 내부적으로 들어가면 사실상 이 둘은 별 차이가 없습니다. 쿼리는 데이터를 읽는데® 사용하고, 뮤테이션은 데이터를 변조(CUD) 하는데 사용한다는 개념 적인 규약을 정해 놓은 것 뿐입니다. > - 쿼리: 데이터를 읽어오는 요청 > - 뮤테이션: 데이터를 변경하는 요청 #### 쿼리 데이터를 읽어오는 요청과 그에 대한 응답의 예시를 보며 이해합니다. - 기본 요청 - 요청 ```graphQL { hero { name } } ``` - 결과 ```json { \"data\": { \"hero\": { \"name\": \"R2-D2\" } } } ``` - 인자: 특정 필드의 값을 지정 - 요청: id가 1000인 사람의 이름과 키를 조회 ```graphQL { human(id: \"1000\") { name # 키는 열거형 타입으로 사용 height(unit: METER) } } ``` - 결과 ```json { \"data\": { \"human\": { \"name\": \"Luke Skywalker\", \"height\": 1.72 } } } ``` - 별칭: 결과에 필드명을 별칭으로 지정 - 요청: EMPIRE 에피스드의 영웅과 JEDI 에피소드의 영웅을 조회 ```graphQL { empireHero: hero(episode: EMPIRE) { # empireHero이라는 별칭 사용 name } jediHero: hero(episode: JEDI) { # jediHero이라는 별칭 사용 name } } ``` - 결과 ```json { \"data\": { \"empireHero\": { # 지정한 필드명으로 나옴 \"name\": \"Luke Skywalker\" }, \"jediHero\": { \"name\": \"R2-D2\" } } } ``` - 프래그먼트: 재사용 가능한 필드 묶음을 선언해 사용 - 요청 ```graphql { leftComparison: hero(episode: EMPIRE) { ...comparisonFields } rightComparison: hero(episode: JEDI) { # rightComparison이라는 별칭 사용 ...comparisonFields # ...을 붙여서 프래그먼트를 사용 } } fragment comparisonFields on Character { # 재사용 가능한 필드 묶음을 선언 name appearsIn friends { name } } ``` - 응답 ```json { \"data\": { \"leftComparison\": { \"name\": \"Luke Skywalker\", \"appearsIn\": [ \"NEWHOPE\", \"EMPIRE\", \"JEDI\" ], \"friends\": [ { \"name\": \"Han Solo\" }, { \"name\": \"Leia Organa\" }, { \"name\": \"C-3PO\" }, { \"name\": \"R2-D2\" } ] }, \"rightComparison\": { \"name\": \"R2-D2\", \"appearsIn\": [ \"NEWHOPE\", \"EMPIRE\", \"JEDI\" ], \"friends\": [ { \"name\": \"Luke Skywalker\" }, { \"name\": \"Han Solo\" }, { \"name\": \"Leia Organa\" } ] } } } ``` - 작업 이름: 작업의 이름을 지정해 명시 - 요청 ```graphql query HeroNameAndFriends { # HeroNameAndFriends라는 작업이름 지정, query는 작업 타입을 의미 hero { name friends { name } } } ``` - 응답 ```json { \"data\": { \"hero\": { \"name\": \"R2-D2\", \"friends\": [ { \"name\": \"Luke Skywalker\" }, { \"name\": \"Han Solo\" }, { \"name\": \"Leia Organa\" } ] } } } ``` - 변수: 작성한 쿼리에 변수를 넣어, 쿼리를 동적으로 사용 - 요청: ```graphql # 쿼리 정의 query HeroNameAndFriends($episode: Episode) { # 외부에서 전달받을 인수를 '$'을 붙여 지정, 타입은 Episode 으로 지정 hero(episode: $episode) { name friends { name } } } # 쿼리에 대한 변수 { \"episode\": \"JEDI\" } ``` - 응답 ```json { \"data\": { \"hero\": { \"name\": \"R2-D2\", \"friends\": [ { \"name\": \"Luke Skywalker\" }, { \"name\": \"Han Solo\" }, { \"name\": \"Leia Organa\" } ] } } } ``` - 지시어 - 요청 - 응답 #### 뮤테이션 데이터를 변경하는 요청의 예시와 그에 대한 응답 예시를 통해 이해합니다. - 기본 요청 - 요청 ```graphql mutation CreateReviewForEpisode($ep: Episode!, $review: ReviewInput!) { createReview(episode: $ep, review: $review) { stars commentary } } { \"ep\": \"JEDI\", \"review\": { \"stars\": 5, \"commentary\": \"This is a great movie!\" } } ``` - 응답 ```json { \"data\": { \"createReview\": { \"stars\": 5, \"commentary\": \"This is a great movie!\" } } } ``` ### 스키마와 타입 - 스키마는 API의 기능을 명시하고, 클라이언트가 데이터를 요청하는 방식을 정의합니다. - GraphQL은 API 스키마를 정의하기 위해 자체 타입 시스템을 사용하며, 이때 사용하는 문법을 스키마 정의 언어(SDL: Schema Definition Language)라고 합니다. - GraphQL 스키마 언어(SDL)를 사용하여 쿼리 가능한 데이터의 구조와 타입을 정의합니다. #### 데이터 타입 - 기본 타입: 스칼라 타입 - Int: 부호가 있는 32비트 정수. - Float: 부호가 있는 부동소수점 값. - String: UTF-8 문자열. - Boolean: true 또는 false. - ID: ID 스칼라 타입은 객체를 다시 요청하거나 캐시의 키로써 자주 사용되는 고유 식별자를 나타냅니다. ID 타입은 String 과 같은 방법으로 직렬화되지만, ID 로 정의하는 것은 사람이 읽을 수 있도록 하는 의도가 아니라는 것을 의미합니다. - 객체 타입(object) ```graphql type Character { name: String! appearsIn: [Episode]! } ``` - `Character`: GraphQL 객체 타입 입니다. 즉, 필드가 있는 타입입니다. 스키마의 대부분의 타입은 객체 타입입니다. - `name` - `Character` 타입의 필드 - String 타입으로 내장된 스칼라 타입 중 하나입니다. - `!`: 필드가 non-nullable임을 의미합니다. - `appearsIn` - `Character` 타입의 필드 - `!`: 필드가 non-nullable 임을 의미합니다. - `[]`: 필드가 배열(array)임을 나타냅니다. - 열거형 타입(enum): 타입의 인자가 허용된 값 중 하나임 ```graphql enum Episode { NEWHOPE EMPIRE JEDI } ``` - 인터페이스(interface): 구현하기 위해 타입이 포함해야하는 특정 필드들을 포함하는 추상 타입, 공통 필드를 정의하는 추상 타입 - 정의 ```graphql interface Character { id: ID! name: String! friends: [Character] appearsIn: [Episode]! } ``` - 사용 예시 ```graphql type Human implements Character { id: ID! name: String! friends: [Character] appearsIn: [Episode]! starships: [Starship] totalCredits: Int } type Droid implements Character { id: ID! name: String! friends: [Character] appearsIn: [Episode]! primaryFunction: String } ``` - 유니온 타입(union): 인터페이스와 매우 유사하지만, 타입 간에 공통 필드는 없습니다. ```graphql union SearchResult = Human | Droid | Starship ``` - enum은 나열한 값 중 하나를 선택해야하고, interface는 공통 필드가 있어야 한다. - 유니온은 이와 달리 단순히 값을 묶는 의미로, 3개는 각각 다른 필드를 가질 수 있으며 결과 값으로 3개의 값 중 하나를 **반환 하겠다**는 의미 - 입력 타입(input type): 객체 타입과 같지만, `type`이 아닌 `input`을 사용하는 점이 다릅니다. - 정의 ```graphql input ReviewInput { stars: Int! commentary: String } ``` - 사용 ```graphql mutation CreateReviewForEpisode($ep: Episode!, $review: ReviewInput!) { createReview(episode: $ep, review: $review) { stars commentary } } { \"ep\": \"JEDI\", \"review\": { \"stars\": 5, \"commentary\": \"This is a great movie!\" } } ``` ```json { \"data\": { \"createReview\": { \"stars\": 5, \"commentary\": \"This is a great movie!\" } } } ``` #### 요청 타입 GraphQL 서비스는 반드시 `Query` 타입을 포함하며, `Mutation` 타입은 선택적으로 포함할 수 있습니다. 이 타입들은 일반적인 객체 타입과 구조는 같지만, 모든 GraphQL 요청의 진입점(entry point) 역할을 하므로 특별한 의미를 가집니다. - Query: 읽기 전용 요청 - Mutation: 쓰기/변경 요청 - Subscription: 실시간 데이터 스트림 ## GraphQL 아키텍처 구성 방식 ### 연결된 데이터베이스가 있는 GraphQL 서버 ![일반적인 방법](/Web/img/web_graphql_db.png) _일반적인 방법, 출처:[GraphQL 문서](https://www.howtographql.com/basics/3-big-picture/)_ 쿼리 해결(resolving) 1. 클라이언트로부터 쿼리가 도착 2. 서버는 해당 쿼리의 페이로드를 해석 3. 데이터베이스에서 필요한 정보를 조회 특징 - GraphQL은 전송 계층에 구애받지 않기 때문에, 모든 네트워크 프로토콜(TCP, 웹소켓 등)과 함께 사용할 수 있습니다. - 데이터베이스나 데이터 저장 형식에 구애받지 않기 떄문에, Nosql DB를 사용할 수 있습니다. ### 기존 시스템을 통합하는 GraphQL 계층 단일하고 일관된 GraphQL API를 기반으로 여러 기존 시스템을 통합하는 방식 실제 서비스는 여러 개인데, GraphQL이라는 단인 API로 감싸서 간단하게 사용하도록 만듬 ![레거시 통합](/Web/img/web_graphql_legacy.png) _여러 서비스 통합, 출처:[GraphQL 문서](https://www.howtographql.com/basics/3-big-picture/)_ 마이크로서비스, 레거시 인프라 또는 타사 API와 같은 기존 시스템의 복잡성을 단일 GraphQL 인터페이스 뒤에 숨길 수 있습니다. ### 하이브리드 방식 (DB + 기존 시스템 통합) 위에서 설명한 두 가지 접근 방식을 결합하는 방식으로, 연결된 DB가 있지만 다른 시스템과도 통신하는 서버를 만듬 ![하이브리드 방식](/Web/img/web_graphql_db_legacy.png) _하이브리드 방식, 출처:[GraphQL 문서](https://www.howtographql.com/basics/3-big-picture/)_ ## 리졸버(Resolver) 이렇게 GraphQL이 유연할 수 있는 이유로, 요청을 보내면 **각 필드마다 실행되는 함수**를 리졸버 함수라고 합니다. ![리졸버](/Web/img/web_graphql_resolver.png) _요청(좌), 실행되는 리졸버(우), 출처:[GraphQL 문서](https://www.howtographql.com/basics/3-big-picture/)_ ### 연쇄 호출 - 객체 타입을 조회할 때마다 그 객체의 필드를 다시 조회하는 방식으로 동작합니다. - 쿼리의 구조를 따라 DFS(Depth First Search) 방식으로 리졸버를 호출됩니다. - 이 방식은 마치 그래프 구조를 탐색하는 것과 유사하기 때문에 \"Graph\"QL이라는 이름과도 잘 어울립니다. 1. user(id: 123)를 조회: user 리졸버가 실행, User 반환 2. name 필드 조회: 스칼라 타입 -> 호출 종료 3. followers 필드 조회: 객체 타입 -> User[] 반환 ->다시 followers 리졸버 호출 4. followers.name과 followers.age 조회: 배열 내 객체마다 필드 조회하는 리졸버 실행, 스칼라 값 -> 리졸버 종료 # 출처 - [GraphQL 문서](https://graphql-kr.github.io/learn/) - [카카오 기술 블로그 - GraphQL 개념잡기](https://tech.kakao.com/posts/364) ",
    "url": "/Web/graphql.html",
    
    "relUrl": "/Web/graphql.html"
  },"80": {
    "doc": "웹",
    "title": "웹",
    "content": "# 웹 - RESTful API - JWT 토큰 - Web Server & WAS - Sync / Async - Blocking / Non-Blocking - OAuth - CDN - SEO - GraphQL - SSR 과 CSR - CSRF ",
    "url": "/Web/readme_Web.html",
    
    "relUrl": "/Web/readme_Web.html"
  },"81": {
    "doc": "RESTful API 설계 원칙과 네이밍 컨벤션",
    "title": "RESTful API 설계 원칙과 네이밍 컨벤션",
    "content": "# RESTful API 설계 원칙과 네이밍 컨벤션 ## 1. RESTful API란? **RESTful API**는 REST(Representational State Transfer) 아키텍처 스타일을 따르는 API입니다. HTTP 프로토콜을 기반으로 자원(Resource)을 URI로 식별하고, HTTP 메서드를 통해 자원에 대한 행위(CRUD)를 정의합니다. ### REST의 핵심 개념 - **자원(Resource)**: URI로 식별되는 객체 (예: `/users`) - **행위(Verb)**: HTTP Method로 표현 (GET, POST, PUT, DELETE) - **표현(Representation)**: JSON, XML 등으로 자원의 상태 전달 - **무상태성(Stateless)**: 요청 간 상태를 서버에 저장하지 않음 ## 2. RESTful API 설계 원칙 ### 2.1 자원은 URI로 고유하게 식별 - URI는 자원의 위치가 아닌 **식별자** 역할 - 예시: - `/users` → 사용자 컬렉션 - `/users/1` → 특정 사용자 ### 2.2 HTTP 메서드를 목적에 맞게 사용 | 메서드 | 목적 | 설명 |----------|------------------|-----------------------------------| GET | 조회 (Read) | 자원 조회. 멱등성 O, | POST | 생성 (Create) | 새 자원 생성. 멱등성 X | PUT | 전체 수정 (Update)| 자원 전체 수정. 멱등성 O | PATCH | 부분 수정 | 자원 일부 수정. 멱등성 X | DELETE | 삭제 (Delete) | 자원 삭제. 멱등성 O | > 💡 멱등성: 동일 요청을 여러 번 보내도 결과가 같음 ### 2.3 무상태(Stateless) 구조 - 각 요청은 **독립적**이어야 함 - 서버는 클라이언트의 이전 상태를 **저장하지 않음** - 인증은 `Authorization` 헤더에 토큰(JWT 등)으로 전달 ### 2.4 일관된 자원 표현 사용 - 주로 JSON 형식을 사용 - 응답 구조는 통일성 있게 유지 - 클라이언트는 `Accept` 헤더로 원하는 포맷 지정 가능 #### 예시 응답(JSON) ```json { \"id\": 1, \"name\": \"Seunga\", \"email\": \"seunga@example.com\" } ``` ## 3. RESTful API 네이밍 컨벤션 ### 3.1 자원명은 **명사**로 표현 - 자원의 의미가 명확하게 드러나야 함 - `/getUser`(X) → `/users` (O) ### 3.2 자원은 **복수형**으로 사용 | 패턴 | 예시 | 설명 |--------------------|--------------------|-------------------------| 복수 자원 조회 | `/users` | 사용자 목록 조회 | 단일 자원 접근 | `/users/1` | ID가 1인 사용자 조회 | 하위 자원 조회 | `/users/1/posts` | 사용자 1의 게시글 목록 | > 💡셀 수 없는 명사(data, info 등)는 단수 그대로 사용 ### 3.3 소문자 사용 - URI는 모두 **소문자**로 구성 - (O) `/user-posts` - (X) `/UserPosts` ### 3.4 단어 구분은 하이픈(-) 사용 - 가독성과 URI 표준을 위해 하이픈 사용 - (O) `/user-posts` - (X) `/userPosts`, `/user_posts` ### 3.5 계층 구조로 관계 표현 - 자원 간 포함 관계를 계층 구조로 표현 - `/users/1/posts/2/comments` ### 3.6 쿼리 파라미터는 필터링, 정렬 등에 사용 - `GET /users?page=2&limit=20&sort=name` ## 4. 응답 및 상태 코드 규칙 ### 4.1 HTTP 상태 코드 | 상태 코드 | 의미 |-----------|--------------------------------| 200 OK | 요청 성공 | 201 Created | 자원 생성 성공 | 204 No Content | 요청 성공, 본문 없음 | 400 Bad Request | 잘못된 요청 | 401 Unauthorized | 인증 실패 | 403 Forbidden | 권한 없음 | 404 Not Found | 자원 없음 | 500 Internal Server Error | 서버 내부 오류 | ### 4.2 에러 응답 포맷 예시 ```json { \"status\": 400, \"message\": \"Invalid request parameter\", \"errorCode\": \"ERR_BAD_REQUEST\" } ``` ## 5. 결론 RESTful API는 표준 HTTP 프로토콜을 바탕으로 자원 중심의 설계를 통해 API를 일관성 있게, 예측 가능하게, 확장 가능하게 만듭니다. > 💡RESTful하게 설계하되, 상황에 따라 유연하게 적용하는 것이 가장 중요합니다. ",
    "url": "/Web/restful_api.html",
    
    "relUrl": "/Web/restful_api.html"
  },"82": {
    "doc": "CSR, SSR 의 등장 배경",
    "title": "CSR, SSR 의 등장 배경",
    "content": "# CSR, SSR 의 등장 배경 ## MPA ### 정적인 초창기 웹 초창기의 웹은 텍스트 중심의 단순 문서에 불과했다. 데이터의 연결과 탐색이 필요하다면 하이퍼텍스트(하이퍼링크를 포함) 를 사용하였다. 이러한 초창기 웹은 MPA(Multiple Page Application) 으로 구현되어있다. MPA 는 다중 페이지로 이뤄져있어 변경사항이 있을 때마다 서버로 페이지를 요청한다. ### MPA의 단점 하지만, 페이지를 요청하여 이동할 때마다 서버로부터 새로운 Html 을 받을 때 새로고침이 발생하는 문제가 있었다. 또한, 웹에서 보여주는 데이터에 단순한 텍스트 뿐아니라 사진, 영상, 유저 인터랙션과 같은 복잡한 요소들이 추가되어 성능 이슈가 발생하였다. ## SPA ### AJAX 의 등장 이러한 문제를 해결하기위해 등장한 기술이 AJAX 이다. AJAX 는 새로운 데이터가 필요할 때 새로운 페이지를 서버에 요청하는 것이아니라, 필요한 데이터만 리로드할 수 있도록 도와준다. 이러한 AJAX을 활용하여 웹을 구현하는 방식으로 SPA(Single Page Application) 가 등장했다. SPA는 단일 페이지로 이뤄져 있어 갱신될 부분에 대해서만 데이터를 요청한다. 이러한 방식은 MPA 의 문제점중 하나였던 새로고침이 발생하지 않아 사용자 경험에 좀더 유리하다는 점에서 이점이 있다. ![](/Web/img/web_csr_ssr_mpaandspa.png) # CSR 렌더링이 클라이언트(브라우저)에서 발생하는 것을 의미한다. - 서버 : 빈 html 제공. - 클라이언트 : js 를 실행해, DOM 을 생성해 렌더링. ## 동작 흐름 ![](/Web/img/web_csr_ssr_csr_process.png) 1. 사용자가 웹에 접속. 2. 브라우저가 서버에 리소스 요청. 3. 서버는 js, css 파일을 불러올 수 있는 빈 html 을 응답. 4. 브라우저는 js 파일을 다운로드 받음. 5. js 를 이용해 DOM 을 생성해 클라이언트에게 페이지 제공됨. ## 특징 - 초기 페이지 로드 이후, 속도가 빠르다. 초기 로딩 때 모든 번들을 다운 받고, 그 이후에는 필요한 데이터만 서버에 요청하면 되기 때문이다. - FCP(First Contentful Paint) 까지 오래 걸린다. js 를 서버로 부터 다운로드 받고, 동적으로 DOM 을 생성 할 때까지 의 시간을 사용자는 모두 기다려야 하기 때문이다. > _**최초 콘텐츠풀 페인트(FCP)** 는 브라우저가 DOM에서 첫 번째 콘텐츠 비트를 렌더링하여, 페이지가 실제로 로드되고 있다는 첫 번째 피드백을 사용자에게 제공하는 경우입니다. FCP 이후에 사용자는 웹 페이지가 로드되어 있다는 것을 느낄 수 있습니다._ - SEO(검색 엔진 최적화) 에 불리하다. 크롤러는 html 을 읽어 검색 가능한 색인을 만들어 내는 방식으로 작동하는데, CSR 의 html 은 텅 비어있는 상태이기 때문이다. ## 사용하기 적합한 서비스 - 사용자와의 상호작용이 많은 서비스. - 굳이 검색 엔진에 노출 시킬 필요가 없거나, 개인적인 정보에 관한 데이터가 많은 서비스. # SSR 서버측에서 렌더링 될 페이지를 클라이언트로 보내주는 것을 의미한다. - 서버 : 미리 렌더링 된 html 을 생성. - 브라우저 : js 를 실행 후 정적인 페이지를 상호작용 가능한 상태로 제공. ## 유형 - 요청 즉시 html 파일을 동적으로 만드는 경우 - 정적인 페이지를 미리 만들어두어 제공하는 경우 ## 동작 흐름 ![](/Web/img/web_csr_ssr_ssr_process.png) 1. 사용자가 웹에 접속. 2. 브라우저가 서버에 리소스 요청. 3. 서버는 js, css 가 포함되고 초기 컨텐츠가 로딩된 html 을 생성하여 응답. 4. 브라우저는 js 파일을 다운로드 받음. 5. 사용자는 상호작용 불가한 정적인 페이지를 볼 수 있음. 6. 브라우저는 javascript 파일들을 실행시키고(이벤트리스너 할당 등), 정적이었던 html 페이지를 상호작용 가능한 페이지 제공. ## 특징 - 초기 구동 속도가 빠르다. 정확히 말하면 FCP (First Contentful Paint)이 빠르다. 이유는, 서버가 초기 콘텐츠가 로딩된 상태인 html 을 응답하기 때문에, 사용자는 웹에 접속하고 얼마 지나지 않아 정적인 페이지를 먼저 확인할 수 있다. - SEO 에 유리하다. 모든 데이터가 이미 html 에 담겨진 채로 브라우저에 전달되기 때문이다. - 사용자가 페이지를 보는 시점과, 사용할 수 있는 시점이 다르다. 다른 표현으로 TBT (Total Blocking Time) 이 발생한다고도 한다. 이는 초기 콘텐츠가 로딩된 html 을 사용자가 받아 보고, 이후 js 가 실행되어 인터랙티브한 페이지가 되기 전까지의 시간 이 발생하는 것을 의미한다. (FCP 에서 TTI(Time To Interactive) 까지의 시간) ## 사용하기 적합한 서비스 - 초기 로딩 속도가 중요한 서비스 - 검색 유입이 중요한 서비스(e.g. 이커머스) ",
    "url": "/Web/web_csr_ssr.html",
    
    "relUrl": "/Web/web_csr_ssr.html"
  },"83": {
    "doc": "CSRF(Cross-site request forgery, 사이트 간 요청 위조)",
    "title": "CSRF(Cross-site request forgery, 사이트 간 요청 위조)",
    "content": "# CSRF(Cross-site request forgery, 사이트 간 요청 위조) > 웹 사이트 취약점 공격 방법 중 하나로, 사용자가 자신의 의지와는 무관하게 공격자가 의도한 행위(수정, 삭제, 등록 등)를 특정 웹사이트에 요청하게 하는 공격을 말한다. _출처:[위키디피아 - 사이트 간 요청 위조](https://ko.wikipedia.org/wiki/%EC%82%AC%EC%9D%B4%ED%8A%B8_%EA%B0%84_%EC%9A%94%EC%B2%AD_%EC%9C%84%EC%A1%B0)_ ## 공격하는 방법 ![공격 방법](/Web/img/web_csrf_example1.png) 1. 유저가 브라우저를 통해 A사이트에 접속해 로그인 2. A사이트는 로그인 과정 이후 유저를 식별하기 위해, 쿠키에 유저 식별 정보를 저장 3. 이후 유저가 브라우저를 통해 B사이트에 접속 4. B사이트에서는 유저 몰래 A사이트에 요청을 보냄 5. A사이트에서는 이 요청이 유저가 보낸 요청이라고 생각해 동작 ### 왜 가능할까? 이유는 쿠키! 이러한 공격 방법이 가능한 이유는 쿠키의 특성 때문입니다. > HTTP 쿠키(웹 쿠키, 브라우저 쿠키)란? > - 서버가 사용자의 웹 브라우저에 전송하는 작은 데이터 조각입니다. > - 브라우저는 그 데이터 조각들을 저장해 놓았다가, **동일한 서버에 재 요청 시 저장된 데이터를 함께 전송**합니다. _출처: [MDN - HTTP 쿠키](https://developer.mozilla.org/ko/docs/Web/HTTP/Guides/Cookies)_ > Browsing context > - 브라우징 컨텍스트는 브라우저가 문서를 표시하는 환경입니다. > - e.g. 탭, 창, iframe, 팝업 etc > - 브라우징 컨텍스트 그룹은 기록, 쿠키, 저장 메커니즘 등과 같은 공통 컨텍스트를 공유하는 브라우징 컨텍스트 들의 집합입니다. _출처: [MDN - Browsing context](https://developer.mozilla.org/en-US/docs/Glossary/Browsing_context)_ 이 내용에서 요점만 요약하자면, - 쿠키는 동일한 서버에 재요청시 **저장된 내용을 함께 전송**한다. - 쿠키가 공유되는 **범위는 같은 브라우저의 탭, 창, 팝업 등을 포함**한다. 다시 예시 이해하기 1. 크롬 브라우저를 이용해 A 사이트에 접속 후 로그인 2. A 사이트의 로그인 정보가 쿠키로 저장 3. 같은 브라우저를 이용해 B 사이트 접속 4. B 사이트에서 A 사이트에 요청 - **유저가 A 사이트에 요청을 보내는 것처럼 행동 = 공격용 html 등을 이용** - e.g. 도착지를 변경하는 요청을 보내는 예시 ```html ``` - 이용자가 공격용 페이지를 열면, 브라우저는 이미지 파일을 받아오기 위해 공격용 URL을 실행 5. A 사이트는 로그인 정보를 같이 받게 되고, 유저가 요청한 것으로 인식해 요청의 내용을 수행 - 유저는 이 사실을 모름 ### XSS(Cross-Site Scripting)와의 차이 > XSS(Cross-Site Scripting) > - 공격자가 웹사이트에 악성 클라이언트 사이드 코드를 삽입할 수 있도록 하는 보안 취약점 공격입니다. > - 이 악성 코드는 피해자에 의해 실행되며 공격자가 접근 제어를 우회하고 사용자로 위장할 수 있게 만들어 줍니다. _출처: [MDN - XSS](https://developer.mozilla.org/ko/docs/Glossary/Cross-site_scripting)_ XSS는 다양한 공격이 가능하지만, 여기서는 CSRF와 비슷한 공격을 한다고 했을 떄 어떤 차이가 있는지 알아보겠습니다. ![xss 예시](/Web/img/web_csrf_xss_example1.png) ![xss 예시](/Web/img/web_csrf_xss_example2.png) 1. 유저가 브라우저를 통해 A사이트에 접속해 로그인 2. A사이트는 로그인 과정 이후 유저를 식별하기 위해, 쿠키에 유저 식별 정보를 저장 3. 유저가 브라우저를 통해 B사이트에 접속 4. B사이트에서는 유저 몰래 쿠키에 있는 정보를 탈취해 다른 곳으로 전송 5. 탈취한 정보를 이용해 A사이트에 요청 6. A사이트에서는 이 요청이 유저가 보낸 요청이라고 생각해 동작 차이점 - CSRF는 쿠키에 저장된 정보를 **직접 접근하지 않고**, 브라우저를 이용해 공격한다. - XSS에서는 쿠키에 저장된 **정보를 가져와**, 이를 이용해 공격한다. ### 공격 예시 - 토렌트 클라이언트가 실행되어있는 상태에서 특정 파일을 자동으로 다운로드하는 요청을 보내, 다운로드 되도록 - 이메일에 HTML 태그를 포함해서 전송해, 이메일을 열자마자 특정 요청을 보내도록함 - 포럼 글에 댓글로 html태그를 넣어 특정 요청을 보내도록 함 ## 대응 방법 이를 해결하기 위한 방법으로는 여러가지 방법이 있고, 조합해서 사용할 수 있습니다. 1. CSRF 토큰(임의의 값) 이용 ![대응방법](/Web/img/web_csrf_prevention.png) 1. 임의의 값을 발급해주고, 요청헤더에 포함해 보냄 -> 요청 헤더의 값이 서버가 발급한 값이 맞는지 확인 - Stateful: 서버에서 자신이 발급한 값이 맞는지 알고 있어야 함 2. 브라우저에서 임의의 값을 같이 쿠키에 저장하고, 프론트에서는 이를 요청헤더에 포함해 보냄 -> 서버에서는 쿠키의 값과 헤더의 값이 같은지 비교 - Stateless: 쿠키는 브라우저가 자동으로 같이 보내지만 헤더에 값을 자동으로 추가하지 않음을 이용한 방식으로, 서버에서는 두 개의 값이 같은지만 알면 됨 2. origin/refer 이용: 서버에서 요청을 보낼 수 있는 origin/refer를 지정함으로써, 그 외에서 보낸 요청은 처리하지 않도록 함 - origin/refer의 값은 브라우저가 요청을 보낼 때 설정하는 값 - B사이트에서 브라우저를 이용해 A사이트에 요청을 보낸다면 origin/refer은 B사이트로 설정되어 있음 > Origin과 Refer > 둘 다 요청이 **어디서 시작된 것인지에 대한 정보를 담고, 브라우저에서 자동으로 설정하고 변경이 불가능**합니다. > - Refer > - 전체 URL 포함합니다. (e.g. `https://developer.mozilla.org/ko/docs/Web/JavaScript`, `https://example.com/page?q=123`) > - 일부 브라우저, 확장 프로그램, 보안 설정에서 Referer를 생략하거나 마스킹합니다. > - Origin > - 프로토콜 + 호스트 + 포트까지만 포함합니다. (e.g. `https://developer.mozilla.org`) > - 보통은 GET에서는 포함되지 않습니다. _출처: [MDN - Refer](https://developer.mozilla.org/ko/docs/Web/HTTP/Reference/Headers/Referer), [MDN - Origin](https://developer.mozilla.org/ko/docs/Web/HTTP/Reference/Headers/Origin)_ 3. SameSite 설정: 서버에서 쿠키로 인증 정보를 저장할 때, 이 쿠키가 자동으로 전송되는 범위를 설정하는 것 - 출처(origin)나 요청 메서드의 타입에 따라 쿠키를 보낼지 안보낼지를 설정함 - 종류 - Strict: 출처가 다르면 안보냄 - Lax: 출처가 다를때는 GET 요청에만 보냄(기본값으로 설정) - None: 출처나 요청 메서드를 구분하지 않고 항상 보냄 # 출처 - [위키디피아 - 사이트 간 요청 위조](https://en.wikipedia.org/wiki/Cross-site_request_forgery) - [MDN - HTTP 쿠키](https://developer.mozilla.org/ko/docs/Web/HTTP/Guides/Cookies) - [MDN - Browsing context](https://developer.mozilla.org/en-US/docs/Glossary/Browsing_context) - [MDN - XSS](https://developer.mozilla.org/ko/docs/Glossary/Cross-site_scripting) - [MDN - Refer](https://developer.mozilla.org/ko/docs/Web/HTTP/Reference/Headers/Referer) - [MDN - Origin](https://developer.mozilla.org/ko/docs/Web/HTTP/Reference/Headers/Origin) ",
    "url": "/Web/web_csrf.html",
    
    "relUrl": "/Web/web_csrf.html"
  },"84": {
    "doc": "JWT",
    "title": "JWT",
    "content": "# JWT - JWT(Json Web Token) 이란 JSON 객체로서, 당사자간에 정보를 안전하게 전송하기위한 개방형 표준(RFC 7519)이다. > **개방형 표준**은 기술 표준의 문서가 공개되어 있고, 누구나 자유롭게 사용할 수 있는 표준을 의미한다. 대표적인 예로 HTML, IP(인터넷 프로토콜), JSON 등이 있다. - 정보는 **서명**되어 있기에 신뢰할 수 있다. JWT는 비밀 키(HMAC 알고리즘 사용) 또는 공개/개인 키 쌍(RSA 또는 ECDSA 사용)을 사용하여 서명할 수 있다. # 사용되는 곳 - **인증** : 사용자에게 JWT 가 생성되어 인증되면, 인증된 사용자의 요청마다 JWT가 포함되어 해당 토큰으로 허용된 경로, 서비스 및 리소스에 액세스할 수 있다. 이러한 Single Sign-On은 오버헤드가 적고 다양한 도메인에서 쉽게 사용할 수 있기 때문에 오늘날 JWT를 널리 사용하는 기능이다. > **Single Sign-On(SSO)** 은 사용자가 한 번만 로그인하면, 동일한 세션 내에서 여러 애플리케이션이나 웹사이트에 추가 로그인 없이 접근할 수 있게 해주는 인증 체계이다. - **정보 교환** : JWT는 공개/개인 키 쌍을 사용하여 서명할 수 있으므로 보낸 사람이 누구인지 확인할 수 있다. 또한 서명은 헤더와 페이로드를 사용하여 계산되므로 콘텐츠가 손상되지 않았는지 확인할 수도 있다. # 구조 JWT 는 base64url 로 인코딩된 JSON 데이터 로 구성되어있으며, 총 세가지 요소가 점(.) 으로 구분되어 있다. JWT 는 간결해야하기 때문에, 각 JSON 데이터의 키는 세자리로 축약한다. ![](/Web/img/web_jwt_structure.png) ## 헤더 헤더는 일반적으로 토큰 유형과 HMAC SHA256 또는 RSA와 같이 해당 JWT 에 사용되는 서명 알고리즘의 두 부분으로 구성된다. ```json { \"alg\": \"HS256\", \"typ\": \"JWT\" } ``` ## 페이로드 페이로드는 클레임을 포함한다. 클레임은 엔터티(일반적으로 사용자) 및 추가 데이터에 대한 설명이다. ### 클레임 클레임에는 등록된 클레임, 공개 클레임 및 개인 클레임의 세 가지 유형이 있다. - **등록된 클레임** : JWT 에서 미리 정의해둔 클레임이다. 필수는 아니지만, 유용한 상호 운용 가능한 클레임 세트를 제공하기 위해 권장된다. - `iss` : 토큰 발급자를 나타낸다. - `sub` : 토큰 제목을 나타낸다. - `aud` : 토큰 대상자를 나타낸다. - `exp` : 토큰 만료 시각을 나타낸다. Numeric Date 형식으로 나타낸다. - `nbf` : Not Before. 토큰의 활성 시각을 나타낸다. 쉽게 말해, 이 시각 전에는 토큰이 유효하지 않다는 의미이다. - `iat` : Issued At. 토큰이 발급된 시각을 나타낸다. Numeric Date 형식으로 나타낸다. 이 값으로 토큰이 발급된지 얼마나 오래됐는지 확인할 수 있다. - `jti` : JWT ID. JWT 의 식별자를 나타낸다. - **공개 클레임** : 공개용 정보(e.g. 이메일 주소, 프로필 이미지 등) 를 위해 사용된다. 충돌 방지를 위해 IANA JSON Web Token Claims Registry 에 등록하여 사용하거나, 정보가 URI 포맷으로 정의될 때 사용한다. ```json \"email\": \"user@example.com\", \"profile\": \"http://domain.com/img.png\", \"http://domain.com/xxx/yyy/is_admin\" : true ``` - **개인 클레임** : 당사자 간에만 협의된 클레임이다. 공개 클레임과 충돌이 일어나지 않도록 해야한다. ```json \"user_id\": \"123456790\", ``` ## 서명 서명 부분을 만들려면 인코딩된 헤더, 인코딩된 페이로드, 비밀 키 및 헤더에서 지정한 알고리즘을 가져와서 해당 비밀 키로 서명해야 한다. 서명은 JWT의 발행자가 자신이 누구인지 확인하고 메시지가 도중에 변경되지 않았는지 확인하는 데 사용한다. ## 직접 확인해보기 [jwt.io](https://jwt.io/) ![](/Web/img/web_jwt_decoder.png) # 작동 방식 ![](/Web/img/web_jwt_diagram.png) 1. 사용자가 로그인 하여, 인증에 성공했다면 서버는 JWT 를 생성하여 반환. 2. 클라이언트는 서버의 반환 방식에 따라 로컬 스토리지 또는 쿠키에 JWT 를 보관. 3. 서비스를 이용하는 동안 인가가 필요한 모든 요청마다 HTTP 헤더에 JWT 를 담음. - 일반적으로 유저 에이전트를 인증하기 위한 자격 증명을 포함하는 Authorization 요청 헤더에 Bearer 스키마를 사용하여 담는다. ```text Authorization: Bearer ``` 4. 서버는 서명을 확인하고 페이로드를 디코딩하여 토큰의 유효성을 검사. # 유효성 검사 와 확인 JWT 의 보안 검사를 위해 유효성 검사 와 확인이라는 절차가 진행된다. ## 유효성 검사 JWT의 구조, 형식 및 내용을 확인하여, 토큰이 말이 되는지, 예상되는 표준을 준수하는지, 올바른 데이터를 포함하는지 확인한다. - **구조**: 토큰에 점으로 구분된 표준 세 부분(헤더, 페이로드, 서명)이 있는지 확인한다. - **형식**: 각 부분이 올바르게 인코딩(base64url) 되었는지, 페이로드에 예상되는 클레임이 포함되어 있는지 확인한다. - **내용**: 페이로드 내의 클레임이 올바른지 확인하여 토큰이 만료되지 않았는지, 시간이 되기 전에 사용되지 않았는지 등을 확인한다. ## 확인 토큰의 진위성과 무결성을 확인하는 것을 포함하며, 토큰이 악의적으로 변경되지 않았고 신뢰할 수 있는 소스에서 온 것인지 확인한다. - **서명 확인**: 비밀 키 또는 공개 키를 사용하여 헤더에 지정된 알고리즘으로 수행되며, 서명이 예상과 일치하는지 확인하여, 토큰이 무결한지 혹은 신뢰할 수 있는 소스에서 온것인지 확인한다. - **발행자 확인**: `iss` 클레임이 예상되는 토큰 발행자와 일치하는지 확인한다. - **대상 확인**: `aud` 클레임이 예상되는 토큰 대상자와 일치하는지 확인한다. # 출처 - [Introduction to JSON Web Tokens](https://jwt.io/introduction) - [Understanding JSON Web Tokens (JWT): A Secure Approach to Web Authentication](https://medium.com/@extio/understanding-json-web-tokens-jwt-a-secure-approach-to-web-authentication-f551e8d66deb) ",
    "url": "/Web/web_jwt.html",
    
    "relUrl": "/Web/web_jwt.html"
  },"85": {
    "doc": "CS Study",
    "title": "CS Study",
    "content": "# CS Study > **컴퓨터 공학 지식을 학습하기 위한 저장소입니다.** ## 목표 - 매주 각자 CS(Computer Science) 관련한 주제에 대해 자료를 정리하여 발표하는 스터디입니다. - CS 관련 지식 습득 및 면접에 도움 이 되는 것을 목표로하고 있습니다. ## 규칙 및 진행 방식 - **매주** **수요일**, **디스코드** 에서 온라인 진행 - 보다 수월한 이해와 질의응답을 위해, **발표전 5분 동안 각자 자료 읽는 시간**을 가집니다. - ❗ 스터디 전까지 별도의 **연락없이 불참** 시 **벌금/벌칙** 이 있습니다. 불가피한 사정이 있다면 미리 말씀해주세요. - **스터디 전날 자정 전(23:59) 까지** 각자 맡은 자료를 준비하여 `main` 브랜치에 **PR 을 생성**합니다. - **출처를 명확**하게 표기해주세요. - ❗ 기한까지 **자료 준비가 되어있지 않다**면 **벌금/벌칙**이 있습니다. - **추가하고 싶은 주제가 있다면 자유롭게** 말씀해주세요. 상의를 통해 자유롭게 추가할 수 있습니다. ## 주제 - [자료구조](https://github.com/Hi-Tech-Study/CS-Study/blob/main/Data%20Structure/readme_DS.md) - [네트워크](https://github.com/Hi-Tech-Study/CS-Study/blob/main/Network/readme_NW.md) - [운영체제](https://github.com/Hi-Tech-Study/CS-Study/blob/main/OS/readme_OS.md) - [데이터베이스](https://github.com/Hi-Tech-Study/CS-Study/blob/main/Database/readme_DB.md) - [디자인패턴](https://github.com/Hi-Tech-Study/CS-Study/blob/main/Design%20Pattern/readme_DP.md) - [Web](https://github.com/Hi-Tech-Study/CS-Study/blob/main/Web/readme_Web.md) - [알고리즘](https://github.com/Hi-Tech-Study/CS-Study/blob/main/Algorithm/readme_AG.md) ",
    "url": "/",
    
    "relUrl": "/"
  }
}
